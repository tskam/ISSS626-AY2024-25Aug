[
  {
    "objectID": "Take-home_Ex02.html",
    "href": "Take-home_Ex02.html",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "",
    "text": "Important\n\n\n\nThis handout provides the context, the task, the expectation and the grading criteria of Take-home Exercise 2. Students must review and understand them before getting started with the take-home exercise."
  },
  {
    "objectID": "Take-home_Ex02.html#setting-the-scene",
    "href": "Take-home_Ex02.html#setting-the-scene",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Setting the Scene",
    "text": "Setting the Scene\nTourism is one of Thailand’s largest industries, accounting for some 20% of the gross domestic product (GDP). In 2019, Thailand earned 90 billion US$ from domestic and international tourism, but the COVID-19 pandemic caused revenues to crash to 24 billion US$ in 2020.\nFigure below shows the total revenue receipt from tourism sector from January 2019 until Feb 2023. The figure reveals that the revenue from tourism industry have been recovered gradually since September 2021.\n\nHowever, it is important to note that the tourism economy of Thailand are not evenly distributed. Figure below reveals that the tourism economy of Thailand are mainly focus on five provinces, namely Bangkok, Phuket, Chiang Mai, Sukhothai and Phetchaburi."
  },
  {
    "objectID": "Take-home_Ex02.html#objectives",
    "href": "Take-home_Ex02.html#objectives",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Objectives",
    "text": "Objectives\nAs a curious geospatial analytics green horn, you are interested to discover:\n\nif the key indicators of tourism economy of Thailand are independent from space and space and time.\n\nIf the tourism economy is indeed spatial and spatio-temporal dependent, then, you would like to detect where are the clusters and outliers, and the emerging hot spot/cold spot areas."
  },
  {
    "objectID": "Take-home_Ex02.html#the-task",
    "href": "Take-home_Ex02.html#the-task",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "The Task",
    "text": "The Task\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate function of sf and tidyverse, preparing the following geospatial data layer:\n\na study area layer in sf polygon features. It must be at province level (including Bangkok) of Thailand.\na tourism economy indicators layer within the study area in sf polygon features.\na derived tourism economy indicator layer in spacetime s3 class of sfdep. Keep the time series at month and year levels.\n\nUsing the extracted data, perform global spatial autocorrelation analysis by using sfdep methods.\nUsing the extracted data, perform local spatial autocorrelation analysis by using sfdep methods.\nUsing the extracted data, perform emerging hotspot analysis by using sfdep methods.\nDescribe the spatial patterns revealed by the analysis above."
  },
  {
    "objectID": "Take-home_Ex02.html#the-data",
    "href": "Take-home_Ex02.html#the-data",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "The Data",
    "text": "The Data\nFor the purpose of this take-home exercise, two data sets shall be used, they are:\n\nThailand Domestic Tourism Statistics at Kaggle. You are required to use version 2 of the data set.\nThailand - Subnational Administrative Boundaries at HDX. You are required to use the province boundary data set."
  },
  {
    "objectID": "Take-home_Ex02.html#grading-criteria",
    "href": "Take-home_Ex02.html#grading-criteria",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Grading Criteria",
    "text": "Grading Criteria\nThis exercise will be graded by using the following criteria:\n\nGeospatial Data Wrangling (20 marks): This is an important aspect of geospatial analytics. You will be assessed on your ability:\n\nto employ appropriate R functions from various R packages specifically designed for modern data science such as readxl, tidyverse (tidyr, dplyr, ggplot2), sf just to mention a few of them, to perform the import and extract the data.\nto clean and derive appropriate variables for meeting the analysis need.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAll data are like vast grassland full of land mines. Your job is to clear those mines and not to step on them.\n\n\n\nGeospatial Analysis (30 marks): In this exercise, you are expected to use the appropriate global and local measures of spatial autocorrelation, and emerging hot spot analysis methods in class to perform the analysis. You will be assessed on your ability:\n\nto describe the methods used correctly, and\nto provide accurate interpretation of the analysis results.\n\nGeovisualisation and geocommunication (20 marks): In this section, you will be assessed on your ability to communicate the results in business friendly visual representations. This course is geospatial centric, hence, it is important for you to demonstrate your competency in using appropriate geovisualisation techniques to reveal and communicate the findings of your analysis.\nReproducibility (15 marks): This is an important learning outcome of this exercise. You will be assessed on your ability to provide a comprehensive documentation of the analysis procedures in the form of code chunks of Quarto. It is important to note that it is not enough by merely providing the code chunk without any explanation on the purpose and R function(s) used.\nBonus (15 marks): Demonstrate your ability to employ methods beyond what you had learned in class to gain insights from the data."
  },
  {
    "objectID": "Take-home_Ex02.html#submission-instructions",
    "href": "Take-home_Ex02.html#submission-instructions",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Submission Instructions",
    "text": "Submission Instructions\n\nThe write-up of the take-home exercise must be in Quarto html document format. You are required to publish the write-up on Netlify.\nZip the take-home exercise folder and upload it onto eLearn. If the size of the zip file is beyond the capacity of eLearn, you can upload it on SMU OneDrive and provide the download link on eLearn.."
  },
  {
    "objectID": "Take-home_Ex02.html#due-date",
    "href": "Take-home_Ex02.html#due-date",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Due Date",
    "text": "Due Date\n13th October 2024 (Sunday), 11.59pm (midnight)."
  },
  {
    "objectID": "Take-home_Ex02.html#learning-from-senior",
    "href": "Take-home_Ex02.html#learning-from-senior",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Learning from senior",
    "text": "Learning from senior\nYou are advised to review these sample submissions prepared by your seniors.\n\nCHUA YAN TING: Have done well in all five grading criteria especially the geocommunication criterion.\nLIN SHUYAN Geospatial data wrangling is very comprehensively done especially identifying water points located outside Nigeria administrative boundary due to location precision issue.\nLOH SI YING Have done well in all five grading criteria especially the followings: (i) the geospatial wrangling are very comprehensively done including to exclude LGAs without water points from the analysis, (ii) managed to compute the p-values, (iii) Start each analysis by explaining the purpose of the analysis. Managed to relate the analysis results to the location context."
  },
  {
    "objectID": "Take-home_Ex02.html#learning-from-is415",
    "href": "Take-home_Ex02.html#learning-from-is415",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Learning from IS415",
    "text": "Learning from IS415\n\nKHANT MIN NAING: Very well done in all the five grading criteria especially the ability to provide a comprehensive overview of the analysis methods used and discussion on the analysis results.\nMATTHEW HO YIWEN Able to provide a clear and comprehensive discussion on the geospatial data wrangling process and to communicate the analysis results by using appropriate geovisualisation and data visualisation methods."
  },
  {
    "objectID": "Take-home_Ex02.html#q-a",
    "href": "Take-home_Ex02.html#q-a",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Q & A",
    "text": "Q & A\nPlease submit your questions or queries related to this take-home exercise on Piazza."
  },
  {
    "objectID": "Take-home_Ex02.html#peer-learning",
    "href": "Take-home_Ex02.html#peer-learning",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Peer Learning",
    "text": "Peer Learning"
  },
  {
    "objectID": "Take-home_Ex02.html#reference",
    "href": "Take-home_Ex02.html#reference",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Reference",
    "text": "Reference\n\nIMPACT OF COVID-19 ON THAILAND’S TOURISM SECTOR\nCovid: Thailand tourism up but still below pre-pandemic level\nTourism in Thailand\n\n\nResearch articles\n\nUglješa Stankov et. al. (2017) “Spatial autocorrelation analysis of tourist arrivals using municipal data: A Serbian example”, Geographica Pannonica, Vol.21 (2), p.106-114. SMU e-journal.\nKhan, D. et. al. (2017) “Hot spots, cluster detection and spatial outlier analysis of teen birth rates in the U.S., 2003–2012”, Spatial and Spatio-temporal Epidemiology, Vol. 21, pp. 67–75.\nMuhammad Arif & Didit Purnomo (2017) “Measuring Spatial Cluster for Leading Industries in Surakarta with Exploratory Spatial Data Analysis (ESDA)”, Jurnal Ekonomi Pembangunan, Vol. 18 (1), pp. 64-81.\nJoshua T. Fergen * and Ryan D. Bergstrom (2021) “Social Vulnerability across the Great Lakes Basin: A County-Level Comparative and Spatial Analysis”, Sustainability, Vol. 13(13).\nV Putrenko, N Pashynska, and S Nazarenko (2018) “Data Mining of Network Events With Space-Time Cube Application”. In: R Westerholt, F-B Mocnik, and A Zipf (eds.), Proceedings of the 1st Workshop on Platial Analysis (PLATIAL’18), pp. 75–82. SMU e-journal.\nJamie Anne Boschan and Caterina G. Roman (2024) “Hot Spots of Gun Violence in the Era of Focused Deterrence: A Space-Time Analysis of Shootings in South Philadelphia”, Social Sciences, Vol. 13.\nMinkyung Kim and Sangdon Lee (2023) “Identification of Emerging Roadkill Hotspots on Korean Expressways Using Space–Time Cubes”, Int. J. Environ. Res. Public Health, 20(6)."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Synopsis",
    "section": "",
    "text": "Where should the next new business outlet be located in order to optimise the profit? What are the location factors that affect the resale prices of HDB housing units? Which are the economic or service activities such as IT professional firms, car workshops, fast food chains (ie. KFC, McDonalds), coffee outlets (Starbucks, Ya Kun Kaya Toast, Toast Box) that tend to be located close to one another and which are the ones that tend to be a distance apart? Do these observed patterns and processes occur at random or are they being constrained by geographical factors? These and many other related questions are the challenges faced by data scientists and data analysts today especially when geographical data are used.\nGeospatial Analytics offers the solutions to these questions by providing data scientists and analysts a problem-driven and data-centric analysis framework focusing on discovering actionable understanding from geographically referenced data. It makes extensive use of geospatial data wrangling, geoprocessing, spatial statistical, geospatial machine learning and spatial data visualisation techniques to support decision- and strategy-making.\nThis course provides students with an introduction to the concepts, principles and methods of geospatial analytics and their practical applications of geospatial analytics in real world operations. Emphasis will be placed on:\n\nperforming geospatial data science tasks such as importing, tidying, manipulating, transforming, projecting and processing geospatial data programmatically,\nvisualising, analysing and describing geographical patterns and processes using appropriate geovisualisation and thematic mapping techniques,\nconducting geospatial analysis by using appropriate spatial statistics and Geomachine learning methods and\ncommunicating the geospatial analysis pipeline in a reproducible report."
  },
  {
    "objectID": "syllabus.html#course-structure",
    "href": "syllabus.html#course-structure",
    "title": "Synopsis",
    "section": "Course structure",
    "text": "Course structure\n\nBasic Modules\nThis course comprises ten integrated components as shown below:"
  },
  {
    "objectID": "syllabus.html#grading-summary",
    "href": "syllabus.html#grading-summary",
    "title": "Synopsis",
    "section": "Grading Summary",
    "text": "Grading Summary\n\n\n\nAssignments / Assessment categories\nWeighting\n\n\n\n\nPre-lesson Learning and Class Participation\n5%\n\n\nHands-on Exercise (2% x 10)\n20%\n\n\nIn-class Exercise (3% x 10)\n30%\n\n\nTake-home Exercise (15% x 3)\n45%\n\n\n\n\nPre-lesson Learning and Class Participation (5%)\nPre-lesson videos and recommended readings exercises will be released one week before the weekly lesson starts. A strict requirement for each class meeting is to complete the assigned readings and video before coming to class. Students are required write down at least one question or issue encountered while viewing the video or reading the recommended articles and post them on Piazza for discussion.\nStudent sharing of insights from readings of assigned materials on Piazza will form a large part of the learning in this course.\n\n\nHands-on Exercise (20%)\nHands-on exercises aim to provide students to gain hands-on experience on using selected R packages to perform geospatial analysis with real world use cases. It is important for students to complete the hands-on exercises before class.\n\n\nIn-class Exercise (30%)\nIn-class exercise and discussion will extend the methods learned from the hands-on exercise to advanced modelling. The in-class discussion will also focus on how to interpret the analysis results and to communicate the analysis results by using appropriate map and data visualisation techniques. Students may also be quizzed in class and thereby contribute to in-class exercise.\n\n\nTake-home Exercise (45%)\nThere are three take-home exercises that are due throughout the term. They aim to provide students the opportunities to apply the methods learned in class by working through mini real-world cases. Each take-home exercise is an extension of the hands-on and in-class exercises. What this means is that, for example, in Lesson 1, students will learn the concept of spatial point processes and the hands-on exercise will provide students step-by-step guide on how to use R packages to perform spatial point patterns analysis. The in-class discussion, beside clarification of the concepts and usage of R packages syntax and argument, it will focus more on how to interpret and communicate the analysis results. Then the take-home exercise will require students to synthesise what they have learned from the readings, hands-on exercise and in-class exercise. The estimated workload will be about 6-8 hours per week.\nEach take-home exercise will carry a same weightage of 15%. The deliverable format of the take-home exercises and marking rubric of will be provided on the handout of the take-home exercise. Feedback on take-home exercise will be provided weekly before the weekly lesson starts. This is to ensure that students will learn from mistakes made in the earlier take-home exercise and improve their work progressively in the subsequent take-home exercises.\nStudents may work together to help one another with computer or geospatial issues and discuss the materials that constitute the take-home exercise. However, each student is required to prepare and submit the take-home exercise (including any computer work) on their own. Cheating is strictly prohibited. Cheating includes but not limited to: plagiarism and submission of work that is not the student’s.\n\n\nFinal Exam\nThere will be no final examination for this course."
  },
  {
    "objectID": "syllabus.html#reference",
    "href": "syllabus.html#reference",
    "title": "Synopsis",
    "section": "Reference",
    "text": "Reference\n\nGimond, Manuel. (2018) Introduction to GIS and Spatial Analysis. (e-book, last visit: 11/11/2022).\nFloch, J.M., Marcon, E. and Puech, F. (2018) Handbook of Spatial Analysis: Theory and Application with R.\nRoger S. Bivand, Edzer Pebesma and Virgilio Gómez-Rubio (2013) Applied Spatial Data Analysis with R (2nd Edition), Springer. (via SMU Library)\n\nBrunsdon, C. & Comber, L (2019) An Introduction to R for Spatial Analysis and Mapping (2nd Edition), SAGE Publication, London."
  },
  {
    "objectID": "R.html",
    "href": "R.html",
    "title": "R Resources",
    "section": "",
    "text": "This page provides links to a selected resources to learn modern R packages, especially those related to tidyverse framework."
  },
  {
    "objectID": "R.html#getting-started-with-r",
    "href": "R.html#getting-started-with-r",
    "title": "R Resources",
    "section": "Getting Started with R",
    "text": "Getting Started with R\n\nR for Data Science by Garrett Grolemund and Hadley Wickham.\nModern R with the tidyverse by Bruno Rodrigues. Chapter 2 provides a detail discussion on R data objects.\nBrendan R. E. Ansell Introduction to R - tidyverse\nThe Comprehensive Guide to Installing R Packages from CRAN, Bioconductor, GitHub and Co.. This article provides useful tips on how to install R packages from different sources.\nR Workflow"
  },
  {
    "objectID": "R.html#blog-post",
    "href": "R.html#blog-post",
    "title": "R Resources",
    "section": "Blog post",
    "text": "Blog post\n\nR Workflow from Statistical Thinking."
  },
  {
    "objectID": "outline/workshop.html",
    "href": "outline/workshop.html",
    "title": "Workshop on Building Web-enabled Geospatial Analytics Applications with R Shiny",
    "section": "",
    "text": "Motivation of developing web-enabled applications\n\nBasic principles of web applications\n\nIntroducing R Shiny\n\nGetting to know Shiny\nArchitecture of Shiny\nBuilding block of Shiny app\n\nAdvanced R Shiny\n\nReactive feature of Shiny\nBuild interactive Shiny application by using plotly R\nBuild static, interactive and reactive geovisualisation application by using tmap\n\nManaging R Shiny Project\n\nThe basic development cycle of creating apps\nDebug errors in the codes\nBuild complex Shiny application using module\nImprove the productivity of Shiny applications development\n\nDeploying Shiny Application\n\nDeploy to the cloud: shinyapps.io\nDeploy on-premises (open source): Shiny Server\nDeploy on-premises (commercial): RStudio Connect"
  },
  {
    "objectID": "outline/workshop.html#content",
    "href": "outline/workshop.html#content",
    "title": "Workshop on Building Web-enabled Geospatial Analytics Applications with R Shiny",
    "section": "",
    "text": "Motivation of developing web-enabled applications\n\nBasic principles of web applications\n\nIntroducing R Shiny\n\nGetting to know Shiny\nArchitecture of Shiny\nBuilding block of Shiny app\n\nAdvanced R Shiny\n\nReactive feature of Shiny\nBuild interactive Shiny application by using plotly R\nBuild static, interactive and reactive geovisualisation application by using tmap\n\nManaging R Shiny Project\n\nThe basic development cycle of creating apps\nDebug errors in the codes\nBuild complex Shiny application using module\nImprove the productivity of Shiny applications development\n\nDeploying Shiny Application\n\nDeploy to the cloud: shinyapps.io\nDeploy on-premises (open source): Shiny Server\nDeploy on-premises (commercial): RStudio Connect"
  },
  {
    "objectID": "outline/workshop.html#workshop-slides-and-hands-on-notes",
    "href": "outline/workshop.html#workshop-slides-and-hands-on-notes",
    "title": "Workshop on Building Web-enabled Geospatial Analytics Applications with R Shiny",
    "section": "Workshop Slides and Hands-on Notes",
    "text": "Workshop Slides and Hands-on Notes\n\nIntroducing R Shiny slides in html and pdf formats\nAdvanced R Shiny I slides in html and pdf formats\nManaging R Shiny Project slides in html and pdf formats"
  },
  {
    "objectID": "outline/workshop.html#must-do",
    "href": "outline/workshop.html#must-do",
    "title": "Workshop on Building Web-enabled Geospatial Analytics Applications with R Shiny",
    "section": "Must Do!",
    "text": "Must Do!\n\nView the three parts series of Shiny Tutorial at this link."
  },
  {
    "objectID": "outline/workshop.html#readings",
    "href": "outline/workshop.html#readings",
    "title": "Workshop on Building Web-enabled Geospatial Analytics Applications with R Shiny",
    "section": "Readings",
    "text": "Readings\n\nCore Readings\n\nShiny reference guide at CRAN.\nHadley Wickham (2021) Mastering Shiny, O’Reilly Media. This is a highly recommended book. You can find the online version with this link.\nPaula Moraga (2020) Geospatial Health Data: Modeling and Visualization with R-INLA and Shiny, Chapman & Hall/CRC. Chapter 13, 14 and 15.\n\n\n\nAdditional references\n\nColin Fay, Sébastien Rochette, Vincent Guyader, Cervan Girard (2020), Engineering Production-Grade Shiny Apps, Chapman & Hall. You can find the online version with this link.\nOutstanding User Interfaces with Shiny.\nHow to Build a Shiny Application from Scratch.\n\n\n\nDeploying Shiny Application on shinyapps.io\n\nGetting started with shinyapps.io\nshinyapps.io user guide"
  },
  {
    "objectID": "outline/workshop.html#gallery",
    "href": "outline/workshop.html#gallery",
    "title": "Workshop on Building Web-enabled Geospatial Analytics Applications with R Shiny",
    "section": "Gallery",
    "text": "Gallery\n\nWinners of the 1st Shiny Contest\nWinners of the 2nd Annual Shiny Contest\nWinners of the 3rd annual Shiny Contest\nShiny Gallery\nFifteen New Zealand government Shiny web apps\nShinyApps Gallery\ndreamRs shiny gallery\nTools for Teaching Quantitative Thinking"
  },
  {
    "objectID": "outline/Lesson09_outline.html",
    "href": "outline/Lesson09_outline.html",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "",
    "text": "Basic Concepts of Geographic Accessibility\nGravitational Law and Distance Decay Function\nIntroducing Potential Models\n\nThe classic model\n\nHansen Potential Accessibility Model\nTwo-step Floating Catchment Area (2SFCA) Method\nKernel Density Two-Step Floating Catchment Area (KD2SFCA) Method\nInterpreting and Visualising Modelling Results"
  },
  {
    "objectID": "outline/Lesson09_outline.html#content",
    "href": "outline/Lesson09_outline.html#content",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "",
    "text": "Basic Concepts of Geographic Accessibility\nGravitational Law and Distance Decay Function\nIntroducing Potential Models\n\nThe classic model\n\nHansen Potential Accessibility Model\nTwo-step Floating Catchment Area (2SFCA) Method\nKernel Density Two-Step Floating Catchment Area (KD2SFCA) Method\nInterpreting and Visualising Modelling Results"
  },
  {
    "objectID": "outline/Lesson09_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson09_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson 9 slides.\nHands-on Exercise 9 handout."
  },
  {
    "objectID": "outline/Lesson09_outline.html#self-reading-before-meet-up",
    "href": "outline/Lesson09_outline.html#self-reading-before-meet-up",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "Self-reading Before Meet-up",
    "text": "Self-reading Before Meet-up\nRead before lesson:\n\nLong, J. (2017). Modelling Accessibility. The Geographic Information Science & Technology Body of Knowledge (3rd Quarter 2017 Edition), John P. Wilson (ed.).\nHansen, W. G. (1959): “How Accessibility Shapes Land Use”. Journal of the American Institute of Planners, 25, 2, p. 73-76.\nLuo, W.; Wang, F. (2003) “Measures of spatial accessibility to health care in a GIS environment: synthesis and a case study in the Chicago region”. Environment and Planning B: Planning and Design. 30 (6): 865–884. doi:10.1068/b29120.\nLuo, W.; Qi, Y. (2009). “An enhanced two-step floating catchment area (E2SFCA) method for measuring spatial accessibility to primary care physicians”. Health & Place. 15 (4): 1100–1107."
  },
  {
    "objectID": "outline/Lesson09_outline.html#reference",
    "href": "outline/Lesson09_outline.html#reference",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "Reference",
    "text": "Reference\n\nSection on “Transportation and Accessibility” in The Geography of Transport Systems.\nRich, D.C. (1980) Potential Models in Human Geography.\nOrpana, T./Lampinen, J. (2003) “Building spatial choice models from aggregate data”. Journal of Regional Science,43, 2, p. 319-347.\nTwo-step floating catchment area method.\nCheng, Gang et. al. (2016) “Spatial difference analysis for accessibility to high level hospitals based on travel time in Shenzhen, China” Habitat International, Vol.53, p.485-494.\nPolzin, Pierre ; Borges, José ; Coelho, António (2014) “An Extended Kernel Density Two-Step Floating Catchment Area Method to Analyze Access to Health Care” Environment and planning. B, Planning & design, Vol.41 (4), p.717-735."
  },
  {
    "objectID": "outline/Lesson09_outline.html#all-about-r",
    "href": "outline/Lesson09_outline.html#all-about-r",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "All About R:",
    "text": "All About R:\n\naccessibility\nSpatialAcc package.\nPotential package."
  },
  {
    "objectID": "outline/Lesson07_outline.html",
    "href": "outline/Lesson07_outline.html",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "",
    "text": "In this lesson, you will learn the basic concepts and methods of geographically weighted regression."
  },
  {
    "objectID": "outline/Lesson07_outline.html#content",
    "href": "outline/Lesson07_outline.html#content",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "Content",
    "text": "Content\n\nBasic concepts and principles of linear regression\n\nSimple linear regression\nMultiple linear regression\n\nThe spatial stationarity assumption of multiple linear regression.\nIntroducing Geographically Weighted Regression\n\nWeighting functions (kernel)\nWeighting schemes\nBandwidth\nInterpreting and Visualising"
  },
  {
    "objectID": "outline/Lesson07_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson07_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson 7 slides.\nHands-on Exercise 7."
  },
  {
    "objectID": "outline/Lesson07_outline.html#self-reading-before-meet-up",
    "href": "outline/Lesson07_outline.html#self-reading-before-meet-up",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "Self-reading Before Meet-up",
    "text": "Self-reading Before Meet-up\nTo read before class:\n\nBrunsdon, C., Fotheringham, A.S., and Charlton, M. (2002) “Geographically weighted regression: A method for exploring spatial nonstationarity”. Geographical Analysis, 28: 281-289.\nBrunsdon, C., Fotheringham, A.S. and Charlton, M., (1999) “Some Notes on Parametric Significance Tests for Geographically Weighted Regression”. Journal of Regional Science, 39(3), 497-524."
  },
  {
    "objectID": "outline/Lesson07_outline.html#references",
    "href": "outline/Lesson07_outline.html#references",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "References",
    "text": "References\n\nMennis, Jeremy (2006) “Mapping the Results of Geographically Weighted Regression”, The Cartographic Journal, Vol.43 (2), p.171-179.\nStephen A. Matthews ; Tse-Chuan Yang (2012) “Mapping the results of local statistics: Using geographically weighted regression”, Demographic Research, Vol.26, p.151-166."
  },
  {
    "objectID": "outline/Lesson07_outline.html#all-about-r",
    "href": "outline/Lesson07_outline.html#all-about-r",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "All About R",
    "text": "All About R\n\nGWmodel package, especially\n\nGollini, I et. al. (2015) “GWmodel: An R Package for Exploring Spatial Heterogeneity Using Geographically Weighted Models”, Journal of Statistical Software, Volume 63, Issue 17 and\nBinbin Lu, Paul Harris, Martin Charlton & Chris Brunsdon (2014) “The GWmodel R package: further topics for exploring spatial heterogeneity using geographically weighted models”, Geo-spatial Information Science, 17:2, 85-101, DOI: 10.1080/10095020.2014.917453.\n\nlctools package especially gw() and gwr() related functions.\nspgwr implements of geographically weighted regression methods for exploring possible non-stationarity.\ngwrr: its geographically weighted regression (GWR) models and has tools to diagnose and remediate collinearity in the GWR models. Also fits geographically weighted ridge regression (GWRR) and geographically weighted lasso (GWL) models."
  },
  {
    "objectID": "outline/Lesson05_outline.html",
    "href": "outline/Lesson05_outline.html",
    "title": "Lesson 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this lesson, you will learn a collection of geospatial statistical methods specially designed for measuring global and local spatial association.\nThese spatial statistics are well suited for:"
  },
  {
    "objectID": "outline/Lesson05_outline.html#content",
    "href": "outline/Lesson05_outline.html#content",
    "title": "Lesson 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Content",
    "text": "Content\n\nWhat is Spatial Autocorrelation\n\nMeasures of Global Spatial Autocorrelation\nMeasures of Global High/Low Clustering\n\nIntroducing Localised Geospatial Analysis\n\nLocal Indicators of Spatial Association (LISA)\n\nCluster and Outlier Analysis\n\nLocal Moran and Local Geary\nMoran scatterplot\nLISA Cluster Map\n\nHot Spot and Cold Spot Areas Analysis\n\nGetis and Ord’s G-statistics\n\nEmerging Hot Spot Analysis (EHSA)"
  },
  {
    "objectID": "outline/Lesson05_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson05_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson 5 slides.\nHands-on Exercise 5: Global Measures of Spatial Autocorrelation.\nHands-on Exercise 5: Local Measures of Spatial Autocorrelation"
  },
  {
    "objectID": "outline/Lesson05_outline.html#self-reading-before-meet-up",
    "href": "outline/Lesson05_outline.html#self-reading-before-meet-up",
    "title": "Lesson 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Self-reading Before Meet-up",
    "text": "Self-reading Before Meet-up\nTo read before class:\n\nMoran, P. A. P. (1950). “Notes on Continuous Stochastic Phenomena”. Biometrika. 37 (1): 17–23.\nGeary, R.C. (1954) “The Contiguity Ratio and Statistical Mapping”. The Incorporated Statistician, Vol. 5, No. 3, pp. 115-127.\nGetis, A., & Ord, K. (1992). “The Analysis of Spatial Association by Use of Distance Statistics”. Geographical Analysis, 24, 189–206.\nAnselin, L. (1995). “Local indicators of spatial association – LISA”. Geographical Analysis, 27(4): 93-115.\nGetis, A. and Ord, J.K. (1992) “The analysis of spatial association by use of distance statistics”. Geographical Analysis, 24(3): 189-206.\nOrd, J.K. and Getis, A. (2010) “Local spatial autocorrelation statistics: Distributional issues and an application”. Geographical Analysis, 27(4): 286-306.\n\nThese six papers are classics of Global and Local Spatial Autocorrelation. Be warned: All classic papers assume that the readers are academic researchers."
  },
  {
    "objectID": "outline/Lesson05_outline.html#references",
    "href": "outline/Lesson05_outline.html#references",
    "title": "Lesson 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "References",
    "text": "References\n\nD. A. Griffith (2009) “Spatial autocorrelation”.\nGetis, A., 2010 “B.3 Spatial Autocorrelation” in Fischer, M.M., and Getis, A. 2010 Handbook of Applied Spatial Analysis: Software Tools, Methods and Applications, Springer.\nAnselin, L. (1996) “The Moran scatterplot as an ESDA tool to assess local instability in spatial association”\nGriffith, Daniel (2009) “Modeling spatial autocorrelation in spatial interaction data: empirical evidence from 2002 Germany journey-to-work flows”. Journal of Geographical Systems, Vol.11(2), pp.117-140.\nCelebioglu, F., and Dall’erba, S. (2010) “Spatial disparities across the regions of Turkey: An exploratory spatial data analysis”. The Annals of Regional Science, 45:379–400.\nMack, Z.W.V. and Kam T.S. (2018) “Is There Space for Violence?: A Data-driven Approach to the Exploration of Spatial-Temporal Dimensions of Conflict” Proceedings of 2nd ACM SIGSPATIAL Workshop on Geospatial Humanities (ACM SIGSPATIAL’18). Seattle, Washington, USA, 10 pages.\nTAN, Yong Ying and KAM, Tin Seong (2019). “Exploring and Visualizing Household Electricity Consumption Patterns in Singapore: A Geospatial Analytics Approach”, Information in Contemporary Society: 14th International Conference, iConference 2019, Washington, DC, USA, March 31–April 3, 2019, Proceedings. Pp 785-796.\nSingh A., Pathak P.K., Chauhan R.K., and Pan, W. (2011) “Infant and Child Mortality in India in the Last Two Decades: A Geospatial Analysis”. PLoS ONE 6(11), 1:19."
  },
  {
    "objectID": "outline/Lesson03_outline.html",
    "href": "outline/Lesson03_outline.html",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "",
    "text": "In this lesson, you will learn two advanced spatial point patterns analysis methods, they are: spatiotemporal KDE and the Network Constrained KDE. Using real-world use cases, you will also gain hands-on experience on using spNetwork to analyse spatial point patterns and temporal spatial point event along networks."
  },
  {
    "objectID": "outline/Lesson03_outline.html#content",
    "href": "outline/Lesson03_outline.html#content",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "Content",
    "text": "Content\n\nSpatiotemporal Kernel Density Estimation\nNetwork Constrained Kernel Density Estimation (NCKDE)\n\nBasic concepts of network constrained spatial point patterns\nNetwork Constrained KDE methods\nThe Three versions of Network Constrained KDE\n\nTemporal Network Kernel Density Estimation (TNKED)\n\nTemporal dimension\nSpatial dimension\nSpatiotemporal point patterns\nThe Temporal Network Kernel Density Estimation method\n\n\n\nLesson Slides and Hands-on Notes\n\nLesson 3 slides\nHands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis."
  },
  {
    "objectID": "outline/Lesson03_outline.html#references",
    "href": "outline/Lesson03_outline.html#references",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "References",
    "text": "References\n\nATSUYUKI OKABE, TOSHIAKI SATOH & KOKICHI SUGIHARA (2009) “A kernel density estimation method for networks, its computational method and a GIS-based tool”, International Journal of Geographical Information Science, Vol. 23, No. 1, January 2009, pp. 7–32.\nIkuho Yamada & Jean-Claude Thill (2007) “Local Indicators of Network-Constrained Clusters in Spatial Point Patterns”, Geographical Analysis, Vol. 39, pp 268–292.\nJérémy Gelb & Philippe Apparicio (2023) “Temporal Network Kernel Density Estimation”, Geographical Analysis. (Online open access version)"
  },
  {
    "objectID": "outline/Lesson03_outline.html#all-about-r",
    "href": "outline/Lesson03_outline.html#all-about-r",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "All About R",
    "text": "All About R\n\nspNetwork: An R package to perform spatial analysis on networks.\n\nDetails about NKDE\nNetwork k Functions\nNetwork Kernel Density Estimate\nTemporal Network Kernel Density Estimate"
  },
  {
    "objectID": "outline/Lesson01_outline.html",
    "href": "outline/Lesson01_outline.html",
    "title": "Lesson 1: Introduction to Geospatial Analytics",
    "section": "",
    "text": "This lesson consists of three parts. First, it provides an overview of geospatial analytics. Second, R objects used to import, integrate, wrangle, process geospatial data will be discussed. The discussion will focus on sfpackage. Other R packages for storing (i.e. sp), transforming (i.e. rgdal), and processing (i.e. rgeos) geospatial data will be discussed briefly too. Lastly, the basic principles and concepts of thematic mapping and geovisualisation will be introduced. You will also gain hands-on experience on using tmap package to build cartographic quality thematic maps."
  },
  {
    "objectID": "outline/Lesson01_outline.html#overview",
    "href": "outline/Lesson01_outline.html#overview",
    "title": "Lesson 1: Introduction to Geospatial Analytics",
    "section": "",
    "text": "This lesson consists of three parts. First, it provides an overview of geospatial analytics. Second, R objects used to import, integrate, wrangle, process geospatial data will be discussed. The discussion will focus on sfpackage. Other R packages for storing (i.e. sp), transforming (i.e. rgdal), and processing (i.e. rgeos) geospatial data will be discussed briefly too. Lastly, the basic principles and concepts of thematic mapping and geovisualisation will be introduced. You will also gain hands-on experience on using tmap package to build cartographic quality thematic maps."
  },
  {
    "objectID": "outline/Lesson01_outline.html#content",
    "href": "outline/Lesson01_outline.html#content",
    "title": "Lesson 1: Introduction to Geospatial Analytics",
    "section": "Content",
    "text": "Content\n\nIntroduction to Geospatial Analytics\n\nDemystifying Geospatial Analytics\nMotivation of Geospatial Analytics\nA Tour Through the Geospatial Analytics Zoo\nGeospatial Analytics and Social Consciousness\n\nFundamentals of Geospatial Data and sf Methods\n\nAn overview of Geospatial Data Models\nMap Projection and Georeferencing\nGeocoding\nClasses of Spatial Data in R: Simple features class\nsf methods\n\nFundamentals of Geospatial Data Visualisation and tmap Methods\n\nClassification of maps\nPrinciples of map design\nThematic mapping techniques\ntmap methods"
  },
  {
    "objectID": "outline/Lesson01_outline.html#lesson-slides",
    "href": "outline/Lesson01_outline.html#lesson-slides",
    "title": "Lesson 1: Introduction to Geospatial Analytics",
    "section": "Lesson Slides",
    "text": "Lesson Slides\n\nLesson 1: Introduction to Geospatial Analytics slides.\nLesson 1: Fundamentals of Geospatial Data and sf Methods slides.\nLesson 1: Fundamental of Geospatial Data Visualisationand tmap Methods slides."
  },
  {
    "objectID": "outline/Lesson01_outline.html#self-reading-before-lesson",
    "href": "outline/Lesson01_outline.html#self-reading-before-lesson",
    "title": "Lesson 1: Introduction to Geospatial Analytics",
    "section": "Self-reading Before Lesson",
    "text": "Self-reading Before Lesson\n\n“Spatial Data, Spatial Analysis, Spatial Data Science” by Prof. Luc Anselin. (This is a long lecture 1hr 15minutes but don’t turn away just because it is lengthy.)\nXie, Yiqun et. al. (2017) “Transdisciplinary Foundations of Geospatial Data Science” ISPRS International Journal of Geo-information, 2017, Vol.6 (12), p.395."
  },
  {
    "objectID": "outline/Lesson01_outline.html#hands-on-exercise",
    "href": "outline/Lesson01_outline.html#hands-on-exercise",
    "title": "Lesson 1: Introduction to Geospatial Analytics",
    "section": "Hands-on Exercise",
    "text": "Hands-on Exercise\n\nHands-on Exercise 1: Geospatial Data Wrangling with R\nHands-on Exercise 1: Choropleth Mapping with R"
  },
  {
    "objectID": "outline/Lesson01_outline.html#all-about-r",
    "href": "outline/Lesson01_outline.html#all-about-r",
    "title": "Lesson 1: Introduction to Geospatial Analytics",
    "section": "All About R",
    "text": "All About R\n\nR packages for Data Science\n\nsf package.\n\nSimple Features for R\nReading, Writing and Converting Simple Features\nManipulating Simple Feature Geometries\nManipulating Simple Features\n\ntidyverse: a family of modern R packages specially designed to meet the tasks of Data Science in R.\n\nreadr: a fast and effective library to parse csv, txt, and tsv files as tibble data.frame in R. To get started, refer to Chapter 11 Data import of R for Data Science book.\n\ntidyr: an R package for tidying data. To get started, refer to Chapter 5 Data tidying of R for Data Science book.\n\ndplyr: a grammar of data manipulation. To get started, read articles under Getting Started and Articles tabs.\nggplot2: a grammar of graphics. To get started, read Chapter 1: Data Visualization, Chapter 10 Exploratory Data Analysis and Chapter 11 Communication of R for Data Science (2ed) book.\npipes: a powerful tool for clearly expressing a sequence of multiple operations. To get started, read Chapter 5 Workflow: pipes of R for Data Science (2ed) book.\n\n\n\n\nR Package for GeoVisualisation and Thematic Mapping\n\nTennekes, M. (2018) “tmap: Thematic Maps in R”, Journal of Statistical Software, Vol 84:6, 1-39.\ntmap: thematic maps in R package especially:\n\ntmap: get started!,\ntmap: version changes, and\nChapter 8 Making maps with R of Geocomputation with R."
  },
  {
    "objectID": "outline/Lesson01_outline.html#references",
    "href": "outline/Lesson01_outline.html#references",
    "title": "Lesson 1: Introduction to Geospatial Analytics",
    "section": "References",
    "text": "References\n\nGeospatial Analytics\n\nPaez, A., and Scott, D.M. (2004) “Spatial statistics for urban analysis: A review of techniques with examples”, GeoJournal, 61: 53-67. Available in SMU eLibrary.\n“Geospatial Analytics Will Eat The World, And You Won’t Even Know It”.\n\n\n\nGeoVisualisation and Thematic Mapping\n\nProportional Symbols\nChoropleth Maps\nThe Basics of Data Classification\nChoropleth Mapping with Exploratory Data Analysis\nThe Concept of Map Symbols\nChoropleth map\nChoropleth Maps – A Guide to Data Classification\nBivariate Choropleth\nValue-by-alpha maps\nWhat to consider when creating choropleth maps"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06.html#content",
    "href": "lesson/Lesson06/Lesson06.html#content",
    "title": "Lesson 6: Geographic Segmentation with Spatial Clustering",
    "section": "Content",
    "text": "Content\n\nIntroduction to Geographic Segmentation\nSpatialising classic clustering methods\nSpatially Constrained Clustering - Hierarchical methods\n\nskater\nREDCAP\nclustGeo\n\nSpatially Constrained Clustering - Partitioning methods\n\nAutomatic zoning procedure (AZP)\nmax-p heuristic"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06.html#regionalisation-and-clustering",
    "href": "lesson/Lesson06/Lesson06.html#regionalisation-and-clustering",
    "title": "Lesson 6: Geographic Segmentation with Spatial Clustering",
    "section": "Regionalisation and Clustering",
    "text": "Regionalisation and Clustering\n\n\n\nRegionalisation is a process of to group a large number of geographical units such as provinces, districts or counties spatial objects into a smaller number of subsets of objects also known as regions, which are internally homogeneous and occupy contiguous regions in space.\nThe process taking into consideration multivariates. Figure on the right shows regions delineated by using six ICT measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home of Shan State, Myanmar."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06.html#spatially-constrained-clustering-versus-non-spatially-constrained-clustering",
    "href": "lesson/Lesson06/Lesson06.html#spatially-constrained-clustering-versus-non-spatially-constrained-clustering",
    "title": "Lesson 6: Geographic Segmentation with Spatial Clustering",
    "section": "Spatially Constrained Clustering versus Non-spatially Constrained Clustering",
    "text": "Spatially Constrained Clustering versus Non-spatially Constrained Clustering\n\n\nA comparison of conventional non-spatially constrained clustering and spatially constrained clustering. Stars represent the centroids of sampled grid cells and polygons are Thiessen polygons that contain the centroids. Grey shading contrasts between polygons stand for the Simpson dissimilarity index (βsim) between them. Non-spatially constrained clustering produces two clusters, one of which contains polygons (C, D, and E) that are spatially disjoint. In contrast, the two clusters produced by the spatially constrained clustering form two spatially contiguous regions."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06.html#spatially-constrained-clustering",
    "href": "lesson/Lesson06/Lesson06.html#spatially-constrained-clustering",
    "title": "Lesson 6: Geographic Segmentation with Spatial Clustering",
    "section": "Spatially Constrained Clustering",
    "text": "Spatially Constrained Clustering\n\nSKATER (Spatial ’K’luster Analysis by Tree Edge Removal) algorithm\nREDCAP (Regionalization with dynamically constrained agglomerative clustering and partitioning algorithm\nClustGeo algorithm"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06.html#skater-spatial-kluster-analysis-by-tree-edge-removal-algorithm",
    "href": "lesson/Lesson06/Lesson06.html#skater-spatial-kluster-analysis-by-tree-edge-removal-algorithm",
    "title": "Lesson 6: Geographic Segmentation with Spatial Clustering",
    "section": "SKATER (Spatial ’K’luster Analysis by Tree Edge Removal) algorithm",
    "text": "SKATER (Spatial ’K’luster Analysis by Tree Edge Removal) algorithm\n\n\nThe SKATER (Spatial ’K’luster Analysis by Tree Edge Removal) builds off of a connectivity graph to represent spatial relationships between neighbouring areas, where each area is represented by a node and edges represent connections between areas. Edge costs are calculated by evaluating the dissimilarity between neighbouring areas. The connectivity graph is reduced by pruning edges with higher dissimilarity until we are left with n nodes and n−1 edges. At this point any further pruning would create subgraphs and these subgraphs become cluster candidates."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06.html#redcap-algorithm",
    "href": "lesson/Lesson06/Lesson06.html#redcap-algorithm",
    "title": "Lesson 6: Geographic Segmentation with Spatial Clustering",
    "section": "REDCAP algorithm",
    "text": "REDCAP algorithm\n\nRegionalization with dynamically constrained agglomerative clustering and partitioning, in short REDCAP is specially developed by D. Guo (2008) to the limitation of SKATER discussed in previous slide.\nLike SKATER, REDCAP starts from building a spanning tree with 4 different ways (single-linkage, average-linkage, ward-linkage and the complete-linkage). The single-linkage way leads to build a minimum spanning tree. Then,REDCAP provides 2 different ways (first-order and full-order constraining) to prune the tree to find clusters. The first-order approach with a minimum spanning tree is exactly the same with SKATER."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06.html#clustgeo-package",
    "href": "lesson/Lesson06/Lesson06.html#clustgeo-package",
    "title": "Lesson 6: Geographic Segmentation with Spatial Clustering",
    "section": "ClustGeo Package",
    "text": "ClustGeo Package\nThe R package ClustGeo implements a Ward-like hierarchical clustering algorithm including spatial/geographical constraints.\n\nTwo dissimilarity matrices D0 and D1 are inputted, along with a mixing parameter alpha in [0,1]. The dissimilarities can be non-Euclidean and the weights of the observations can be non-uniform.\nThe first matrix gives the dissimilarities in the “feature space”” and the second matrix gives the dissimilarities in the “constraint space”.\nThe criterion minimized at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1. The idea is to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest i.e. those of the feature space."
  },
  {
    "objectID": "lesson/Lesson04/Lesson04-Spatial_Weights.html#what-is-geographically-referenced-attribute",
    "href": "lesson/Lesson04/Lesson04-Spatial_Weights.html#what-is-geographically-referenced-attribute",
    "title": "Lesson 4: Spatial Weights and Applications",
    "section": "What is geographically referenced attribute?",
    "text": "What is geographically referenced attribute?\n\n\nRows: 323\nColumns: 12\n$ SUBZONE_N        &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERS…\n$ SUBZONE_C        &lt;fct&gt; MSSZ01, OTSZ01, SRSZ03, BMSZ08, BMSZ03, BMSZ07, BMSZ0…\n$ PLN_AREA_N       &lt;fct&gt; MARINA SOUTH, OUTRAM, SINGAPORE RIVER, BUKIT MERAH, B…\n$ PLN_AREA_C       &lt;fct&gt; MS, OT, SR, BM, BM, BM, BM, SR, QT, QT, QT, BM, ME, R…\n$ REGION_N         &lt;fct&gt; CENTRAL REGION, CENTRAL REGION, CENTRAL REGION, CENTR…\n$ REGION_C         &lt;fct&gt; CR, CR, CR, CR, CR, CR, CR, CR, CR, CR, CR, CR, CR, C…\n$ YOUNG            &lt;dbl&gt; NA, 1100, 0, 2620, 2840, 2910, 2850, 0, 1120, 30, NA,…\n$ `ECONOMY ACTIVE` &lt;dbl&gt; NA, 3420, 50, 7500, 6260, 7560, 8340, 50, 2750, 210, …\n$ AGED             &lt;dbl&gt; NA, 2110, 20, 3260, 1630, 3310, 3590, 10, 560, 50, NA…\n$ TOTAL            &lt;dbl&gt; NA, 6630, 70, 13380, 10730, 13780, 14780, 60, 4430, 2…\n$ DEPENDENCY       &lt;dbl&gt; NA, 0.9385965, 0.4000000, 0.7840000, 0.7140575, 0.822…\n$ geometry         &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOL…\n\n\n\nA kind of data that is very similar to an ordinary data. The only difference is that each observation is associated with some form of geography such as numbers of aged population by planning subzone."
  },
  {
    "objectID": "lesson/Lesson04/Lesson04-Spatial_Weights.html#what-are-spatial-weights-wij",
    "href": "lesson/Lesson04/Lesson04-Spatial_Weights.html#what-are-spatial-weights-wij",
    "title": "Lesson 4: Spatial Weights and Applications",
    "section": "What are Spatial Weights (wij)",
    "text": "What are Spatial Weights (wij)\n\nA way to define spatial neighbourhood.\n\n\n\nBefore we can perform statistics test of spatial randomness, we need to understand how spatial relationship among geographical areas can be defined mathematically."
  },
  {
    "objectID": "lesson/Lesson04/Lesson04-Spatial_Weights.html#applications-of-spatial-weights",
    "href": "lesson/Lesson04/Lesson04-Spatial_Weights.html#applications-of-spatial-weights",
    "title": "Lesson 4: Spatial Weights and Applications",
    "section": "Applications of Spatial Weights",
    "text": "Applications of Spatial Weights\nFormally, for observation i, the spatial lag of yi, referred to as [Wy]i (the variable Wy observed for location i) is:\n\nwhere the weights wij consist of the elements of the i-th row of the matrix W, matched up with the corresponding elements of the vector y.\n\nWith a neighbor structure defined by the non-zero elements of the spatial weights matrix W, a spatially lagged variable is a weighted sum or a weighted average of the neighboring values for that variable. In most commonly used notation, the spatial lag of y is then expressed as Wy."
  },
  {
    "objectID": "lesson/Lesson04/Lesson04-Spatial_Weights.html#references",
    "href": "lesson/Lesson04/Lesson04-Spatial_Weights.html#references",
    "title": "Lesson 4: Spatial Weights and Applications",
    "section": "References",
    "text": "References\n\nChapter 2. Codifying the neighbourhood structure of Handbook of Spatial Analysis: Theory and Application with R.\nFrançois Bavaud (2010) “Models for Spatial Weights: A Systematic Look” Geographical Analysis, Vol. 30, No.2, pp 153-171.\nTony H. Grubesic and Andrea L. Rosso (2014) “The Use of Spatially Lagged Explanatory Variables for Modeling Neighborhood Amenities and Mobility in Older Adults”, Cityscape, Vol. 16, No. 2, pp. 205-214."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#content",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#content",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Content",
    "text": "Content\n\n\n\nIntroducing Spatial Point Patterns\n\nThe basic concepts of spatial point patterns\n1st Order versus 2nd Order\nSpatial Point Patterns in real world\n\n1st Order Spatial Point Patterns Analysis\n\nQuadrat analysis\nKernel density estimation\n\n\n\n\n2nd Order Spatial Point Patterns Analysis\n\nNearest Neighbour Index\nG-function\nF-function\nK-function\nL-function\n\n\n\n\nWelcome to Lesson 4: Spatial Point Pattern Analysis, a family of spatial statistics specially developed to model and to test distribution of spatial point events.\nThe lesson proceeding is divided into three main section. First, I will share with you what are real world spatial point events. This is followed by explaining the concepts and methods of 1st-order and 2nd-order spatial point patterns analysis."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#what-is-spatial-point-patterns",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#what-is-spatial-point-patterns",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "What is Spatial Point Patterns",
    "text": "What is Spatial Point Patterns\n\nPoints as Events\nMapped pattern\n\nNot a sample\nSelection bias\n\nEvents are mapped, but non-events are not"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#real-world-question",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#real-world-question",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Real World Question",
    "text": "Real World Question\n\nLocation only\n\nare points randomly located or patterned\n\nLocation and value\n\nmarked point pattern\nis combination of location and value random or patterned\n\nWhat is the underlying process?\n\n\nIt is important note that SPPA is exploratory and confirmatory in nature. They are specially developed for describing the spatial point pattern and for confirming the observed patterns statistically. However, they are explanatory nor for prediction."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#points-on-a-plane",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#points-on-a-plane",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Points on a Plane",
    "text": "Points on a Plane\n\nClassic point pattern analysis\n\npoints on an isotropic plane\nno effect of translation and rotation\nclassic examples: tree seedlings, rocks, etc\n\nDistance\n\nstraight line only"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#spatial-point-patterns-analysis",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#spatial-point-patterns-analysis",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Spatial Point Patterns Analysis",
    "text": "Spatial Point Patterns Analysis\n\nPoint pattern analysis (PPA) is the study of the spatial arrangements of points in (usually 2-dimensional) space.\nThe simplest formulation is a set X = {x ∈ D} where D, which can be called the study region, is a subset of Rn, a n-dimensional Euclidean space.\nA fundamental problem of PPA is inferring whether a given arrangement is merely random or the result of some process."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#homogeneous-spatial-point-patterns",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#homogeneous-spatial-point-patterns",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Homogeneous Spatial Point Patterns",
    "text": "Homogeneous Spatial Point Patterns\n\n\nA homogeneous spatial point pattern assumes that the points are distributed uniformly across the study area. The intensity (expected number of points per unit area) is constant throughout the region.\n\n\nCharacteristics:\n\nThe probability of observing a point is the same across the entire space.\nThe process generating the points does not depend on location.\nThe points are randomly and independently distributed across the space, leading to a uniform density.\n\nModel:\n\nTypically modeled by a Homogeneous Poisson Process, where the intensity λ (the number of points per unit area) is constant."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#heterogeneous-spatial-point-patterns",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#heterogeneous-spatial-point-patterns",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Heterogeneous Spatial Point Patterns",
    "text": "Heterogeneous Spatial Point Patterns\n\n\nA heterogeneous spatial point pattern assumes that the intensity of points varies across the study area. The intensity function is not constant and may depend on spatial covariates, leading to non-uniform distribution.\n\n\nCharacteristics:\n\nThe probability of observing a point varies across the space, often depending on underlying factors like geography, environmental conditions, or other spatial variables.\nThe density of points can be higher in some regions and lower in others, leading to clusters or dispersed patterns.\n\nModel: - Modeled by an Inhomogeneous Poisson Process (IPP), where the intensity function λ(x,y) varies with location. The intensity can be a function of spatial covariates or other influences."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#spatial-point-patterns-analysis-techniques",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#spatial-point-patterns-analysis-techniques",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Spatial Point Patterns Analysis Techniques",
    "text": "Spatial Point Patterns Analysis Techniques\n\nFirst-order vs Second-order Analysis of spatial point patterns.\n\n\nReference: 11.4 First and second order effects of Intro to GIS and Spatial Analysis\n\nThe first-order properties describe the way in which the expected value (mean or average) of the spatial point pattern varies across space (i.e., the intensity of the spatial point pattern). Such properties are usually measured with the so-called quadrat analysis, nearest neighbour index and kernel estimation. Second-order properties describe the covariance (or correlation) between values of the spatial point pattern at different regions in space and are usually measured with the G function, K function and L function. Applied to point event data, both properties could be used to explore the spatial variation in the risk of being victimized by a crime, spatial and space-time clustering of criminal activities, and the raised incidence of criminal activities around point sources, such as robberies around ATM machines, subway entrances and exits, etc."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#kernel-density-estimation-silverman-1986",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#kernel-density-estimation-silverman-1986",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Kernel density estimation (Silverman 1986)",
    "text": "Kernel density estimation (Silverman 1986)\n\nA method to compute the intensity of a point distribution.\n\n\n\nThe general formula:\n\n\nGraphically"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#distance-based-nearest-neighbour-index",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#distance-based-nearest-neighbour-index",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Distance-based: Nearest Neighbour Index",
    "text": "Distance-based: Nearest Neighbour Index\nWhat is Nearest Neighbour?\nDirect distance from a point to its nearest neighbour."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#nearest-neighbour-index",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#nearest-neighbour-index",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Nearest Neighbour Index",
    "text": "Nearest Neighbour Index\nThe Nearest Neighbour Index is expressed as the ratio of the Observed Mean Distance to the Expected Mean Distance."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#g-function",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#g-function",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "G function",
    "text": "G function\n\n\nThe formula"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#f-function",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#f-function",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "F function",
    "text": "F function\n\nSelect a sample of point locations anywhere in the study region at random\n\nDetermine minimum distance from each point to any event in the study area.\n\nThree steps:\n\nRandomly select m points (p1, p2, ….., pn),\nCalculate dmin(pi,s) as the minimum distance from location pi to any event in the point patterns, and\nCalculate F(d)."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#ripleys-k-function-ripley-1981",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#ripleys-k-function-ripley-1981",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Ripley’s K function (Ripley, 1981)",
    "text": "Ripley’s K function (Ripley, 1981)\n\nLimitation of nearest neighbor distance method is that it uses only nearest distance\nConsiders only the shortest scales of variation.\nK function uses more points.\n\nProvides an estimate of spatial dependence over a wider range of scales.\nBased on all the distances between events in the study area.\nAssumes isotropy over the region."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#the-l-function-besag-1977",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#the-l-function-besag-1977",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "The L function (Besag 1977)",
    "text": "The L function (Besag 1977)\n\n\nIn practice, K function will be normalised to obtained a benchmark of zero.\nThe formula:"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-SPPA.html#references",
    "href": "lesson/Lesson02/Lesson02-SPPA.html#references",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "References",
    "text": "References\n\nChapter 11 Point Pattern Analysis of Intro to GIS and Spatial Analysis. Section 11.2, 11.3, 11.3.1 and 11.4\nGIS&T Body of Knowledge AM-07-Point Pattern Analysis\nGIS&T Body of Knowledge AM-08-Kernels and Density Estimation\nAnalyzing Patterns in Business Point Data, Directions Magazine March 17, 2005.\nO’Sullivan, D., and Unwin, D. (2010) Geographic Information Analysis, Second Edition. John Wiley & Sons Inc., New Jersey, Canada. Chapter 5-6.\nBaddeley A., Rubak E. and Turner R. (2015) Spatial Point Patterns: Methodology and Applications with R, Chapman and Hall/CRC."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#content",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#content",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Content",
    "text": "Content\n\nIntroducing maps\nTypology of maps\n\nReference maps\nThematic maps\n\nProportional Symbol Map\nChoropleth Mapping\nIntroduction to tmap Methods\n\n\nThis lesson consists of two parts. First, I will share with you the concepts and design principles of choropleth maps. Next, I will introduce you to tmap, an R package specially designed for thematic mapping based on Layered Grammar of Graphics"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#what-is-a-map",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#what-is-a-map",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "What is a Map?",
    "text": "What is a Map?\nA model of real world depict by a collection of cartographic symbols or/and visual abstraction."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#typology-of-maps",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#typology-of-maps",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Typology of Maps",
    "text": "Typology of Maps"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#thematic-mapping-principles-and-methods",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#thematic-mapping-principles-and-methods",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Thematic Mapping: Principles and Methods",
    "text": "Thematic Mapping: Principles and Methods\n\nDisplaying\n\nQualitative data\nQuantitative data\n\nChoosing -Appropriate classification method for displaying data\n\nAppropriate number of classes\n\nTechniques in data analysis\n\nUsing the classification histogram\nNormalizing data"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#qualitative-thematic-maps",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#qualitative-thematic-maps",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Qualitative Thematic Maps",
    "text": "Qualitative Thematic Maps\nVisual Variables and Cartographic Symbols\n\n\n\nQualitative visual variables are used for nominal scale data.\nThe goal of qualitative visual variables is to show how entities differ from each other.\nThe visual variables that do a good job of showing ordinal differences are: colour value, colour saturation, size and texture/grain.\n\nFigure on the right for examples of these four ordinal visual variables used each in point, linear and areal symbols."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#qualitative-thematic-map",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#qualitative-thematic-map",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Qualitative Thematic Map",
    "text": "Qualitative Thematic Map\nPoint symbol map\n\n\n\nDifferent point symbols are used to represent school types."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#qualitative-thematic-map-1",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#qualitative-thematic-map-1",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Qualitative Thematic Map",
    "text": "Qualitative Thematic Map\nLine symbol map\n\n\n\nA road map is an example of a thematic map. It shows the road network of an area. In this map, lines with different colour intensity and tickness are used to differentiate hierarchy of roads."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#qualitative-thematic-map-2",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#qualitative-thematic-map-2",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Qualitative Thematic Map",
    "text": "Qualitative Thematic Map\nArea map\n\n\n\nLand use map below is a good example of a discrete thematic map. In this map, different colours are use to represent different land use types."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#quantitative-thematic-map",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#quantitative-thematic-map",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Quantitative Thematic Map",
    "text": "Quantitative Thematic Map\nVisual Variables and Cartographic Symbols\n\n\n\nQuantitative visual variables are used to display ordinal, interval or ratio scale data.\n\nThe goal of the quantitative visual variable is to show relative magnitude or order between entities.\nThe visual variables that do a good job of showing ordinal differences are: colour value, colour saturation, size and texture/grain.\n\nFigure on the right shows of these four ordinal visual variables used each in point, linear and areal symbols."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#proportional-symbol-map",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#proportional-symbol-map",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Proportional Symbol Map",
    "text": "Proportional Symbol Map\n\nThe proportional symbol technique uses symbols of different sizes to represent data associated with different areas or locations within the map.\n\n\n\nThe proportional symbol technique uses symbols of different sizes to represent data associated with different areas or locations within the map. For example, the proportional maps above use circle with different sizes to represent millions of people. There are two types of point features that are typically depicted with proportional symbols: features for which the data represents a geographic position directly (e.g., gallons of oil from individual oil wells), and features that are geographic areas to which data are aggregated and the data magnitudes are assigned to a representative point within the area (e.g., the geographic centroid of a state as in the examples above). In either case, the area of the symbol is scaled to represent the data magnitude, sometimes with a bit of exaggeration to adjust for a general tendency of human vision to underestimate differences in area. A variant on this direct data-to-symbol scaling groups values into categories first, then scales the symbol to represent the mean for the category, assigning a symbol to each place to represent the category range that the mean for the place falls within"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#dot-density-map",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#dot-density-map",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Dot Density Map",
    "text": "Dot Density Map\nA dot-density map is a type of thematic map that uses dots or other symbols on the map to show the values of one or more numeric data fields. Each dot on a dot-density map represents some amount of data.\n\n\nOne dot represent 100 households.\n\n\nReference: Dot distribution map at wiki and Dot Density Maps"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#choropleth-map",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#choropleth-map",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Choropleth Map",
    "text": "Choropleth Map\nA choropleth map is a type of thematic map in which areas are shaded or patterned in proportion to a statistical variable that represents an aggregate summary of a geographic characteristic within each area, such as population or per-capita income."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#data-classification",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#data-classification",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Data classification",
    "text": "Data classification\n\n\nNot sure how many classes to use? Have a look at the distribution of your data in a histogram (see examples below): Are there obvious clusters within your data? Are there large gaps in your data range that suggest nice compact data classes? If so, pick that number of classes and place those class breaks around those clusters."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#colour-scheme",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#colour-scheme",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Colour scheme",
    "text": "Colour scheme\nColorBrewer"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#mapping-packages-in-r",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#mapping-packages-in-r",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Mapping packages in R",
    "text": "Mapping packages in R\n\n\nSelected popular mapping packages\nCRAN Task View: Analysis of Spatial Data\n\ntmap\nmapsf\nleaflet\nggplot2. Read Chapter 6: Maps of ‘ggplot2: Elegant Graphics for Data Analysis’ for more detail.\nggmap\nquickmapr\nmapview\n\n\nOther packages\n\nRColorBrewer\nclassInt"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#introducing-tmap",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#introducing-tmap",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Introducing tmap",
    "text": "Introducing tmap\n\n\n\ntmap is a R package specially designed for creating thematic maps using the pricinples of the Grammar of Graphics.\nIt offers a flexible, layer-based, and easy to use approach to create thematic maps, such as choropleths and proportional symbol maps.\nIt supports two modes: plot(static maps) and view (interactive maps).\nIt provides shiny integration(with tmapOutput and renderTmap)."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#tmap-elements",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#tmap-elements",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "tmap elements",
    "text": "tmap elements\ntm_shape()\n\nThe first element to start with is tm_shape(), which specifies the shape object."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#tmap-elements-1",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#tmap-elements-1",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "tmap elements",
    "text": "tmap elements\nBase layers\n\nNext, one, or a combination of the following drawing layers should be specified:\n\n\n\nLinks to tm_polygons(), tm_symbols(), tm_lines(), tm_raster() and tm_text()"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#tmap-elements-2",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#tmap-elements-2",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "tmap elements",
    "text": "tmap elements\nBase layers\n\nEach of these functions specifies the geometry, mapping, and scaling component of the LGTM.\nAn aesthetic can take a constant value, a data variable name, or a vector consisting of values or variable names.\nIf a data variable is provided, the scale is automatically configured according to the values of this variable, but can be adjusted with several arguments. For instance, the main scaling arguments for a color aesthetic are color palette, the preferred number of classes, and a style to create classes.\nAlso, for each aesthetic, except for the text labels, a legend is automatically created.\nIf a vector of variable names is provided, small multiples are created, which will be explained further below."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#tmap-elements-3",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#tmap-elements-3",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "tmap elements",
    "text": "tmap elements\nDerived layers\n\n\nEach aesthetic can take a constant value or a data variable name. For instance, tm_fill(col=\"blue\") colors all polygons blue, while tm_fill(col=\"var1\"), where “var1” is the name of a data variable in the shape object, creates a choropleth.\n\nThe supported derived layers are as follows:"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#data-classification-methods-of-tmap",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#data-classification-methods-of-tmap",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Data classification methods of tmap",
    "text": "Data classification methods of tmap\n\n\nMost choropleth maps employ some method of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\n\n\n\n\n\n\nNote\n\n\n\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\nThe choropleth map on the right shows a quantile data classification with 8 classes are used.\n\n\n\n\n\n\n\ntm_shape(mpszpop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 8,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#colour-scheme-1",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#colour-scheme-1",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Colour Scheme",
    "text": "Colour Scheme\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\n\n\n\n\nNote\n\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill().\nNotice that the word blues is used instead of blue and the alphabet b is in uppercase.\n\n\n\n\n\n\n\ntm_shape(mpszpop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#reference",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#reference",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "Reference",
    "text": "Reference\nPrinciples, Concepts and Methods of Choropleth Maps Design\nCore Reading\n\nChoropleth Maps\nThe Basics of Data Classification\n\nAdditional Readings\n\nChoropleth Maps – A Guide to Data Classification\nBivariate Choropleth\nValue-by-alpha maps\nWhat to consider when creating choropleth maps\nChoropleth Mapping with Exploratory Data Analysis"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-GeoVis.html#references",
    "href": "lesson/Lesson01/Lesson01-GeoVis.html#references",
    "title": "Lesson 1: Fundamental of Geospatial Data Visualisation and tmap Methods",
    "section": "References",
    "text": "References\nAll About tmap package\n\ntmap: Thematic Maps in R\nDevelopment site\ntmap Reference\ntmap: get started!\ntmap: version changes\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS626 AY2024-25 October Term",
    "section": "",
    "text": "In this web site, you will find all course materials here.\nInstructor: Dr. Kam Tin Seong, Associate Professor of Information Systems (Practice)\nDate & Time: Monday 19:00 - 22:15\nVenue: SOE/SCIS2 Seminar Room 2-10\nPiazza link.\nConsultation booking link.\nVirtual Meeting Room: Zoom\n\n\nFor the next 10 weeks, your learning journey will be very bumpy, especially come to R programming.\n\nLearning R can be difficult at first—it’s like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you’ll be using like ggplot2 — made this wise observation:\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\nEven experienced programmers find themselves bashing their heads against seemingly intractable errors.\n\nIf you’re finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, and don’t hesitate to approach me.\nThe students who have a bad time in this course are the ones who don’t work with one another to learn. We are a learning community, and we should help each other to learn.\nIf you understand something and someone is struggling with it, try and help them. If you are struggling, take a breath, and try to pinpoint what you are struggling with.\nOur goal is to be better programmers each day, not to be the perfect programmer. There’s no such thing as a perfect programmer. I’ve been learning new things almost every day.\nI promise you can succeed in this class as long as you are willing to learn, practice, be open minded and don’t give up easily.\n\n\n\n\n\n\nAll acts of academic dishonesty (including, but not limited to, plagiarism, cheating, fabrication, facilitation of acts of academic dishonesty by others, unauthorized possession of exam questions, or tampering with the academic work of other students) are serious offences. All work (whether oral or written) submitted for purposes of assessment must be the student’s own work. Penalties for violation of the policy range from zero marks for the component assessment to expulsion, depending on the nature of the offense. When in doubt, students should consult the instructors of the course. Details on the SMU Code of Academic Integrity may be accessed at http://www.smuscd.org/resources.html\n\n\n\nCourse materials obtained during your course of study at SMU are meant for personal use only, namely, for the purposes of studying and research. You are strictly not permitted to make copies of or print additional copies or distribute such copies of the course materials or any parts thereof, for commercial gain or exchange. For example, offering such materials on the Internet through CourseHero, Carousell and the like, is strictly prohibited.\nThe selling of these materials and/or any copies thereof are strictly prohibited under Singapore copyright laws. Printed materials and electronic materials are both protected by copyright laws. All students are subject to Singapore copyright laws and must strictly adhere to SMU’s procedures and requirements relating to copyright.\nPlease also note that for some materials, the publishers may specifically state that each copy is for the personal use of one individual only and no further reprographic reproduction is allowed, including for personal use. These restrictions are spelt out clearly on these specific sets of resources and students are required to adhere to these rules.\nStudents who infringe any of the aforesaid rules, laws and requirements shall be liable to disciplinary action by SMU. In addition, such students may also leave themselves open to suits by copyright owners who are entitled to take legal action against persons who infringe their copyright.\nWe strongly urge all students to respect the copyright laws and abide by SMU’s procedures and requirements relating to copyright.\n\n\n\nSMU strives to make learning experiences accessible for all. If you anticipate or experience physical or academic barriers due to disability, please let the instructor know immediately. You are also welcome to contact the university’s disability support team if you have questions or concerns about academic accommodations:included@smu.edu.sg\nPlease be aware that the accessible tables in our seminar room should remain available for students who require them. Emergency\n\n\n\nAs part of emergency preparedness, Instructors may conduct lessons online via the WebEx platform during the term, to prepare students for online learning. During an actual emergency, students will be notified to access the WebEx platform for their online lessons. The class schedule will mirror the current face-to-face class timetable unless otherwise stated."
  },
  {
    "objectID": "index.html#words-of-encouragement",
    "href": "index.html#words-of-encouragement",
    "title": "ISSS626 AY2024-25 October Term",
    "section": "",
    "text": "For the next 10 weeks, your learning journey will be very bumpy, especially come to R programming.\n\nLearning R can be difficult at first—it’s like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you’ll be using like ggplot2 — made this wise observation:\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\nEven experienced programmers find themselves bashing their heads against seemingly intractable errors.\n\nIf you’re finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, and don’t hesitate to approach me.\nThe students who have a bad time in this course are the ones who don’t work with one another to learn. We are a learning community, and we should help each other to learn.\nIf you understand something and someone is struggling with it, try and help them. If you are struggling, take a breath, and try to pinpoint what you are struggling with.\nOur goal is to be better programmers each day, not to be the perfect programmer. There’s no such thing as a perfect programmer. I’ve been learning new things almost every day.\nI promise you can succeed in this class as long as you are willing to learn, practice, be open minded and don’t give up easily."
  },
  {
    "objectID": "index.html#other-important-information",
    "href": "index.html#other-important-information",
    "title": "ISSS626 AY2024-25 October Term",
    "section": "",
    "text": "All acts of academic dishonesty (including, but not limited to, plagiarism, cheating, fabrication, facilitation of acts of academic dishonesty by others, unauthorized possession of exam questions, or tampering with the academic work of other students) are serious offences. All work (whether oral or written) submitted for purposes of assessment must be the student’s own work. Penalties for violation of the policy range from zero marks for the component assessment to expulsion, depending on the nature of the offense. When in doubt, students should consult the instructors of the course. Details on the SMU Code of Academic Integrity may be accessed at http://www.smuscd.org/resources.html\n\n\n\nCourse materials obtained during your course of study at SMU are meant for personal use only, namely, for the purposes of studying and research. You are strictly not permitted to make copies of or print additional copies or distribute such copies of the course materials or any parts thereof, for commercial gain or exchange. For example, offering such materials on the Internet through CourseHero, Carousell and the like, is strictly prohibited.\nThe selling of these materials and/or any copies thereof are strictly prohibited under Singapore copyright laws. Printed materials and electronic materials are both protected by copyright laws. All students are subject to Singapore copyright laws and must strictly adhere to SMU’s procedures and requirements relating to copyright.\nPlease also note that for some materials, the publishers may specifically state that each copy is for the personal use of one individual only and no further reprographic reproduction is allowed, including for personal use. These restrictions are spelt out clearly on these specific sets of resources and students are required to adhere to these rules.\nStudents who infringe any of the aforesaid rules, laws and requirements shall be liable to disciplinary action by SMU. In addition, such students may also leave themselves open to suits by copyright owners who are entitled to take legal action against persons who infringe their copyright.\nWe strongly urge all students to respect the copyright laws and abide by SMU’s procedures and requirements relating to copyright.\n\n\n\nSMU strives to make learning experiences accessible for all. If you anticipate or experience physical or academic barriers due to disability, please let the instructor know immediately. You are also welcome to contact the university’s disability support team if you have questions or concerns about academic accommodations:included@smu.edu.sg\nPlease be aware that the accessible tables in our seminar room should remain available for students who require them. Emergency\n\n\n\nAs part of emergency preparedness, Instructors may conduct lessons online via the WebEx platform during the term, to prepare students for online learning. During an actual emergency, students will be notified to access the WebEx platform for their online lessons. The class schedule will mirror the current face-to-face class timetable unless otherwise stated."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#overview",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#overview",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "Overview",
    "text": "Overview\n\n\n\nEmerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\nCategorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin.\n\n\n\n\n\n\n\nImportant\n\n\nIt is highly recommended to read Emerging Hot Spot Analysis before you continue the exercise."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#getting-started",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#getting-started",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "Getting started",
    "text": "Getting started\nInstalling and Loading the R Packages\n\n\nAs usual, p_load() of pacman package will be used to check if the necessary packages have been installed in R, if yes, load the packages on R environment.\nFive R packages are need for this in-class exercise, they are: sf, sfdep, tmap, plotly, and tidyverse.\n\n\npacman::p_load(sf, sfdep, tmap, \n               plotly, tidyverse, \n               Kendall)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#the-data",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "The Data",
    "text": "The Data\n\n\nFor the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\nHunan, a geospatial data set in ESRI shapefile format, and\nHunan_GDPPC, an attribute data set in csv format.\n\nBefore getting started, reveal the content of Hunan_GDPPC.csv by using Notepad and MS Excel."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#creating-a-time-series-cube",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#creating-a-time-series-cube",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "Creating a Time Series Cube",
    "text": "Creating a Time Series Cube\nBefore getting started, students must read this article to learn the basic concept of spatio-temporal cube and its implementation in sfdep package.\nIn the code chunk below, spacetime() of sfdep ised used to create an spatio-temporal cube.\n\n\nGDPPC_st &lt;- spacetime(GDPPC, hunan,\n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\n\n\nNext, is_spacetime_cube() of sfdep package will be used to verify if GDPPC_st is indeed an space-time cube object.\n\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE\n\n\n\nThe TRUE return confirms that GDPPC_st object is indeed an time-space cube."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#computing-gi",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#computing-gi",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "Computing Gi*",
    "text": "Computing Gi*\nNext, we will compute the local Gi* statistics.\nDeriving the spatial weights\n\n\nThe code chunk below will be used to identify neighbors and to derive an inverse distance weights.\n\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wt = st_inverse_distance(nb, \n                             geometry, \n                             scale = 1,\n                             alpha = 1),\n    .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nactivate() of dplyr package is used to activate the geometry context\nmutate() of dplyr package is used to create two new columns nb and wt.\nThen we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()\n\nrow order is very important so do not rearrange the observations after using set_nbs() or set_wts().\n\n\n\n\n\n\nNote that this dataset now has neighbors and weights for each time-slice."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#computing-gi-1",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#computing-gi-1",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "Computing Gi*",
    "text": "Computing Gi*\n\n\nWe can use these new columns to manually calculate the local Gi* for each location. We can do this by grouping by Year and using local_gstar_perm() of sfdep package. After which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.\n\n\ngi_stars &lt;- GDPPC_nb %&gt;% \n  group_by(Year) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#mann-kendall-test",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#mann-kendall-test",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "Mann-Kendall Test",
    "text": "Mann-Kendall Test\nA monotonic series or function is one that only increases (or decreases) and never changes direction. So long as the function either stays flat or continues to increase, it is monotonic.\nH0: No monotonic trend\nH1: Monotonic trend is present\nInterpretation\n\nReject the null-hypothesis null if the p-value is smaller than the alpha value (i.e. 1-confident level)\nTau ranges between -1 and 1 where:\n\n-1 is a perfectly decreasing series, and\n1 is a perfectly increasing series.\n\n\n\n\n\n\n\n\nImportant\n\n\nYou are encouraged to read Mann-Kendall Test For Monotonic Trend to learn more about the concepts and method of Mann-Kendall test.."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#performing-emerging-hotspot-analysis",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-EHSA.html#performing-emerging-hotspot-analysis",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis",
    "section": "Performing Emerging Hotspot Analysis",
    "text": "Performing Emerging Hotspot Analysis\n\n\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object x (i.e. GDPPC_st), and the quoted name of the variable of interest (i.e. GDPPC) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\n\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st, \n  .var = \"GDPPC\", \n  k = 1, \n  nsim = 99\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#loading-the-package",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#loading-the-package",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Loading the package",
    "text": "Loading the package\nIn this in-class exercise, sf, spdep, tmap, tidyverse, knitr and GWmodel will be used.\n\nDIYThe code\n\n\nUsing the step you leanred from previous hands-in, install and load the necessary R packages in R environment.\n\n\n\n\npacman::p_load(sf, ggstatsplot, tmap, tidyverse, knitr, GWmodel)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#preparing-the-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#preparing-the-data",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Preparing the Data",
    "text": "Preparing the Data\nFor this in-class exercise, Hunan shapefile and Hunan_2012 data file will be used.\n\nDIYImporting Hunan shapefileImporting Hunan_2012 tableJoining Hunan and Hunan_2012\n\n\nUsing the steps you learned from previous hands-on, complete the following tasks:\n\nimport Hunan shapefile and parse it into a sf polygon feature object.\nimport Hunan_2012.csv file parse it into a tibble data.frame.\njoin Hunan and Hunan_2012 data.frames.\n\n\n\n\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\tskam\\ISSS626-AY2024-25Aug\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\n\nhunan_sf &lt;- left_join(hunan_sf, hunan2012) %&gt;%\n  select(1:3, 7, 15, 16, 31, 32)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#mapping-gdppc",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#mapping-gdppc",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Mapping GDPPC",
    "text": "Mapping GDPPC\n\nDIYThe code\n\n\nUsing the steps you learned from Hands-on Exercise 5, prepare a choropleth map showing the geographic distribution of GDPPC of Hunan Province.\n\n\n\n\n\n\n\n\n\n\n\n\n\nbasemap &lt;- tm_shape(hunan_sf) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan_sf, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-to-spatialpolygondataframe",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-to-spatialpolygondataframe",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Converting to SpatialPolygonDataFrame",
    "text": "Converting to SpatialPolygonDataFrame\n\n\n\n\n\n\nNote\n\n\nGWmodel presently is built around the older sp and not sf formats for handling spatial data in R.\n\n\n\n\n\nhunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Geographically Weighted Summary Statistics with adaptive bandwidth",
    "text": "Geographically Weighted Summary Statistics with adaptive bandwidth\nDetermine adaptive bandwidth\n\nCross-validationAIC\n\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach = \"CV\",\n             adaptive = TRUE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\nbw_CV\n\n[1] 22\n\n\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach =\"AIC\",\n             adaptive = TRUE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\nbw_AIC\n\n[1] 22"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth-1",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth-1",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Geographically Weighted Summary Statistics with adaptive bandwidth",
    "text": "Geographically Weighted Summary Statistics with adaptive bandwidth\nComputing geographically wieghted summary statistics\n\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth-2",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth-2",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Geographically Weighted Summary Statistics with adaptive bandwidth",
    "text": "Geographically Weighted Summary Statistics with adaptive bandwidth\nPreparing the output data\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame().\n\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data.frame.\n\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-geographically-weighted-summary-statistics",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-geographically-weighted-summary-statistics",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Visualising geographically weighted summary statistics",
    "text": "Visualising geographically weighted summary statistics\n\nThe Geographically Weighted MeanThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically wieghted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50, \n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Geographically Weighted Summary Statistics with fixed",
    "text": "Geographically Weighted Summary Statistics with fixed\nDetermine fixed bandwidth\n\nCross-validationAIC\n\n\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach = \"CV\",\n             adaptive = FALSE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\nbw_CV\n\n[1] 76.29126\n\n\n\n\n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1, \n             data = hunan_sp,\n             approach =\"AIC\",\n             adaptive = FALSE, \n             kernel = \"bisquare\", \n             longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\nbw_AIC\n\n[1] 160.5517"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-1",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-1",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Geographically Weighted Summary Statistics with fixed",
    "text": "Geographically Weighted Summary Statistics with fixed\nComputing adaptive bandwidth\n\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = FALSE,\n               longlat = T)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Geographically Weighted Summary Statistics with fixed bandwidth",
    "text": "Geographically Weighted Summary Statistics with fixed bandwidth\nPreparing the output data\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame().\n\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data.frame.\n\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-2",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-summary-statistics-with-fixed-2",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Geographically Weighted Summary Statistics with fixed",
    "text": "Geographically Weighted Summary Statistics with fixed\nVisualising geographically weighted summary statistics\n\nThe Geographically Weighted MeanThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically wieghted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50, \n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-correlation-with-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-correlation-with-adaptive-bandwidth",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Geographically Weighted Correlation with Adaptive Bandwidth",
    "text": "Geographically Weighted Correlation with Adaptive Bandwidth\nBusiness question: Is there any relationship between GDP per capita and Gross Industry Output?\n\nConventional statistical solutionThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = hunan2012, \n  x = Agri, \n  y = GDPPC,\n  xlab = \"Gross Agriculture Output\", ## label for the x-axis\n  ylab = \"GDP per capita\", \n  label.var = County, \n  label.expression = Agri &gt; 10000 & GDPPC &gt; 50000, \n  point.label.args = list(alpha = 0.7, size = 4, color = \"grey50\"),\n  xfill = \"#CC79A7\", \n  yfill = \"#009E73\", \n  title = \"Relationship between GDP PC and Gross Agriculture Output\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-correlation-with-adaptive-bandwidth-1",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#geographically-weighted-correlation-with-adaptive-bandwidth-1",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Geographically Weighted Correlation with Adaptive Bandwidth",
    "text": "Geographically Weighted Correlation with Adaptive Bandwidth\nGeospatial analytics solution\n\nDetermine the bandwidthComputing gwCorrelationExtracting the result\n\n\n\n\nbw &lt;- bw.gwr(GDPPC ~ GIO, \n             data = hunan_sp, \n             approach = \"AICc\", \n             adaptive = TRUE)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1870.235 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1870.852 \nAdaptive bandwidth (number of nearest neighbours): 72 AICc value: 1869.744 \nAdaptive bandwidth (number of nearest neighbours): 78 AICc value: 1869.713 \nAdaptive bandwidth (number of nearest neighbours): 82 AICc value: 1869.604 \nAdaptive bandwidth (number of nearest neighbours): 84 AICc value: 1869.537 \nAdaptive bandwidth (number of nearest neighbours): 86 AICc value: 1869.647 \nAdaptive bandwidth (number of nearest neighbours): 83 AICc value: 1869.567 \nAdaptive bandwidth (number of nearest neighbours): 84 AICc value: 1869.537 \n\n\n\n\n\n\n\ngwstats &lt;- gwss(hunan_sp, \n                vars = c(\"GDPPC\", \"GIO\"), \n                bw = bw,\n                kernel = \"bisquare\",\n                adaptive = TRUE, \n                longlat = T)\n\n\n\n\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame().\n\n\ngwstat_df &lt;- as.data.frame(gwstats$SDF) %&gt;%\n  select(c(12,13)) %&gt;%\n  rename(gwCorr = Corr_GDPPC.GIO,\n         gwSpearman = Spearman_rho_GDPPC.GIO)\n\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data.frame.\n\n\nhunan_Corr &lt;- cbind(hunan_sf, gwstat_df)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-local-correlation",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-local-correlation",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "Visualising Local Correlation",
    "text": "Visualising Local Correlation\n\nLocal Correlation CoefficientLocal Spearman CoefficientThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(hunan_Corr) +\n  tm_fill(\"gwSpearman\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Local Spearman Rho\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50, \n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#references",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#references",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - gwModel methods",
    "section": "References",
    "text": "References\nBrunsdon, C. et. al. (2002) “Geographically weighted summary statistics - a framework for localised exploratory data analysis”, Computer, Environment and Urban Systems, Vol 26, pp. 501-525. Available as e-journal, SMU library.\nHarris, P. & Brunsdon, C. (2010) “Exploring spatial variation and spatial relationships in freshwater acidification critical load data set for Great Britain using geographically weighted summary statistics”, Computers & Geosciences, Vol. 36, pp. 54-70. Available as e-journal, SMU library."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/data/rawdata/Punggol_Road.html",
    "href": "In-class_Ex/In-class_Ex03/data/rawdata/Punggol_Road.html",
    "title": "ISSS626 Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  GDM.RoadSectionLine  ENG dataset\n\nGDM.RoadSectionLine\n\nRoad Network lines with information on road names, road category and road code\nSafeguarding Road Reserve  Road Inventory, Road Furniture, Road Elements    mailing address\n\n251 North Bridge Road Singapore 179102\n\n  &lt;city&gt;&lt;/city&gt;\n  &lt;administrativearea&gt;&lt;/administrativearea&gt;\n  &lt;postalcode&gt;&lt;/postalcode&gt;\n  &lt;country&gt;&lt;/country&gt;\n&lt;/contactAddress&gt;\n&lt;name&gt;&lt;/name&gt;\n&lt;organization&gt;&lt;/organization&gt;\n&lt;position&gt;&lt;/position&gt;\n&lt;voice&gt;63328915&lt;/voice&gt;\n&lt;fax&gt;&lt;/fax&gt;\n&lt;email&gt;&lt;/email&gt;\n&lt;role&gt;Point of contact&lt;/role&gt;\n      on need basis The data is for internal use only      0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#issue-1-installing-maptools",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#issue-1-installing-maptools",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Issue 1: Installing maptools",
    "text": "Issue 1: Installing maptools\nmaptools is retired and binary is removed from CRAN. However, we can download from Posit Public Package Manager snapshots by using the code chunk below.\n\n\ninstall.packages(\"maptools\", \n                 repos = \"https://packagemanager.posit.co/cran/2023-10-13\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#issue-1-installing-maptools-1",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#issue-1-installing-maptools-1",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Issue 1: Installing maptools",
    "text": "Issue 1: Installing maptools\n\n\nAfter the installation is completed, it is important to edit the code chunk as shown below in order to avoid maptools being download and install repetitively every time the Quarto document been rendered."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#issue-2-creating-coastal-outline",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#issue-2-creating-coastal-outline",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Issue 2: Creating coastal outline",
    "text": "Issue 2: Creating coastal outline\nIn sf package, there are two functions allow us to combine multiple simple features into one simple features. They are st_combine() and st_union().\n\nst_combine() returns a single, combined geometry, with no resolved boundaries; returned geometries may well be invalid.\nIf y is missing, st_union(x) returns a single geometry with resolved boundaries, else the geometries for all unioned pairs of x[i] and y[j]."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#introducing-spatstat-package",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#introducing-spatstat-package",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Introducing spatstat package",
    "text": "Introducing spatstat package\nspatstat R package is a comprehensive open-source toolbox for analysing Spatial Point Patterns. Focused mainly on two-dimensional point patterns, including multitype or marked points, in any spatial region."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#spatstat",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#spatstat",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "spatstat",
    "text": "spatstat\nspatstat sub-packages\n\n\nThe spatstat package now contains only documentation and introductory material. It provides beginner’s introductions, vignettes, interactive demonstration scripts, and a few help files summarising the package.\nThe spatstat.data package now contains all the datasets for spatstat.\nThe spatstat.utils package contains basic utility functions for spatstat.\nThe spatstat.univar package contains functions for estimating and manipulating probability distributions of one-dimensional random variables.\nThe spatstat.sparse package contains functions for manipulating sparse arrays and performing linear algebra.\nThe spatstat.geom package contains definitions of spatial objects (such as point patterns, windows and pixel images) and code which performs geometrical operations.\nThe spatstat.random package contains functions for random generation of spatial patterns and random simulation of models.\nThe spatstat.explore package contains the code for exploratory data analysis and nonparametric analysis of spatial data.\nThe spatstat.model package contains the code for model-fitting, model diagnostics, and formal inference.\nThe spatstat.linnet package defines spatial data on a linear network, and performs geometrical operations and statistical analysis on such data."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#creating-ppp-objects-from-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#creating-ppp-objects-from-sf-data.frame",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Creating ppp objects from sf data.frame",
    "text": "Creating ppp objects from sf data.frame\nInstead of using the two steps approaches discussed in Hands-on Exercise 3 to create the ppp objects, in this section you will learn how to work with sf data.frame.\n\n\nIn the code chunk below, as.ppp() of spatstat.geom package is used to derive an ppp object layer directly from a sf tibble data.frame.\n\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\n\n\nNext, summary() can be used to reveal the properties of the newly created ppp objects.\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1925 character character \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#creating-owin-object-from-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#creating-owin-object-from-sf-data.frame",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Creating owin object from sf data.frame",
    "text": "Creating owin object from sf data.frame\n\n\nIn the code chunk as.owin() of spatstat.geom is used to create an owin object class from polygon sf tibble data.frame.\n\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\nNext, summary() function is used to display the summary information of the owin object class.\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#combining-point-events-object-and-owin-object",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#combining-point-events-object-and-owin-object",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Combining point events object and owin object",
    "text": "Combining point events object and owin object\n\nThe taskThe codeThe output\n\n\nUsing the step you learned from Hands-on Exercise 3, create an ppp object by combining childcare_ppp and sg_owin.\n\n\n\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\n\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#kernel-density-estimation-of-spatial-point-event",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#kernel-density-estimation-of-spatial-point-event",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Kernel Density Estimation of Spatial Point Event",
    "text": "Kernel Density Estimation of Spatial Point Event\nThe code chunk below re-scale the unit of measurement from metre to kilometre before performing KDE.\n\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, \n                                  1000, \n                                  \"km\")\n\nkde_childcareSG_adaptive &lt;- adaptive.density(\n  childcareSG_ppp.km, \n  method=\"kernel\")\nplot(kde_childcareSG_adaptive)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#kernel-density-estimation",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#kernel-density-estimation",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Kernel Density Estimation",
    "text": "Kernel Density Estimation\nCode chunk shown two different ways to convert KDE output into grid object\n\nmaptools methodspatstat.geom method\n\n\n\n\npar(bg = '#E4D5C9')\n\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(\n  kde_childcareSG_adaptive)\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\ngridded_kde_childcareSG_ad &lt;- as(\n  kde_childcareSG_adaptive,\n  \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_ad)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#kernel-density-estimation-1",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#kernel-density-estimation-1",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Kernel Density Estimation",
    "text": "Kernel Density Estimation\nVisualising KDE using tmap\nThe code chunk below is used to plot the output raster by using tmap functions.\n\n\ntm_shape(kde_childcareSG_ad_raster) + \n  tm_raster(palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            frame = FALSE,\n            bg.color = \"#E4D5C9\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#extracting-study-area-using-sf-objects",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#extracting-study-area-using-sf-objects",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Extracting study area using sf objects",
    "text": "Extracting study area using sf objects\n\nThe taskThe code\n\n\nExtract and create an ppp object showing child care services and within Punggol Planning Area\n\n\nOn the other hand, filter() of dplyr package should be used to extract the target planning areas as shown in the code chunk below.\n\n\npg_owin &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\") %&gt;%\n  as.owin()\n\nchildcare_pg = childcare_ppp[pg_owin]\n\nplot(childcare_pg)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#monte-carlo-simulation",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#monte-carlo-simulation",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Monte Carlo Simulation",
    "text": "Monte Carlo Simulation\n\n\n\n\n\n\n\n\nTip\n\n\nIn order to ensure reproducibility, it is important to include the code chunk below before using spatstat functions involve Monte Carlo simulation\n\n\n\n\n\nset.seed(1234)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#edge-correction-methods-of-spatstat",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#edge-correction-methods-of-spatstat",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Edge correction methods of spatstat",
    "text": "Edge correction methods of spatstat\nIn spatstat, edge correction methods are used to handle biases that arise when estimating spatial statistics near the boundaries of a study region. These corrections are essential for ensuring accurate estimates in spatial point pattern analysis, especially for summary statistics like the K-function, L-function, pair correlation function, etc.\n\nCommon Edge Correction Methods in spatstat\n\n“none”: No edge correction is applied. This method assumes that there is no bias at the edges, which may lead to underestimation of statistics near the boundaries.\n“isotropic”: This method corrects for edge effects by assuming that the point pattern is isotropic (uniform in all directions). It compensates for missing neighbors outside the boundary by adjusting the distances accordingly.\n“translate” (Translation Correction): This method uses a translation correction, which involves translating the observation window so that every point lies entirely within it. The statistic is then averaged over all possible translations.\n“Ripley” (Ripley’s Correction): Similar to the isotropic correction but specifically tailored for Ripley’s K-function and related functions. It adjusts the expected number of neighbors for points near the edges based on the shape and size of the observation window.\n“border”: Border correction reduces bias by only considering points far enough from the boundary so that their neighborhood is fully contained within the window. This can be quite conservative but reduces the influence of edge effects."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#geospatial-analytics-for-social-good-thailand-road-accident-case-study",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#geospatial-analytics-for-social-good-thailand-road-accident-case-study",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Geospatial Analytics for Social Good: Thailand Road Accident Case Study",
    "text": "Geospatial Analytics for Social Good: Thailand Road Accident Case Study\nBackground\n\nRoad traffic injuries, WHO.\nRoad traffic deaths and injuries in Thailand"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#the-study-area",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#the-study-area",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "The Study Area",
    "text": "The Study Area\nThe study area is Bangkok Metropolitan Region.\n\n\n\n\n\n\n\nNote\n\n\nThe projected coordinate system of Thailand is WGS 84 / UTM zone 47N and the EPSG code is 32647."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#the-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#the-data",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "The Data",
    "text": "The Data\nFor the purpose of this exercise, three basic data sets are needed, they are:\n\nThailand Road Accident [2019-2022] on Kaggle\nThailand Roads (OpenStreetMap Export) on HDX.\nThailand - Subnational Administrative Boundaries on HDX."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#importing-traffic-accident-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#importing-traffic-accident-data",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Importing Traffic Accident Data",
    "text": "Importing Traffic Accident Data\n\nThe taskThe code\n\n\nUsing the steps you learned in previous lessons, import the downloaded accident data into R environment and save the output as an sf tibble data.frame.\n\n\n\n\nrdacc_sf &lt;- read_csv(\"data/thai_road_accident_2019_2022.csv\") %&gt;%\n  filter(!is.na(longitude) & longitude != \"\", \n         !is.na(latitude) & latitude != \"\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%\n  st_transform(crs = 32647)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#visualising-the-accident-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02-SPPA.html#visualising-the-accident-data",
    "title": "In-class Exercise 2: Spatial Point Patterns Analysis: spatstat methods",
    "section": "Visualising The Accident Data",
    "text": "Visualising The Accident Data\n\nThe taskThe code\n\n\nUsing the steps you learned in previous lessons, import the ACLED data into R environment as an sf tibble data.frame.\n\n\n\n\ntmap_mode(\"plot\")\nacled_sf %&gt;%\n  filter(year == 2023 | \n           event_type == \"Political violence\") %&gt;%\n  tm_shape()+\n  tm_dots()\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#getting-started",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#getting-started",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Getting started",
    "text": "Getting started\n\nLaunch the coursework project with RStudio\nCreate a new folder called In-class_Ex.\nCreate a new sub-folder inside the newly created In-class_Ex folder. Name the sub-folder In-class_Ex01.\nCreate a new Quarto document. Save the newly create qmd file in In-class_Ex01 sub-folder. Call the file In-class_Ex01."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-the-r-packages",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Loading the R packages",
    "text": "Loading the R packages\n\nThe taskThe code\n\n\nFor the purpose of this in-class exercise, the following R packages will be used:\n\ntidyverse\nsf\ntmap\nggstatsplot\n\nWrite a code chunk to check if these two packages have been installed in R. If yes, load them in R environment.\n\n\n\n\npacman::p_load(tidyverse, sf, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-planning-sub-zone-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-planning-sub-zone-data",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Working with Master Plan Planning Sub-zone Data",
    "text": "Working with Master Plan Planning Sub-zone Data\n\nThe taskThe code\n\n\n\nCreate a sub-folder called data in In-class_Ex01 folder.\nIf necessary visit data.gov.sg and download Master Plan 2014 Subzone Boundary (Web) from the portal. You are required to download both the ESRI shapefile and kml file.\nWrite a code chunk to import Master Plan 2014 Subzone Boundary (Web) in shapefile and kml save them in sf simple features data frame.\n\n\n\n\nThis code chunk imports shapefile.\n\nmpsz14_shp &lt;- st_read(dsn = \"data/\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\tskam\\ISSS626-AY2024-25Aug\\In-class_Ex\\In-class_Ex01\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThis code chunk imports kml file.\n\nmpsz14_kml &lt;- st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-planning-sub-zone-data-1",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-planning-sub-zone-data-1",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Working with Master Plan Planning Sub-zone Data",
    "text": "Working with Master Plan Planning Sub-zone Data\n\nThe taskThe code\n\n\n\nWrite a code chunk to export mpsz14_shp sf data.frame into kml file save the output in data sub-folder. Name the output file MP14_SUBZONE_WEB_PL.\n\n\n\n\n\nst_write(mpsz14_shp, \n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-pre-school-location-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-pre-school-location-data",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Working with Pre-school Location Data",
    "text": "Working with Pre-school Location Data\n\nThe taskThe code\n\n\n\nIf necessary visit data.gov.sg and download Pre-Schools Location from the portal. You are required to download both the kml and geojson files.\nWrite a code chunk to import Pre-Schools Location in kml geojson save them in sf simple features data frame.\n\n\n\n\nThis code chunk imports kml file.\n\npreschool_kml &lt;- st_read(\"data/PreSchoolsLocation.kml\")\n\nThis code chunk imports geojson file.\n\npreschool_geojson &lt;- st_read(\"data/PreSchoolsLocation.geojson\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-2019-subzone-boundary-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-master-plan-2019-subzone-boundary-data",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Working with Master Plan 2019 Subzone Boundary Data",
    "text": "Working with Master Plan 2019 Subzone Boundary Data\n\nThe taskTo import shapefileTo import kml\n\n\n\nVisit data.gov.sg and download Master Plan 2019 Subzone Boundary (No Sea) from the portal. You are required to download both the kml file.\nMove MPSZ-2019 shapefile provided for In-class Exercise 1 folder on elearn to data sub-folder of In-class_Ex02.\nWrite a code chunk to import Master Plan 2019 Subzone Boundary (No SEA) kml and MPSZ-2019 into sf simple feature data.frame.\n\n\n\n\n\nmpsz19_shp &lt;- st_read(dsn = \"data/\",\n                layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `D:\\tskam\\ISSS626-AY2024-25Aug\\In-class_Ex\\In-class_Ex01\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `D:\\tskam\\ISSS626-AY2024-25Aug\\In-class_Ex\\In-class_Ex01\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#handling-coordinate-systems",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#handling-coordinate-systems",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Handling Coordinate Systems",
    "text": "Handling Coordinate Systems\nChecking coordinate system\n\nThe taskThe code\n\n\nWrite a code chunk to check the project of the imported sf objects.\n\n\n\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#handling-coordinate-systems-1",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#handling-coordinate-systems-1",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Handling Coordinate Systems",
    "text": "Handling Coordinate Systems\nTransforming coordinate system\n\nThe taskTo import MPSZ-2019To import PreSchoolsLocation.kml\n\n\nRe-write the code chunk to import the Master Plan Sub-zone 2019 and Pre-schools Location with proper transformation\n\n\n\n\nmpsz19_shp &lt;- st_read(dsn = \"data/\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `D:\\tskam\\ISSS626-AY2024-25Aug\\In-class_Ex\\In-class_Ex01\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\npreschool &lt;- st_read(\"data/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\tskam\\ISSS626-AY2024-25Aug\\In-class_Ex\\In-class_Ex01\\data\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#geospatial-data-wrangling",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#geospatial-data-wrangling",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\nPoint-in-Polygon count\n\nThe taskThe code\n\n\nWrite a code chunk to count the number of pre-schools in each planning sub-zone.\n\n\n\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(`PreSch Count` = lengths(\n    st_intersects(mpsz19_shp, preschool)))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#geospatial-data-wrangling-1",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#geospatial-data-wrangling-1",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\nComputing density\n\nThe taskThe code\n\n\nWrite a single line code to perform the following tasks:\n\nDerive the area of each planning sub-zone.\nDrop the unit of measurement of the area (i.e. m^2)\nCalculate the density of pre-school at the planning sub-zone level.\n\n\n\n\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(Area = units::drop_units(\n    st_area(.)),\n    `PreSch Density` = `PreSch Count` / Area * 1000000\n  )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#statistical-analysis",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#statistical-analysis",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Statistical Analysis",
    "text": "Statistical Analysis\n\nThe taskThe codeThe plot\n\n\nUsing appropriate Exploratory Data Analysis (EDA) and Confirmatory Data Analysis (CDA) methods to explore and confirm the statistical relationship between Pre-school Density and Pre-school count.\nTip: Refer to ggscatterstats() of ggstatsplot package.\n\n\n\n\nmpsz$`PreSch Density` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Density`))\nmpsz$`PreSch Count` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Count`)) \nmpsz19_shp &lt;- as.data.frame(mpsz19_shp)\n\nggscatterstats(data = mpsz19_shp,\n               x = `PreSch Density`,\n               y = `PreSch Count`,\n               type = \"parametric\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-population-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#working-with-population-data",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Working with Population Data",
    "text": "Working with Population Data\n\nThe taskThe code\n\n\n\nVisit and extract the latest Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling from Singstat homepage.\n\n\n\n\npopdata &lt;- read_csv(\"data/respopagesextod2023.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#data-wrangling",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#data-wrangling",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nThe taskThe code\n\n\n\nWrite a code chunk to prepare a data.frame showing population by Planning Area and Planning subzone\n\n\n\n\npopdata2023 &lt;- popdata %&gt;% \n  group_by(PA, SZ, AG) %&gt;% \n  summarise(`POP`=sum(`Pop`)) %&gt;%  \n  ungroup() %&gt;% \n  pivot_wider(names_from=AG,\n              values_from = POP)\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#data-processing",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#data-processing",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Data Processing",
    "text": "Data Processing\n\nThe taskThe code\n\n\nWrite a code chunk to derive a tibble data.framewith the following fields PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY where by:\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group.\n\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG=rowSums(.[3:6]) # Aged 0 - 24, 10 - 24\n         +rowSums(.[14])) %&gt;% # Aged 5 - 9\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+ # Aged 25 - 59\n  rowSums(.[15])) %&gt;%  # Aged 60 -64\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY`=(`YOUNG` + `AGED`)\n  / `ECONOMY ACTIVE`) %&gt;% \n  select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`,\n         `TOTAL`, `DEPENDENCY`)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#joining-popdata2023-and-mpsz19_shp",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#joining-popdata2023-and-mpsz19_shp",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Joining popdata2023 and mpsz19_shp",
    "text": "Joining popdata2023 and mpsz19_shp\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) \n\n\nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp, \n                          by = c(\"SZ\" = \"SUBZONE_N\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#choropleth-map-of-dependency-ratio-by-planning-subzone",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#choropleth-map-of-dependency-ratio-by-planning-subzone",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Choropleth Map of Dependency Ratio by Planning Subzone",
    "text": "Choropleth Map of Dependency Ratio by Planning Subzone\n\nThe mapThe code"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Analytical Map: Percentile Map",
    "text": "Analytical Map: Percentile Map\nThe concept\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map-1",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map-1",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Analytical Map: Percentile Map",
    "text": "Analytical Map: Percentile Map\nStep 1: Data Preparation\nThe code chunk below excludes records with NA by using the code chunk below.\n\n\nmpsz_pop2023 &lt;- mpsz_pop2023 %&gt;%\n  drop_na()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map-2",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map-2",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Analytical Map: Percentile Map",
    "text": "Analytical Map: Percentile Map\nStep 2: The get function\nThe code chunk below defines a function to get the input data and field to be used for creating the percentile map.\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map-3",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map-3",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Analytical Map: Percentile Map",
    "text": "Analytical Map: Percentile Map\nStep 3: A percentile mapping function\nThe code chunk below creates a function for computing and plotting the percentile map.\n\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(mpsz_pop2023) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map-4",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-percentile-map-4",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Analytical Map: Percentile Map",
    "text": "Analytical Map: Percentile Map\nStep 4: Running the functions\nThe code chunk below runs the percentile map function.\n\n\npercentmap(\"DEPENDENCY\", mpsz_pop2023)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Analytical Map: Box Map",
    "text": "Analytical Map: Box Map\n\n\nThe Concept\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\n\nggplot(data = mpsz_pop2023,\n       aes(x = \"\",\n           y = DEPENDENCY)) +\n  geom_boxplot()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map-1",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map-1",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Analytical Map: Box Map",
    "text": "Analytical Map: Box Map\nStep 1: Creating the boxbreaks function\n\n\nThe code chunk on the right is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analyticsal-map-box-map",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analyticsal-map-box-map",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Analyticsal Map: Box Map",
    "text": "Analyticsal Map: Box Map\nStep 2: Creating the get.var function\n\n\nThe code chunk on the right an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map-2",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map-2",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Analytical Map: Box Map",
    "text": "Analytical Map: Box Map\nStep 3: Boxmap function\n\n\nThe code chunk on the right is an R function to create a box map.\n\narguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nreturns:\n\na tmap-element (plots a map)\n\n\n\n\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map-3",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map-3",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Analytical Map: Box Map",
    "text": "Analytical Map: Box Map\nStep 4: Plotting Box Map\n\nboxmap(\"DEPENDENCY\", mpsz_pop2023)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map-4",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#analytical-map-box-map-4",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "Analytical Map: Box Map",
    "text": "Analytical Map: Box Map\nPlotting Interactive Box Map\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\nboxmap(\"DEPENDENCY\", mpsz_pop2023)"
  },
  {
    "objectID": "git.html",
    "href": "git.html",
    "title": "Git and Github",
    "section": "",
    "text": "Happy Git and GitHub for the useR. Highly recommended to beginners."
  },
  {
    "objectID": "git.html#book",
    "href": "git.html#book",
    "title": "Git and Github",
    "section": "",
    "text": "Happy Git and GitHub for the useR. Highly recommended to beginners."
  },
  {
    "objectID": "git.html#gitgithub",
    "href": "git.html#gitgithub",
    "title": "Git and Github",
    "section": "git/github",
    "text": "git/github\n\ngithub doc\nGitHub and RStudio"
  },
  {
    "objectID": "git.html#blog-post",
    "href": "git.html#blog-post",
    "title": "Git and Github",
    "section": "Blog post",
    "text": "Blog post\n\ngit in RStudio\nSolving git(GitHub) token issue\nGetting starting with git and GitHub using RStudio\ngit\nTransform a folder as git project synchronized on Github or Gitlab\nRecovering from common Git predicaments"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "title": "ISSS626 Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/data/rawdata/Punggol_BusStop.html",
    "href": "In-class_Ex/In-class_Ex03/data/rawdata/Punggol_BusStop.html",
    "title": "ISSS626 Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  GDM.BusStop  ENG dataset\n\nGDM.BusStop\n\nREQUIRED: A brief narrative summary of the data set.\nREQUIRED: A summary of the intentions with which the data set was developed.  REQUIRED: Common-use word or phrase used to describe the subject of the data set.       REQUIRED: Restrictions and legal prerequisites for accessing the data set. REQUIRED: Restrictions and legal prerequisites for using the data set after access is granted.      0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, you are going to gain hands-on experience on using appropriate functions of spNetwork package:\n\nto derive network kernel density estimation (NKDE), and\nto perform network G-function and k-function analysis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#overview",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#overview",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, you are going to gain hands-on experience on using appropriate functions of spNetwork package:\n\nto derive network kernel density estimation (NKDE), and\nto perform network G-function and k-function analysis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#the-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#the-data",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "The Data",
    "text": "The Data\nIn this study, we will analyse the spatial distribution of childcare centre in Punggol planning area. For the purpose of this study, two geospatial data sets will be used. They are:\n\nPunggol_St, a line features geospatial data which store the road network within Punggol Planning Area.\nPunggol_CC, a point feature geospatial data which store the location of childcare centres within Punggol Planning Area.\n\nBoth data sets are in ESRI shapefile format."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#installing-and-launching-the-r-packages",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#installing-and-launching-the-r-packages",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "Installing and launching the R packages",
    "text": "Installing and launching the R packages\nIn this hands-on exercise, four R packages will be used, they are:\n\nspNetwork, which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\nsf package provides functions to manage, processing, and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nUse the code chunk below to install and launch the four R packages.\n\npacman::p_load(sf, spNetwork, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#data-import-and-preparation",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#data-import-and-preparation",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "Data Import and Preparation",
    "text": "Data Import and Preparation\nThe code chunk below uses st_read() of sf package to important Punggol_St and Punggol_CC geospatial data sets into RStudio as sf data frames.\n\nnetwork &lt;- st_read(dsn=\"data/rawdata\", \n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `D:\\tskam\\ISSS626-AY2024-25Aug\\In-class_Ex\\In-class_Ex03\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare &lt;- st_read(dsn=\"data/rawdata\",\n                     layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `D:\\tskam\\ISSS626-AY2024-25Aug\\In-class_Ex\\In-class_Ex03\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nWe can examine the structure of the output simple features data tables in RStudio. Alternative, code chunk below can be used to print the content of network and childcare simple features objects by using the code chunk below.\n\nChildcareNetwork\n\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                      geometry\n1   kml_10 POINT Z (36173.81 42550.33 0)\n2   kml_99 POINT Z (36479.56 42405.21 0)\n3  kml_100 POINT Z (36618.72 41989.13 0)\n4  kml_101 POINT Z (36285.37 42261.42 0)\n5  kml_122  POINT Z (35414.54 42625.1 0)\n6  kml_161 POINT Z (36545.16 42580.09 0)\n7  kml_172 POINT Z (35289.44 44083.57 0)\n8  kml_188 POINT Z (36520.56 42844.74 0)\n9  kml_205  POINT Z (36924.01 41503.6 0)\n10 kml_222 POINT Z (37141.76 42326.36 0)\n\n\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n\n\n\nWhen I exploring spNetwork’s functions, it came to my attention that spNetwork is expecting the geospatial data contains complete CRS information."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-the-geospatial-data",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "Visualising the Geospatial Data",
    "text": "Visualising the Geospatial Data\nBefore we jump into the analysis, it is a good practice to visualise the geospatial data. There are at least two ways to visualise the geospatial data. One way is by using plot() of Base R as shown in the code chunk below.\n\nplot(st_geometry(network))\nplot(childcare,add=T,col='red',pch = 19)\n\n\n\n\n\n\n\n\nTo visualise the geospatial data with high cartographic quality and interactive manner, the mapping function of tmap package can be used as shown in the code chunk below.\n\ntmap_mode('view')\ntm_shape(childcare) + \n  tm_dots() + \n  tm_shape(network) +\n  tm_lines()\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#network-kde-nkde-analysis",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#network-kde-nkde-analysis",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "Network KDE (NKDE) Analysis",
    "text": "Network KDE (NKDE) Analysis\nIn this section, we will perform NKDE analysis by using appropriate functions provided in spNetwork package.\n\nPreparing the lixels objects\nBefore computing NKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 375)\n\nWhat can we learned from the code chunk above:\n\nThe length of a lixel, lx_length is set to 700m, and\nThe minimum length of a lixel, mindist is set to 350m.\n\nAfter cut, if the length of the final lixel is shorter than the minimum distance, then it is added to the previous lixel. If NULL, then mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified\nNote: There is another function called lixelize_lines.mc() which provide multicore support.\n\n\nGenerating line centre points\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples &lt;- lines_center(lixels) \n\nThe points are located at center of the line based on the length of the line.\n\n\nPerforming NKDE\nWe are ready to computer the NKDE by using the code chunk below.\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\nWhat can we learn from the code chunk above?\n\nkernel_name argument indicates that quartic kernel is used. Are possible kernel methods supported by spNetwork are: triangle, gaussian, scaled gaussian, tricube, cosine ,triweight, epanechnikov or uniform.\nmethod argument indicates that simple method is used to calculate the NKDE. Currently, spNetwork support three popular methods, they are:\n\nmethod=“simple”. This first method was presented by Xie et al. (2008) and proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an areal unit.\nmethod=“discontinuous”. The method is proposed by Okabe et al (2008), which equally “divides” the mass density of an event at intersections of lixels.\nmethod=“continuous”. If the discontinuous method is unbiased, it leads to a discontinuous kernel function which is a bit counter-intuitive. Okabe et al (2008) proposed another version of the kernel, that divide the mass of the density at intersection but adjusts the density before the intersection to make the function continuous.\n\n\nThe user guide of spNetwork package provide a comprehensive discussion of nkde(). You should read them at least once to have a basic understanding of the various parameters that can be used to calibrate the NKDE model.\n\nVisualising NKDE\nBefore we can visualise the NKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. The code chunk below is used to resale the density values from number of events per meter to number of events per kilometer.\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code below uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation.\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\ntmap_mode('plot')\n\nThe interactive map above effectively reveals road segments (darker color) with relatively higher density of childcare centres than road segments with relatively lower density of childcare centres (lighter color)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#network-constrained-g--and-k-function-analysis",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#network-constrained-g--and-k-function-analysis",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "Network Constrained G- and K-Function Analysis",
    "text": "Network Constrained G- and K-Function Analysis\nIn this section, we are going to perform complete spatial randomness (CSR) test by using kfunctions() of spNetwork package. The null hypothesis is defined as:\nHo: The observed spatial point events (i.e distribution of childcare centres) are uniformly distributed over a street network in Punggol Planning Area.\nThe CSR test is based on the assumption of the binomial point process which implies the hypothesis that the childcare centres are randomly and independently distributed over the street network.\nIf this hypothesis is rejected, we may infer that the distribution of childcare centres are spatially interacting and dependent on each other; as a result, they may form nonrandom patterns.\n\nkfun_childcare &lt;- kfunctions(network, \n                             childcare,\n                             start = 0, \n                             end = 1000, \n                             step = 50, \n                             width = 50, \n                             nsim = 50, \n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05)\n\nWhat can we learn from the code chunk above?\nThere are ten arguments used in the code chunk above they are:\n\nlines: A SpatialLinesDataFrame with the sampling points. The geometries must be a SpatialLinesDataFrame (may crash if some geometries are invalid).\npoints: A SpatialPointsDataFrame representing the points on the network. These points will be snapped on the network.\nstart: A double, the start value for evaluating the k and g functions.\nend: A double, the last value for evaluating the k and g functions.\nstep: A double, the jump between two evaluations of the k and g function.\nwidth: The width of each donut for the g-function.\nnsim: An integer indicating the number of Monte Carlo simulations required. In the above example, 50 simulation was performed. Note: most of the time, more simulations are required for inference\nresolution: When simulating random points on the network, selecting a resolution will reduce greatly the calculation time. When resolution is null the random points can occur everywhere on the graph. If a value is specified, the edges are split according to this value and the random points are selected vertices on the new network.\nconf_int: A double indicating the width confidence interval (default = 0.05).\n\nFor the usage of other arguments, you should refer to the user guide of spNetwork package.\nThe output of kfunctions() is a list with the following values:\n\nplotkA, a ggplot2 object representing the values of the k-function\nplotgA, a ggplot2 object representing the values of the g-function\nvaluesA, a DataFrame with the values used to build the plots\n\nFor example, we can visualise the ggplot2 object of k-function by using the code chunk below.\n\nkfun_childcare$plotk\n\n\n\n\n\n\n\n\nThe blue line is the empirical network K-function of the childcare centres in Punggol planning area. The gray envelop represents the results of the 50 simulations in the interval 2.5% - 97.5%. Because the blue line between the distance of 250m-400m are below the gray area, we can infer that the childcare centres in Punggol planning area resemble regular pattern at the distance of 250m-400m."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#references",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#references",
    "title": "Network Constrained Spatial Point Patterns Analysis",
    "section": "References",
    "text": "References\n\nspNetwork: Spatial Analysis on Network\nNetwork Kernel Density Estimate\nDetails about NKDE\nNetwork k Functions"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#content",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#content",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "Content",
    "text": "Content\n\nIntroducing sfdep.\n\nsfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep.\nsfdep utilizes list columns extensively to make this interface possible.”"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#getting-started",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#getting-started",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "Getting started",
    "text": "Getting started\nInstalling and Loading the R Packages\nFour R packages will be used for this in-class exercise, they are: sf, sfdep, tmap and tidyverse.\n\nDo It Yourself!The code\n\n\nUsing the steps you learned in previous lesson, install and load sf, tmap, sfdep and tidyverse packages into R environment.\n\n\n\n\npacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#the-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#the-data",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "The Data",
    "text": "The Data\nFor the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\nHunan, a geospatial data set in ESRI shapefile format, and\nHunan_2012, an attribute data set in csv format.\n\n\nDo It Yourself!The code\n\n\nUsing the steps you learned in previous lesson, import Hunan shapefile into R environment as an sf data frame.\n\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\tskam\\ISSS626-AY2024-25Aug\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#importing-attribute-table",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#importing-attribute-table",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "Importing Attribute Table",
    "text": "Importing Attribute Table\n\nDo It Yourself!The code\n\n\nUsing the steps you learned in previous lesson, import Hunan_2012.csv into R environment as an tibble data frame.\n\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#combining-both-data-frame-by-using-left-join",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#combining-both-data-frame-by-using-left-join",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "Combining both data frame by using left join",
    "text": "Combining both data frame by using left join\n\nDo It Yourself!The code\n\n\nUsing the steps you learned in previous lesson, combine the Hunan sf data frame and Hunan_2012 data frame. Ensure that the output is an sf data frame.\n\n\n\n\nhunan_GDPPC &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n\n\n\n\n\nNote\n\n\nFor the purpose of this exercise, we only retain column 1 to 4, column 7 and column 15. You should examine the output sf data.frame to learn know what are these fields.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hunan)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#plotting-a-choropleth-map",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#plotting-a-choropleth-map",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "Plotting a choropleth map",
    "text": "Plotting a choropleth map\n\nDo It Yourself!The plotThe code\n\n\nUsing the steps you learned in previous lesson, plot a choropleth map showing the distribution of GDPPC of Hunan Province.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#global-measures-of-spatial-association",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#global-measures-of-spatial-association",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "Global Measures of Spatial Association",
    "text": "Global Measures of Spatial Association\nStep 1: Deriving Queen’s contiguity weights: sfdep methods\n\n\n\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1) \n\n\n\n\nNotice that st_weights() provides tree arguments, they are:\n\nnb: A neighbor list object as created by st_neighbors().\nstyle: Default “W” for row standardized weights. This value can also be “B”, “C”, “U”, “minmax”, and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nallow_zero: If TRUE, assigns zero as lagged value to zone without neighbors."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#lisa-map",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#lisa-map",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "LISA map",
    "text": "LISA map\n\n\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#computing-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#computing-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "Computing local Moran’s I",
    "text": "Computing local Moran’s I\nIn this section, you will learn how to compute Local Moran’s I of GDPPC at county level by using local_moran() of sfdep package.\n\nThe codeThe output\n\n\n\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\n\n\nThe output of local_moran() is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\nii: local moran statistic\neii: expectation of local moran statistic; for localmoran_permthe permutation sample means\nvar_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\nz_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations p_ii_sim: For localmoran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative= -p_folded_sim: the simulation folded [0, 0.5] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\nskewness: For localmoran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For localmoran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-GLSA.html#hot-spot-and-cold-spot-area-analysis-hcsa",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods",
    "section": "Hot Spot and Cold Spot Area Analysis (HCSA)",
    "text": "Hot Spot and Cold Spot Area Analysis (HCSA)\n\n\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#installing-and-loading-the-r-packages",
    "title": "In-class Exercise 6: Spatially Constrained Clustering Analysis: REDCAP methods",
    "section": "Installing and Loading the R Packages",
    "text": "Installing and Loading the R Packages\nAs usual, p_load() of pacman package will be used to check if the necessary packages have been installed in R, if yes, load the packages on R environment.\nFive R packages are need for this in-class exercise, they are: sf, sfdep, tmap, and tidyverse.\n\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#importing-geospatial-data",
    "title": "In-class Exercise 6: Spatially Constrained Clustering Analysis: REDCAP methods",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\nIn the code chunk below, st_read() of sf package is used to import Hunan shapefile into R.\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\tskam\\ISSS626-AY2024-25Aug\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#importing-attribute-table",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#importing-attribute-table",
    "title": "In-class Exercise 6: Spatially Constrained Clustering Analysis: REDCAP methods",
    "section": "Importing attribute table",
    "text": "Importing attribute table\nIn the code chunk below, read_csv() of readr is used to import Hunan_GDPPC.csv into R.\n\n\nGDPPC &lt;- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#computing-gi",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#computing-gi",
    "title": "In-class Exercise 6: Spatially Constrained Clustering Analysis: REDCAP methods",
    "section": "Computing Gi*",
    "text": "Computing Gi*\nNext, we will compute the local Gi* statistics.\n\nDeriving the spatial weights\nThe code chunk below will be used to identify neighbors and to derive an inverse distance weights.\n\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nactivate() of dplyr package is used to activate the geometry context\nmutate() of dplyr package is used to create two new columns nb and wt.\nThen we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()\n\nrow order is very important so do not rearrange the observations after using set_nbs() or set_wts().\n\n\n\n\nNote that this dataset now has neighbors and weights for each time-slice.\n\nhead(GDPPC_nb)\n\n# A tibble: 6 × 5\n   Year County  GDPPC nb        wt       \n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;   \n1  2005 Anxiang  8184 &lt;int [6]&gt; &lt;dbl [6]&gt;\n2  2005 Hanshou  6560 &lt;int [6]&gt; &lt;dbl [6]&gt;\n3  2005 Jinshi   9956 &lt;int [5]&gt; &lt;dbl [5]&gt;\n4  2005 Li       8394 &lt;int [5]&gt; &lt;dbl [5]&gt;\n5  2005 Linli    8850 &lt;int [5]&gt; &lt;dbl [5]&gt;\n6  2005 Shimen   9244 &lt;int [6]&gt; &lt;dbl [6]&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#computing-gi-1",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#computing-gi-1",
    "title": "In-class Exercise 6: Spatially Constrained Clustering Analysis: REDCAP methods",
    "section": "Computing Gi*",
    "text": "Computing Gi*\nWe can use these new columns to manually calculate the local Gi* for each location. We can do this by grouping by Year and using local_gstar_perm() of sfdep package. After which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.\n\n\ngi_stars &lt;- GDPPC_nb %&gt;% \n  group_by(Year) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#arrange-to-show-significant-emerging-hotcold-spots",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#arrange-to-show-significant-emerging-hotcold-spots",
    "title": "In-class Exercise 6: Spatially Constrained Clustering Analysis: REDCAP methods",
    "section": "Arrange to show significant emerging hot/cold spots",
    "text": "Arrange to show significant emerging hot/cold spots\n\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#performing-emerging-hotspot-analysis",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html#performing-emerging-hotspot-analysis",
    "title": "In-class Exercise 6: Spatially Constrained Clustering Analysis: REDCAP methods",
    "section": "Performing Emerging Hotspot Analysis",
    "text": "Performing Emerging Hotspot Analysis\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object x (i.e. GDPPC_st), and the quoted name of the variable of interest (i.e. GDPPC) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st, \n  .var = \"GDPPC\", \n  k = 1, \n  nsim = 99\n)\n\n\n\nVisualising the distribution of EHSA classes\nIn the code chunk below, ggplot2 functions ised used to reveal the distribution of EHSA classes as a bar chart.\n\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nFigure above shows that sporadic cold spots class has the high numbers of county.\n\n\nVisualising EHSA\nIn this section, you will learn how to visualise the geographic distribution EHSA classes. However, before we can do so, we need to join both hunan and ehsa together by using the code chunk below.\n\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County == location))\n\n\nNext, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.\n\n\nehsa_sig &lt;- hunan_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Geospatial_Data.html#content",
    "href": "lesson/Lesson01/Lesson01-Geospatial_Data.html#content",
    "title": "Lesson 1: Fundamental of Geospatial Data and sf Methods",
    "section": "Content",
    "text": "Content\n\nAn overview of Geospatial Data Models\n\nVector and raster data model\nCoordinate systems and map projection\n\nHandling Geospatial Data in R: An Overview\nSimple features approach\n\nsf package\n\n\n\nThis lesson consists of two parts. First, I will talk about Geospatial Data Models. For students who have taken SMT201 GIS for Urban Planning, this is not new at all. However, for students who did not read SMT201, this will be new. Anyway, the focus of this section will be on R. Hence, even for students who have taken SMT201 before, this will be a good revision.\nIn part two of this lesson, I will introduce sp package. It is a relatively new R package specially developed to handle geospatial data R using tidyverse principle."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Geospatial_Data.html#geospatial-data-models",
    "href": "lesson/Lesson01/Lesson01-Geospatial_Data.html#geospatial-data-models",
    "title": "Lesson 1: Fundamental of Geospatial Data and sf Methods",
    "section": "Geospatial Data Models",
    "text": "Geospatial Data Models\nWhy should we worry about?\n\n\nIt is important for us to note that what ever data capture in a database is a model of the real world. When we say model, this means that it is a simplify version of the real world and not the real world themselves."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Geospatial_Data.html#basic-spatial-data-models",
    "href": "lesson/Lesson01/Lesson01-Geospatial_Data.html#basic-spatial-data-models",
    "title": "Lesson 1: Fundamental of Geospatial Data and sf Methods",
    "section": "Basic Spatial Data Models",
    "text": "Basic Spatial Data Models\n\nVector - implementation of discrete object conceptual model\n\nPoint, line and polygon representations.\nWidely used in cartography, and network analysis.\n\nRaster – implementation of field conceptual model\n\nArray of cells used to represent objects.\nUseful as background maps and for spatial analysis.\n\n\n\nIn general, there are two types of geospatial data models, namely vector and raster data models.\nVector data model tends to be used to store geospatial data that are discrete in nature. For example bus stop, building footprint, planning area.\nRaster data model, one the other hands, are used to store continuous fenomena such as air polution, elevation and precipitation."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Geospatial_Data.html#coordinate-systems-and-map-projections",
    "href": "lesson/Lesson01/Lesson01-Geospatial_Data.html#coordinate-systems-and-map-projections",
    "title": "Lesson 1: Fundamental of Geospatial Data and sf Methods",
    "section": "Coordinate Systems and Map Projections",
    "text": "Coordinate Systems and Map Projections\nWhat is a coordinate system?\n\n\nA coordinate system is an important property of an geospatial data. It provides a location reference to the geospatial data.\n\nThere are two common types of coordinate systems used in mapping, namely: geographic coordinate systems and projected coordinate system.\n\n\n\n\n\n\n\nFurther Reading\n\n\n\nRefer to this article and Chapter 9 Coordinate Systems to learn more about map projection.\n\n\n\n\n\n\n\n\n\nA coordinate system is a reference system used to represent the locations of geographic features, imagery, and observations such as GPS locations within a common geographic framework.\nEach coordinate system is defined by:\n\nIts measurement framework which is either geographic (in which spherical coordinates are measured from the earth’s center) or planimetric (in which the earth’s coordinates are projected onto a two-dimensional planar surface).\nUnit of measurement (typically feet or meters for projected coordinate systems or decimal degrees for latitude–longitude).\nThe definition of the map projection for projected coordinate systems.\nOther measurement system properties such as a spheroid of reference, a datum, and projection parameters like one or more standard parallels, a central meridian, and possible shifts in the x- and y-directions."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Geospatial_Data.html#standard-for-geospatial-data-handling-and-analysis",
    "href": "lesson/Lesson01/Lesson01-Geospatial_Data.html#standard-for-geospatial-data-handling-and-analysis",
    "title": "Lesson 1: Fundamental of Geospatial Data and sf Methods",
    "section": "Standard for Geospatial Data Handling and Analysis",
    "text": "Standard for Geospatial Data Handling and Analysis\n\n\n\n\n\n\n\nFurther Reading\n\n\nFor more information, visit this link.\n\n\n\n\nThe OGC OpenGIS Implementation Standard for Geographic Information / ISO 19125 defines:\n\nGeometric objects which can be of type point, line, polygon, multi-point, etc, and are associated to a given Coordinate Reference System;\nMethods on geometric objects return properties like dimension, boundary, area, centroid, etc;\nMethods for testing spatial relations between geometric objects equals, disjoint, intersects, touches, crosses, within, contains, overlaps and relate, which returns TRUE or FALSE;\nMethods that support spatial analysis distance, which returns a distance, and buffer, convex hull, intersection, union, difference, and symmetric difference, which returns new geometric objects.\n\nSource: www.opengeospatial.org/standards/sfa"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Geospatial_Data.html#an-introduction-to-simple-features",
    "href": "lesson/Lesson01/Lesson01-Geospatial_Data.html#an-introduction-to-simple-features",
    "title": "Lesson 1: Fundamental of Geospatial Data and sf Methods",
    "section": "An introduction to simple features",
    "text": "An introduction to simple features\n\nfeature: abstraction of real world phenomena (type or instance); has a geometry and other attributes (properties)\nsimple feature: feature with all geometric attributes described piecewise by straight line or planar interpolation between sets of points (no curves)\nIt is a hierarchical data model that simplifies geographic data by condensing a complex range of geographic forms into a single geometry class."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Geospatial_Data.html#geospatial-data-object-framework",
    "href": "lesson/Lesson01/Lesson01-Geospatial_Data.html#geospatial-data-object-framework",
    "title": "Lesson 1: Fundamental of Geospatial Data and sf Methods",
    "section": "Geospatial Data Object Framework",
    "text": "Geospatial Data Object Framework\n\nTo begin with, all contributed packages for handling spatial data in R had different representations of the data. This made it difficult to exchange data both within R between packages, and between R and external le formats and applications.\nThe first general package to provide classes and methods for spatial data types that was developed for R is called sp. It was first released on CRAN in 2005.\nIn late October 2016, sf was first released on CRAN to provide standardised support for vector data in R."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Geospatial_Data.html#r-packages-that-support-spatial-classes",
    "href": "lesson/Lesson01/Lesson01-Geospatial_Data.html#r-packages-that-support-spatial-classes",
    "title": "Lesson 1: Fundamental of Geospatial Data and sf Methods",
    "section": "R packages that support spatial classes",
    "text": "R packages that support spatial classes\nIn general, three R packages will be used to handle vector-based geospatial data in spatial classes, they are:\n\nsp provides classes and methods for dealing with spatial data in R.\nrgdal allows R to understand the structure of a geospatial data file by providing functions to read and convert geospatial data into easy-to-work-with R dataframes.\nrgeos implements the methods of the OGC standard."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Geospatial_Data.html#introducing-sf-package",
    "href": "lesson/Lesson01/Lesson01-Geospatial_Data.html#introducing-sf-package",
    "title": "Lesson 1: Fundamental of Geospatial Data and sf Methods",
    "section": "Introducing sf Package",
    "text": "Introducing sf Package\n\nsf package provides a syntax and data-structures which are coherent with the tidyverse.\nA quick introduction can be found here.\nFor more detail, visit this link."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Geospatial_Data.html#sf-functions",
    "href": "lesson/Lesson01/Lesson01-Geospatial_Data.html#sf-functions",
    "title": "Lesson 1: Fundamental of Geospatial Data and sf Methods",
    "section": "sf functions",
    "text": "sf functions\n\nGeospatial data handling\nGeometric confirmation\nGeometric operations\nGeometry creation\nGeometry operations\nGeometric measurement"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Geospatial_Data.html#references",
    "href": "lesson/Lesson01/Lesson01-Geospatial_Data.html#references",
    "title": "Lesson 1: Fundamental of Geospatial Data and sf Methods",
    "section": "References",
    "text": "References\nAll About sf package\n\n\nReference manual\nTidy spatial data analysis\n\nVignettes:\n\nSimple Features for R\nReading, Writing and Converting Simple Features\nManipulating Simple Feature Geometries\nManipulating Simple Features\nPlotting Simple Features\nMiscellaneous\nSpherical geometry in sf using s2geometry\n\nOthers:\n\nR spatial follows GDAL and PROJ development"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#demystifying-geospatial-analytics",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#demystifying-geospatial-analytics",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "Demystifying Geospatial Analytics",
    "text": "Demystifying Geospatial Analytics\n\nA Geographical Information System (GIS) is a toolkit for creating, managing, analysing, visualising, and sharing data of any kind according to where it’s located.\n\n\n\nGeospatial analytics is more than a GIS."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#demystifying-geospatial-analytics-1",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#demystifying-geospatial-analytics-1",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "Demystifying Geospatial Analytics",
    "text": "Demystifying Geospatial Analytics\n\nGeospatial analytics is more than data visualisation\n\n\n\n\n\nSource: Singapore’s first disease map delivers real-time information on infectious diseases"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#demystifying-geospatial-analytics-2",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#demystifying-geospatial-analytics-2",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "Demystifying Geospatial Analytics",
    "text": "Demystifying Geospatial Analytics\n\nGeospatial analytics is more than just mapping."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#motivation-of-geospatial-analytics",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#motivation-of-geospatial-analytics",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "Motivation of Geospatial Analytics",
    "text": "Motivation of Geospatial Analytics\n\nAbout 80% of all data maintained by organisations around the world has a location component.\n\n\n\n(Source: BusinessWeek Research Services, 2006)"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#motivation-of-geospatial-analytics-1",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#motivation-of-geospatial-analytics-1",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "Motivation of Geospatial Analytics",
    "text": "Motivation of Geospatial Analytics\n\nGeospatial information in Smart Nation.\n\n\n\nSee more at this link"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#motivation-of-geospatial-analytics-2",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#motivation-of-geospatial-analytics-2",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "Motivation of Geospatial Analytics",
    "text": "Motivation of Geospatial Analytics\n\nThe explosion in the availability of open geospatial data from both the public and private sectors at national and international levels."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#motivation-of-geospatial-analytics-3",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#motivation-of-geospatial-analytics-3",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "Motivation of Geospatial Analytics",
    "text": "Motivation of Geospatial Analytics\n\nThe national geospatial master plan.\n\n\n\nSource: Singapore Geospatial Master Plan"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#the-role-of-geospatial-analytics",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#the-role-of-geospatial-analytics",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "The role of Geospatial Analytics",
    "text": "The role of Geospatial Analytics\n\nUncovering insights not found in statistical graphs and tables.\n\n\n\nSource: SGSAS - Simple Geo-Spatial Analysis using R Shiny"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#the-role-of-geospatial-analytics-1",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#the-role-of-geospatial-analytics-1",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "The role of Geospatial Analytics",
    "text": "The role of Geospatial Analytics\n\nTo reveal the untapped property of spatial contiguity in geographic knowledge discovery in databases.\n\n\n\nSource: SGSAS - Simple Geo-Spatial Analysis using R Shiny"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#the-role-of-geospatial-analytics-2",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#the-role-of-geospatial-analytics-2",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "The role of Geospatial Analytics",
    "text": "The role of Geospatial Analytics\n\nTo uncover the complexity of the real world relationship.\n\n\n\nSource: SGSAS - Simple Geo-Spatial Analysis using R Shiny"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#the-role-of-geospatial-analytics-3",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#the-role-of-geospatial-analytics-3",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "The role of Geospatial Analytics",
    "text": "The role of Geospatial Analytics\n\nTo model spatial interactions and flows.\n\n\n\nSource: IS415 Bus Rider Flow Project"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#geospatial-analytics-and-social-consciousness",
    "href": "lesson/Lesson01/Lesson01-Introduction_to_GAA.html#geospatial-analytics-and-social-consciousness",
    "title": "Lesson 1: Introduction to Geospatial Analytics and Applications",
    "section": "Geospatial Analytics and Social Consciousness",
    "text": "Geospatial Analytics and Social Consciousness\nThe true power of geospatial analytics is to provide decision makers and planners with data-driven and process information for better problem solving and more efficient use of resources."
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#content",
    "href": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#content",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "Content",
    "text": "Content\n\nNetwork Constrained Kernel Density Estimation (NCKDE)\n\nBasic concepts of network constrained spatial point patterns\nNetwork Constrained KDE methods\nThe Three versions of Network Constrained KDE\n\nTemporal Network Kernel Density Estimation (TNKED)\n\nTemporal dimension\nSpatial dimension\nSpatio-temporal point patterns\n\n\n\nWelcome to Lesson 3: Spatial Point Pattern Analysis, a family of spatial statistics specially developed to model and to test distribution of spatial point events.\nThe lesson proceeding is divided into three main section. First, I will share with you what are real world spatial point events. This is followed by explaining the concepts and methods of 1st-order and 2nd-order spatial point patterns analysis."
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#network-constrained-point-processes",
    "href": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#network-constrained-point-processes",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "Network Constrained Point Processes",
    "text": "Network Constrained Point Processes\nMany real world point event are not randomly distributed. Their distribution, on the other hand, are constrained by network such as roads, rivers, and fault lines just to name a few of them.\n\n\nRoad traffic accidents within Bangkok City. \n\nLocation of banks at Central, Hong Kong"
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#network-constrained-kernel-density-estimation-nkde",
    "href": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#network-constrained-kernel-density-estimation-nkde",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "Network Constrained Kernel Density Estimation (NKDE)",
    "text": "Network Constrained Kernel Density Estimation (NKDE)\nNetwork Kernel Density Estimation, in short, NKDE is a geospatial analytics methods specially designed to computer intensity of spatial point event either located along or occurred along linear networks.\n\n\nMathematically, NKDE can be defined as: \nwhere K must be a probability density function and verifies the two following conditions:"
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#network-constrained-kernel-density-estimation-nkde-1",
    "href": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#network-constrained-kernel-density-estimation-nkde-1",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "Network Constrained Kernel Density Estimation (NKDE)",
    "text": "Network Constrained Kernel Density Estimation (NKDE)\nPlanar KDE versus NKDE\n\n\nFigure on the right shows the basic differences between the Planar KDE and Network KDE for the same spatial point event data. To estimate th density values at a focal point X, the planar KDE treats the whole 2-D space as the context and finds four point events (black circle) within a search bandwidth (i.e. h), whereas the Network KDE only finds two point events within the same bandwidth in the network space based on network distance."
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#the-three-version-of-nkde",
    "href": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#the-three-version-of-nkde",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "The Three version of NKDE",
    "text": "The Three version of NKDE\nSimple method\n\n\nThe first method was proposed by Xie and Yan (2008). Considering the planar KDE, they defined the NKDE with the following formula:\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThis method remains useful for two reasons:\n\nFor quick data visualization. With big datasets, it might be useful to use this simple method to do a primary investigation.\nIn a purely geographical view, this method is intuitive. In the case of crime analysis for example, one could argue that the strength of an event should not be affected by intersections on the network. In that case, the kernel function is seen as a distance decaying function."
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#the-three-version-of-nkde-1",
    "href": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#the-three-version-of-nkde-1",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "The Three version of NKDE",
    "text": "The Three version of NKDE\nDiscontinuous method\n\n\nThis method is introduced by Okabe and Sugihara (2012). The discontinuous NKDE is easily presented by a figure:\n Note that the density of the kernel function is equally divided at intersections.\n\n\n\n\n\n\n\nWarning\n\n\nAs one can see, the values of the NKDE are split at intersections to avoid the multiplication of the mass observed in the simple version. However, this creates a discontinuous NKDE, which is counter-intuitive. It leads to sharp differences between density values in the network, and could be problematic in networks with many intersections."
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#the-three-version-of-nkde-2",
    "href": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#the-three-version-of-nkde-2",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "The Three version of NKDE",
    "text": "The Three version of NKDE\nContinue method\n\n\nThe method merges the best of the two worlds: it adjusts the values of the NKDE at intersections to ensure that it integrates to 1 on its domain, and applies a backward correction to force the density values to be continuous.\nThis process is accomplished by a recursive function. This function is more time consuming, so it might be necessary to stop it when the recursion is too deep. Considering that the kernel density is divided at each intersection, stopping the function at deep level 16 should give results almost identical to the true values.\n\n\nNote that there are three different equations to calculate the kernel density depending on the situation (here, q1, q2, q3).\n\n\n\n\n\n\nNote\n\n\nAs one can see, the values of the NKDE are continuous, and the density values close to the events have been adjusted. This leads to smoother results than the discontinuous method."
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#temporal-network-kernel-density-estimate",
    "href": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#temporal-network-kernel-density-estimate",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "Temporal Network Kernel Density Estimate",
    "text": "Temporal Network Kernel Density Estimate\n\n\nEvents recorded on a network often have a temporal dimension. In that context, one could estimate the density of events in both time and network spaces.\nThe spatio-temporal kernel is calculated as the product of the network kernel density and the time kernel density.\n\nFor a sample point at location l and time t, the Temporal Network Kernel Density Estimate (TNKDE) is calculated as follows:"
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#references",
    "href": "lesson/Lesson03/Lesson03-Advanced_SPPA.html#references",
    "title": "Lesson 3: Advanced Spatial Point Patterns Analysis",
    "section": "References",
    "text": "References\n\nNetwork Kernel Density Estimate\nTemporal Network Kernel Density Estimate"
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#content",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#content",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "Content",
    "text": "Content\n\n\n\nWhat is Spatial Autocorrelation\n\nMeasures of Global Spatial Autocorrelation\nMeasures of Global High/Low Clustering\n\nIntroducing Localised Geospatial Analysis\n\nLocal Indicators of Spatial Association (LISA)\n\nCluster and Outlier Analysis\n\nLocal Moran and Local Geary\nMoran scatterplot\nLISA Cluster Map\n\n\n\n\nHot Spot and Cold Spot Areas Analysis\n\nGetis and Ord’s G-statistics\n\nEmerging Hot Spot Analysis (EHSA)\n\nSpacetime and spacetime cubes\nMann-Kendall Test\nEHSA map"
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#what-is-spatial-autocorrelation",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#what-is-spatial-autocorrelation",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "What is Spatial Autocorrelation",
    "text": "What is Spatial Autocorrelation\n\nToble’s First Law of Geography\nSpatial Dependency\nSpatial Autocorrelation\n\nPositive autocorrelation\nNegative autocorrelation"
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#measures-of-global-spatial-autocorrelation",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#measures-of-global-spatial-autocorrelation",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "Measures of Global Spatial Autocorrelation",
    "text": "Measures of Global Spatial Autocorrelation\n\nMoran’s I\nGeary’s c"
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#measures-of-global-highlow-clustering-getis-ord-global-g",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#measures-of-global-highlow-clustering-getis-ord-global-g",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "Measures of Global High/Low Clustering: Getis-Ord Global G",
    "text": "Measures of Global High/Low Clustering: Getis-Ord Global G\n\n\n\nGetis-Ord Global G statistic is concerned with the overall concentration or lack of concentration in all pairs that are neighbours given the definition of neighbouring areas.\nThe variable must contain only positive values to be used.\n\n\n\nSource: Getis, A., & Ord, K. (1992). “The Analysis of Spatial Association by Use of Distance Statistics”. Geographical Analysis, 24, 189–206."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#local-spatial-autocorrelation-statistics",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#local-spatial-autocorrelation-statistics",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "Local Spatial Autocorrelation Statistics",
    "text": "Local Spatial Autocorrelation Statistics\n\nA collection of geospatial statistical analysis methods for analysing the location related tendency (clusters or outliers) in the attributes of geographically referenced data (points or areas).\nCan be indecies decomposited from their global measures such as local Moran’s I, local Geary’s c, and Getis-Ord Gi*.\nThese spatial statistics are well suited for:\n\ndetecting clusters or outliers;\nidentifying hot spot or cold spot areas;\nassessing the assumptions of stationarity; and\nidentifying distances beyond which no discernible association obtains."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#local-indicator-of-spatial-association-lisa",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#local-indicator-of-spatial-association-lisa",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "Local Indicator of Spatial Association (LISA)",
    "text": "Local Indicator of Spatial Association (LISA)\n\nA subset of localised geospatial statistics methods.\nAny spatial statistics that satisfies the following two requirements (Anselin, L. 1995):\n\nthe LISA for each observation gives an indication of the extent of significant spatial clustering of similar values around that observation;\nthe sum of LISAs for all observations is proportional to a global indicator of spatial association."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#local-morans-i",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#local-morans-i",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "Local Moran’s I",
    "text": "Local Moran’s I\nGiven a geographically referenced attribute field, X the formula of local Moran’s I is:"
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#detecting-hot-and-cold-spot-areas",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#detecting-hot-and-cold-spot-areas",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "Detecting hot and cold spot areas",
    "text": "Detecting hot and cold spot areas\n\n\n\nGiven a set of geospatial features (i.e. points or polygons) and an analysis field, the spatial statistics tell you where features with either high (i.e. hot spots) or low values (cold spots) cluster spatially.\nThe spatial statistic used is called Getis-Ord Gi* statistic (pronounced G-i-star).\nGetis and Ord (1992) define the local G and G∗ statistics for region i (i=1,···,n) as:"
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#fixed-weighting-scheme",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#fixed-weighting-scheme",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "Fixed weighting scheme",
    "text": "Fixed weighting scheme\n\n\n\nThings to consider if fixed distance is used: - All features should have at least one neighbour.\n\nNo feature should have all other features as neighbours.\nEspecially if the values for the input field are skewed, you want features to have about eight neighbors each.\nMight produce large estimate variances where data are sparse, while mask subtle local variations where data are dense.\nIn extreme condition, fixed schemes might not be able to calibrate in local areas where data are too sparse to satisfy the calibration requirements (observations must be more than parameters)."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#adaptive-weighting-schemes",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#adaptive-weighting-schemes",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "Adaptive weighting schemes",
    "text": "Adaptive weighting schemes\n\n\n\nAdaptive schemes adjust itself according to the density of data\n\nShorter bandwidths where data are dense and longer where sparse.\nFinding nearest neighbors are one of the often used approaches.\n\n\n\n]"
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#best-practice-guidelines",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#best-practice-guidelines",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "Best practice guidelines",
    "text": "Best practice guidelines\n\nResults are only reliable if the input feature class contains at least 30 features.\nThe input field mst be in continuous data type such as a count, rate, or other numeric measurement, no categorical attribute field is allowed."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#emerging-hot-spot-analysis-ehsa",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#emerging-hot-spot-analysis-ehsa",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "Emerging Hot Spot Analysis (EHSA)",
    "text": "Emerging Hot Spot Analysis (EHSA)\n\nA technique that falls under exploratory spatial data analysis (ESDA).\nIt combines the traditional ESDA technique of hot spot analysis using the Getis-Ord Gi* statistic with the traditional time-series Mann-Kendall test for monotonic trends.\nThe goal of EHSA is to evaluate how hot and cold spots are changing over time. It helps us answer the questions: are they becoming increasingly hotter, are they cooling down, or are they staying the same?"
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#in-colclusion",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#in-colclusion",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "In colclusion",
    "text": "In colclusion\nSpatial statistics methods are not a blackbox. Before performing the analysis, a geospatial analyst should consider the followings:\n\nWhat is the geographical question?\nWhat is the geospatial feature?\nWhat is the analysis field?\nWhich conceptualization of spatial relationships is appropriate?"
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-GLSA.html#references",
    "href": "lesson/Lesson05/Lesson05-GLSA.html#references",
    "title": "Lesson 5: Global and Local Measures of Spatial Association",
    "section": "References",
    "text": "References\n\nMoran, P. A. P. (1950). “Notes on Continuous Stochastic Phenomena”. Biometrika. 37 (1): 17–23.\nGeary, R.C. (1954) “The Contiguity Ratio and Statistical Mapping”. The Incorporated Statistician, Vol. 5, No. 3, pp. 115-127. - Moran’s I\nGeary’s c - Getis, A., & Ord, K. (1992). “The Analysis of Spatial Association by Use of Distance Statistics”. Geographical Analysis, 24, 189–206.\nAnselin, L. (1995). “Local indicators of spatial association – LISA”. Geographical Analysis, 27(4): 93-115.\nGetis, A. and Ord, J.K. (1992) “The analysis of spatial association by use of distance statistics”. Geographical Analysis, 24(3): 189-206.\nOrd, J.K. and Getis, A. (2010) “Local spatial autocorrelation statistics: Distributional issues and an application”. Geographical Analysis, 27(4): 286-306."
  },
  {
    "objectID": "lesson.html",
    "href": "lesson.html",
    "title": "Weekly Lesson Plan",
    "section": "",
    "text": "Week\nDate\nTopic\nStudent Assignment\n\n\n\n\n1\n26/8/2024\nIntroduction to Geospatial Analytics\n\n\n\n2\n2/9/2024\nSpatial Point Patterns Analysis (SPAA)\n\n\n\n3\n9/9/2024\nAdvanced Spatial Point Patterns Analysis\n\n\n\n4\n16/9/2024\nSpatial Weights and Applications\n\n\n\n5\n23/9/2024\nGlobal and Local Measures of Spatial Association\n\n\n\n6\n30/9/2024\nGeographic Segmentation\n\n\n\n\n7/10/2024\n\n\n\n\n7\n14/10/2024\nGeographically Weighted Explanatory Models\n\n\n\n8\n21/10/2024\nGeographically Weighted Predictive Models\n\n\n\n9\n28/10/2024\nModelling Geographic of Accessibility\n\n\n\n10\n4/11/2024\nSpatial Interaction Models"
  },
  {
    "objectID": "outline/Lesson02_outline.html",
    "href": "outline/Lesson02_outline.html",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern, or distribution, of a set of points on a surface. It can refer to the actual spatial or temporal location of these points or also include data from point sources. It is one of the most fundamental concepts in geography and spatial analysis. This lesson aims to share with you the basic concepts and methods of Spatial Point Pattern Analysis. You will also gain hands experience on using spatstat, an R package specially designed for Spatial Point Pattern Analysis."
  },
  {
    "objectID": "outline/Lesson02_outline.html#content",
    "href": "outline/Lesson02_outline.html#content",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Content",
    "text": "Content\n\nIntroducing Spatial Point Patterns\n\nThe basic concepts of spatial point patterns\nSpatial Point Patterns in real world\n\n1st Order Spatial Point Patterns Analysis\n\nKernel Density Estimation (KDE)\n\n2nd Order Spatial Point Patterns Analysis\n\nNearest Neighbour Index\nG-function\nF-function\nK-function\nL-function"
  },
  {
    "objectID": "outline/Lesson02_outline.html#lesson-slides",
    "href": "outline/Lesson02_outline.html#lesson-slides",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Lesson Slides",
    "text": "Lesson Slides\n\nLesson 2 slides."
  },
  {
    "objectID": "outline/Lesson02_outline.html#hands-on-exercise",
    "href": "outline/Lesson02_outline.html#hands-on-exercise",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Hands-on Exercise",
    "text": "Hands-on Exercise\n\nChapter 4: 1st Order Spatial Point Patterns Analysis Methods\nChapter 5: 2nd Order Spatial Point Patterns Analysis Methods"
  },
  {
    "objectID": "outline/Lesson02_outline.html#core-readings",
    "href": "outline/Lesson02_outline.html#core-readings",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "Core Readings",
    "text": "Core Readings\n\nYuan, Y., Qiang, Y., Bin Asad, K., and Chow, T. E. (2020). Point Pattern Analysis. The Geographic Information Science & Technology Body of Knowledge (1st Quarter 2020 Edition), John P. Wilson (ed.). DOI: 10.22224/gistbok/2020.1.13.\nYin, P. (2020). Kernels and Density Estimation. The Geographic Information Science & Technology Body of Knowledge (1st Quarter 2020 Edition), John P. Wilson (ed.). DOI: 10.22224/gistbok/2020.1.12\nChapter 7 Spatial Point Pattern Analysis of Roger S. Bivand, Edzer Pebesma and Virgilio Gómez-Rubio (2013) Applied Spatial Data Analysis with R (2nd Edition), Springer.\n\n\nEnrichment Resources\nProf. Luc Anselin on point pattern analysis (YouTube):\n\nPoint Pattern Analysis Concepts\nPoint Pattern Analysis: Clustered, Regular and Dispersed Patterns\nPoint Pattern Analysis: Nearest Neighbor Statistics\nPoint Pattern Analysis: Quadrat Counts\nPoint Pattern Analysis: F and J Functions\nPoint Pattern Analysis: K, L and Kd Functions"
  },
  {
    "objectID": "outline/Lesson02_outline.html#references",
    "href": "outline/Lesson02_outline.html#references",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "References",
    "text": "References\n\nO’Sullivan, D., and Unwin, D. (2010) Geographic Information Analysis, Second Edition. John Wiley & Sons Inc., New Jersey, Canada. Chapter 5-6.\nBaddeley A., Rubak E. and Turner R. (2015) Spatial Point Patterns: Methodology and Applications with R, Chapman and Hall/CRC.\nChapter 11 Point Pattern Analysis of Intro to GIS and Spatial Analysis. Section 11.2, 11.3, 11.3.1 and 11.4 • Ripley’s K-function.\n\n\nApplications\n\nNaveen Donthu and Roland T. Rust (1989) “Estimating Geographic Customer Densities Using Kernel Density Estimation”, Marketing Science, Vol. 8, No. 2, pp. 191-203.\nJoseph Wartman and Nicholas E. Malasavage (2010). “Spatial Analysis for Identifying Concentrations of Urban Damage” in Methods and Techniques in Urban Engineering, Armando Carlos de Pina Filho and Aloisio Carlos dePina (Ed.), ISBN: 978-953-307-096-4, InTech.\nGiuseppe Borruso and Andrea Porceddu (2009) “A Tale of Two Cities: Density Analysis of CBD on Two Midsize Urban Areas in Northeastern Italy” in Murgante, Beniamino; Borruso, Giuseppe & Lapucci, Alessandra (2009) Studies in Computational Intelligence, Geocomputation and Urban Planning, pp.37-56."
  },
  {
    "objectID": "outline/Lesson02_outline.html#all-about-r",
    "href": "outline/Lesson02_outline.html#all-about-r",
    "title": "Lesson 2: Spatial Point Patterns Analysis",
    "section": "All About R",
    "text": "All About R\n\nspatstat at R Cran\n\nspatstat resource."
  },
  {
    "objectID": "outline/Lesson04_outline.html",
    "href": "outline/Lesson04_outline.html",
    "title": "Lesson 4: Spatial Weights and Applications",
    "section": "",
    "text": "Computing spatial weight is an essential step toward measuring the strength of the spatial relationships between objects. In this lesson, the basic concept of spatial weight will be introduced. This is followed by a discussion of methods to compute spatial weights."
  },
  {
    "objectID": "outline/Lesson04_outline.html#content",
    "href": "outline/Lesson04_outline.html#content",
    "title": "Lesson 4: Spatial Weights and Applications",
    "section": "Content",
    "text": "Content\n\nTobler’s First law of Geography\nPrinciples of Spatial Autocorrelation\nConcepts of Spatial Proximity and Spatial Weights\n\nContiguity-Based Spatial Weights: Rook’s & Queen’s\nDistance-Band Spatial Weights: fixed and adaptive\n\nApplications of Spatial Weights\n\nSpatially lagged variables\nGeographically Weighted Summary Statistics\nSpatially lagged rates"
  },
  {
    "objectID": "outline/Lesson04_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson04_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 4: Spatial Weights and Applications",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson 4 slides.\nHands-on Exercise 4\n\n\nSelf-reading Before Meet-up\nTo read before class:\n\nChapter 2. Codifying the neighbourhood structure of Handbook of Spatial Analysis: Theory and Application with R.\n\nAlternatively\n\nChapter 9: Modelling Areal Data of Applied Spatial Data Analysis with R (2nd Edition). This book is available in smu digital library. Until section 9.3.1."
  },
  {
    "objectID": "outline/Lesson04_outline.html#references",
    "href": "outline/Lesson04_outline.html#references",
    "title": "Lesson 4: Spatial Weights and Applications",
    "section": "References",
    "text": "References\n\nFrançois Bavaud (2010) “Models for Spatial Weights: A Systematic Look” Geographical Analysis, Vol. 30, No.2, pp 153-171.\nTony H. Grubesic and Andrea L. Rosso (2014) “The Use of Spatially Lagged Explanatory Variables for Modeling Neighborhood Amenities and Mobility in Older Adults”, Cityscape, Vol. 16, No. 2, pp. 205-214."
  },
  {
    "objectID": "outline/Lesson04_outline.html#all-about-r",
    "href": "outline/Lesson04_outline.html#all-about-r",
    "title": "Lesson 4: Spatial Weights and Applications",
    "section": "All About R",
    "text": "All About R\n\nspdep package\n\ndnearneigh()\nknearneigh()"
  },
  {
    "objectID": "outline/Lesson06_outline.html#content",
    "href": "outline/Lesson06_outline.html#content",
    "title": "Lesson 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "Content",
    "text": "Content\n\nBasic concepts of geographic segmentation\nConventional cluster analysis techniques\nApproaches for clustering geographically referenced data\n\nHierarchical clustering with spatial constraints\nMinimum spanning trees\nClustGeo method"
  },
  {
    "objectID": "outline/Lesson06_outline.html#lesson-slides",
    "href": "outline/Lesson06_outline.html#lesson-slides",
    "title": "Lesson 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "Lesson slides",
    "text": "Lesson slides\n\nLesson 6: Geographic Segmentation with Spatially Constrained Cluster Analysis slides."
  },
  {
    "objectID": "outline/Lesson06_outline.html#hands-on-exercise",
    "href": "outline/Lesson06_outline.html#hands-on-exercise",
    "title": "Lesson 6: Geographic Segmentation with Spatially Constrained Cluster Analysis",
    "section": "Hands-on Exercise",
    "text": "Hands-on Exercise\n\n12 Geographical Segmentation with Spatially Constrained Clustering Techniques\n\n\nSelf-reading Before Meet-up\nTo read before class:\n\nAssuncao, R. M., Neves, M.C., Camara, G. and Costa Freitas, C.D. 2006. “Efficient Regionalization Techniques for Socio-Economic Geographical Units Using Minimum Spanning Trees”. International Journal of Geographical Information Science 20: 797-811. (Available in SMU digital library)\nChavent, M., Kuentz-Simonet, V., Labenne,A. and Saracco, J. 2018. “ClustGeo: an R package for hierarchical clustering with spatial constraints” Computational Statistics, 33: 1799-1822. (Available in SMU digital library)\n\n\n\nReferences\n\nRovan, J. and Sambt, J. (2003) “Socio-economic Differences Among Slovenian Municipalities: A Cluster Analysis Approach”, Developments in Applied Statistics, pp. 265-278.\n\nDemeter, T. and Bratucu, G. (2013) “Statistical Analysis Of The EU Countries from A Touristic Point of View”, Bulletin of the Transilvania University of Braşov, 6(55): 121-130.\nBrown, N.S. & Watson, P. (2012) “What can a comprehensive plan really tell us about a region?: A cluster analysis of county comprehensive plans in Idaho”, Western Economics Forum. Pp.22-37.\nJaya, I.G.M., Ruchjana, B.N., Andriyana, Y. & Agata, R (2019) “Clustering with spatial constraints: The case of diarrhea in Bandung city, Indonesia”\nde Souza, D. C. & Taconeli, C. A. (2022) “Spatial and non-spatial clustering algorithm in the analysis of Brazilian educational data”, Communications in Statistics: Case Studies, Data Analysis, and Applications. Vol. 8, No. 4, 588-606. (Available in SMU digital library)\n\n\n\nAll About R\n\nHierarchical Cluster Analysis.\nskater: A function from spdep package that implements a SKATER procedure for spatial clustering analysis.\nClustGeo: Hierarchical Clustering with Spatial Constraints\n\nIntroduction to Clustgeo"
  },
  {
    "objectID": "outline/Lesson08_outline.html",
    "href": "outline/Lesson08_outline.html",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "",
    "text": "What is Predictive Modelling?\nWhat is Geospatial Predictive Modelling\nIntroducing Recursive Partitioning\nAdvanced Recursive Partitioning: Random Forest\nIntroducing Geographically Weighted Random Forest"
  },
  {
    "objectID": "outline/Lesson08_outline.html#content",
    "href": "outline/Lesson08_outline.html#content",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "",
    "text": "What is Predictive Modelling?\nWhat is Geospatial Predictive Modelling\nIntroducing Recursive Partitioning\nAdvanced Recursive Partitioning: Random Forest\nIntroducing Geographically Weighted Random Forest"
  },
  {
    "objectID": "outline/Lesson08_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson08_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson 8 slides.\nHandout of Hands-on Exercise 8.\n\n\nSelf-reading Before Meet-up\nTo read before class:\n\nStefanos Georganos et. al. (2019) “Geographical Random Forests: A Spatial Extension of the Random Forest Algorithm to Address Spatial Heterogeneity in Remote Sensing and Population Modelling”, Geocarto International, DOI: 10.1080/10106049.2019.1595177.\nGeorganos, S. and Kalogirou, S. (2022) “A Forest of Forests: A Spatially Weighted and Computationally Efficient Formulation of Geographical Random Forests”. ISPRS, International Journal of Geo-Information, 2022, 11, 471. https://www.mdpi.com/2220-9964/11/9/471\n\n\n\nReferences\n\nGeorge Grekousis et. al. (2022) “Ranking the importance of demographic, socioeconomic, and underlying health factors on US COVID-19 deaths: A geographical random forest approach”, Health and Place, vol. 74, pp. 1-12.\nYaowen Luo, Jianguo Yan & Stephen McClure. (2020) “Distribution of the environmental and socioeconomic risk factors on COVID-19 death rate across continental USA: a spatial nonlinear analysis”, Environmental Science and Pollution Research, 28:6587–6599.\nEun-Hee Koh, Eunhee Lee, & Kang-Kun Lee (2020) “Application of geographically weighted regression models to predict spatial characteristics of nitrate contamination: Implications for an effective groundwater management strategy”, Journal of Environmental Management. Vol. 268\n\n\n\nAll About R\n\nSpatialML"
  },
  {
    "objectID": "outline/Lesson10_outline.html",
    "href": "outline/Lesson10_outline.html",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "",
    "text": "In this lesson, you will learn the basic concepts and methods of Spatial Interaction Models."
  },
  {
    "objectID": "outline/Lesson10_outline.html#content",
    "href": "outline/Lesson10_outline.html#content",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Content",
    "text": "Content\n\nBasic Concepts of Spatial Interaction Models\n\nA Family of Gravity Models\n\nUnconstrained\nOrigin constrained\nDestination constrained\nDoubly constrained\n\nStatistical Approach\nInterpreting and Visualising Modelling Results\n\nSpatial Econometric Interaction Models\n\nThe general formula\n\nWhat is Econometrics?\nWhat is Spatial Econometrics?\n\nSpatial Econometric Interaction Model Specifications"
  },
  {
    "objectID": "outline/Lesson10_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson10_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson 10 slides in html format.\nHands-on Exercise 10a: Processing and Visualising Flow Data.\nHands-on Exercise 10b: Calibrating Spatial Interaction Models with R."
  },
  {
    "objectID": "outline/Lesson10_outline.html#self-reading-before-meet-up",
    "href": "outline/Lesson10_outline.html#self-reading-before-meet-up",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Self-reading Before Meet-up",
    "text": "Self-reading Before Meet-up\nRead before lesson:\n\nKingsley E. Haynes and A. Stewart Fotheringham (2020) Gravity and Spatial Interaction Models, Web Book of Regional Science. Chapter 1 and Sub-section 2.2.\nFarmer, C. and Oshan, T. (2017). “Spatial interaction”. The Geographic Information Science & Technology Body of Knowledge (4th Quarter 2017 Edition), John P. Wilson (ed.). DOI: 10.22224/gistbok/2017.4.5 (link is external)\nFlowerdew R, Aitkin M (1982) “A method of fitting the gravity model based on the Poisson distribution”. Journal of Regional Science, 22: 191–202.\n” Chapter 6. Spatial econometrics - common models”, Handbook of Spatial Analysis.\nJames P. LeSage and R. Kelley Pace (2008) “Spatial Econometric Modeling of Origin-Destination Flows”. Journal of Regional Science, Vol. 48, No. 5, pp. 941-967."
  },
  {
    "objectID": "outline/Lesson10_outline.html#reference",
    "href": "outline/Lesson10_outline.html#reference",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Reference",
    "text": "Reference\n\nPavel KLAPKA, et. al. (2013) “The Footfall of Shopping Centre in Olomouc (CZECH REPUBLIC): An Application of The Gravity Model”, Moravian Geographical Reports, Vol 21, pp. 12-26.\n\nYang Yue et. al. (2012) “Exploratory calibration of a spatial interaction model using taxi GPS trajectories”, Computers, Environment and Urban Systems, 36 (2012) 140–153.\nMorito Tsutsumi and Kazuki Tamesue (2012) “Intraregional flow problem in spatial econometric model for origin-destination flows”, Environment and Planning B: Planning and Design, Vol. 39, pp. 1006-1015. Access via SMU e-journal."
  },
  {
    "objectID": "outline/Lesson10_outline.html#all-about-r",
    "href": "outline/Lesson10_outline.html#all-about-r",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "All About R:",
    "text": "All About R:\n\nPaul Roback and Julie Legler (2020) Beyond Multiple Linear Regression: Applied Generalized Linear Models and Multilevel Models in R, CRC Press. On line version (January 26, 2021). Chapter 4\nNegative Binomial Regression and Poisson Regression from UCLA Institute for Digital Research & Education.\nspflow\nHome-to-work commuting flows within the municipalities around Paris"
  },
  {
    "objectID": "Quarto.html",
    "href": "Quarto.html",
    "title": "All About Quarto",
    "section": "",
    "text": "Getting Started\nRStudio IDE\nUsing R\nHTML Basics"
  },
  {
    "objectID": "Quarto.html#overview",
    "href": "Quarto.html#overview",
    "title": "All About Quarto",
    "section": "",
    "text": "Getting Started\nRStudio IDE\nUsing R\nHTML Basics"
  },
  {
    "objectID": "Quarto.html#create-websites-and-blogs",
    "href": "Quarto.html#create-websites-and-blogs",
    "title": "All About Quarto",
    "section": "Create websites and blogs",
    "text": "Create websites and blogs\n\nCreating a Website\nWebsite Navigation\nDocument Listings"
  },
  {
    "objectID": "Quarto.html#authoring-guide",
    "href": "Quarto.html#authoring-guide",
    "title": "All About Quarto",
    "section": "Authoring Guide",
    "text": "Authoring Guide\n\nMarkdown Basics\nFigures\nTables\nDiagrams\nCitations & Footnotes\nCross References\nArticle Layout"
  },
  {
    "objectID": "Quarto.html#useful-web-resources",
    "href": "Quarto.html#useful-web-resources",
    "title": "All About Quarto",
    "section": "Useful web resources",
    "text": "Useful web resources\n\nAwesome Quarto. This github repository provides a comprehensive listing of Quarto resources. It should be the second stop (after Quarto homepage) if you need to look for revelent materials about Quarto."
  },
  {
    "objectID": "Take-home_Ex01.html",
    "href": "Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "According to World Health Organisation (WHO), road traffic accidents cause the death of approximately 1.19 million people each year leave between 20 and 50 million people with non-fatal injuries. More than half of all road traffic deaths occur among vulnerable road users, such as pedestrians, cyclists and motorcyclists.\nRoad traffic injuries are the leading cause of death for children and young adults aged 5–29. Yet two thirds of road traffic fatalities occur among people of working age (18–59 years). Nine in 10 fatalities on the roads occur in low- and middle-income countries, even though these countries have around 60% of the world’s vehicles.\nIn addition to the human suffering caused by road traffic injuries, they also incur a heavy economic burden on victims and their families, both through treatment costs for the injured and through loss of productivity of those killed or disabled. More broadly, road traffic injuries have a serious impact on national economies, costing countries 3% of their annual gross domestic product.\nThailand’s roads are the deadliest in Southeast Asia and among the worst in the world, according to the World Health Organisation. About 20,000 people die in road accidents each year, or about 56 deaths a day (WHO).\nBetween 2014 and 2021, Thailand experienced a notable increase in accident frequencies. Specifically, 19% of all accidents in Thailand occurred on the national highways, which constituted the primary public thoroughfares connecting various regions, provinces, districts, and significant locations within a comprehensive network. Within the broader context of accidents across the country, there existed a considerable 66% likelihood of encountering accident-prone zones, often termed ‘black spots,’ distributed as follows: 66% on straight road segments, 13% at curves, 6% at median points of cross-shaped intersections, 5% at T-shaped intersections and Y-shaped intersections, 3% at cross-shaped intersections, 2% on bridges, and 2% on steep slopes, respectively."
  },
  {
    "objectID": "Take-home_Ex01.html#setting-the-scene",
    "href": "Take-home_Ex01.html#setting-the-scene",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "According to World Health Organisation (WHO), road traffic accidents cause the death of approximately 1.19 million people each year leave between 20 and 50 million people with non-fatal injuries. More than half of all road traffic deaths occur among vulnerable road users, such as pedestrians, cyclists and motorcyclists.\nRoad traffic injuries are the leading cause of death for children and young adults aged 5–29. Yet two thirds of road traffic fatalities occur among people of working age (18–59 years). Nine in 10 fatalities on the roads occur in low- and middle-income countries, even though these countries have around 60% of the world’s vehicles.\nIn addition to the human suffering caused by road traffic injuries, they also incur a heavy economic burden on victims and their families, both through treatment costs for the injured and through loss of productivity of those killed or disabled. More broadly, road traffic injuries have a serious impact on national economies, costing countries 3% of their annual gross domestic product.\nThailand’s roads are the deadliest in Southeast Asia and among the worst in the world, according to the World Health Organisation. About 20,000 people die in road accidents each year, or about 56 deaths a day (WHO).\nBetween 2014 and 2021, Thailand experienced a notable increase in accident frequencies. Specifically, 19% of all accidents in Thailand occurred on the national highways, which constituted the primary public thoroughfares connecting various regions, provinces, districts, and significant locations within a comprehensive network. Within the broader context of accidents across the country, there existed a considerable 66% likelihood of encountering accident-prone zones, often termed ‘black spots,’ distributed as follows: 66% on straight road segments, 13% at curves, 6% at median points of cross-shaped intersections, 5% at T-shaped intersections and Y-shaped intersections, 3% at cross-shaped intersections, 2% on bridges, and 2% on steep slopes, respectively."
  },
  {
    "objectID": "Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex01.html#objectives",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Objectives",
    "text": "Objectives\nBy and large, road traffic accidents can be attributed by two major factors, namely: behavioural and environmental factors. Behavioural factors in driving are considered to be major causes of traffic accidents either in direct or indirect manner (Lewin, 1982). These factors can be further grouped into two as, driver behavior (also called driver/driving style) and driver performance, in other words, driver/driving skills (Elander, West, & French, 1993). Environmental factors, on the other hand, includes but not limited to weather condition such as poor visibility during heavy rain or foggy and road conditions such as sharp bend road, slippery slope road, and blind spot.\nPrevious studies have demonstrated the significant potential of Spatial Point Patterns Analysis (SPPA) in exploring and identifying factors influencing road traffic accidents. However, these studies often focus solely on either behavioral or environmental factors, with limited consideration of temporal factors such as season, day of the week, or time of day.\nIn view of this, you are tasked to discover factors affecting road traffic accidents in the Bangkok Metropolitan Region BMR by employing both spatial spatio-temporal point patterns analysis methods.\nThe specific objectives of this take-home exercise are as follows:\n\nTo visualize the spatio-temporal dynamics of road traffic accidents in BMR using appropriate statistical graphics and geovisualization methods.\nTo conduct detailed spatial analysis of road traffic accidents using appropriate Network Spatial Point Patterns Analysis methods.\nTo conduct detailed spatio-temporal analysis of road traffic accidents using appropriate Temporal Network Spatial Point Patterns Analysis methods."
  },
  {
    "objectID": "Take-home_Ex01.html#the-data",
    "href": "Take-home_Ex01.html#the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "The Data",
    "text": "The Data\nFor the purpose of this exercise, three basic data sets must be used, they are:\n\nThailand Road Accident [2019-2022] on Kaggle\nThailand Roads (OpenStreetMap Export) on HDX.\nThailand - Subnational Administrative Boundaries on HDX.\n\nStudents are free to include other data sets if they help in the study."
  },
  {
    "objectID": "Take-home_Ex01.html#grading-criteria",
    "href": "Take-home_Ex01.html#grading-criteria",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Grading Criteria",
    "text": "Grading Criteria\nThis exercise will be graded by using the following criteria:\n\nGeospatial Data Wrangling (20 marks): This is an important aspect of geospatial analytics. You will be assessed on your ability to employ appropriate R functions from various R packages specifically designed for modern data science such as readr, tidyverse (tidyr, dplyr, ggplot2), sf just to mention a few of them, to perform the entire geospatial data wrangling processes, including. This is not limited to data import, data extraction, data cleaning and data transformation. Besides assessing your ability to use the R functions, this criterion also includes your ability to clean and derive appropriate variables to meet the analysis need.\n\n\n\n\n\n\n\nWarning\n\n\n\nAll data are like vast grassland full of land mines. Your job is to clear those mines and not to step on them).\n\n\n\nGeospatial Analysis (25 marks): In this exercise, you are expected to utilize the geospatial analytics methods introduced in class, along with the R packages provided during the hands-on exercises, to perform your analysis. You will be assessed on your ability to apply these methods correctly and to provide accurate interpretations and discussions of the analysis results.\nGeovisualisation and Geocommunication (25 marks): In this section, your ability to effectively communicate complex geospatial analysis results through user-friendly visual representations will be assessed. Since this course is focused on geospatial analysis, it is crucial that you demonstrate proficiency in using appropriate geovisualization techniques to clearly convey the findings of your analysis.\nReproducibility (20 marks): This is a key learning outcome of this course. You will be assessed on your ability to thoroughly document the analysis procedures using code chunks within Quarto. It is important to note that simply providing the code chunks is insufficient; you must also include explanations of the purpose behind each step and the R function(s) used.\nBonus (10 marks): Demonstrate your ability to employ methods beyond what you had learned in class to gain insights from the data. The methods used must be geospatial in nature."
  },
  {
    "objectID": "Take-home_Ex01.html#submission-instructions",
    "href": "Take-home_Ex01.html#submission-instructions",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Submission Instructions",
    "text": "Submission Instructions\n\nThe write-up of the take-home exercise must be in Quarto html document format. You are required to publish the write-up on Netlify.\nThe R project of the take-home exercise must be pushed onto your Github repository.\nYou are required to provide the links to Netlify service of the take-home exercise write-up and github repository on eLearn."
  },
  {
    "objectID": "Take-home_Ex01.html#due-date",
    "href": "Take-home_Ex01.html#due-date",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Due Date",
    "text": "Due Date\n22nd September 2024 (Sunday), 11.59pm (midnight)."
  },
  {
    "objectID": "Take-home_Ex01.html#references",
    "href": "Take-home_Ex01.html#references",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "References",
    "text": "References\n\nWHO (2023) Road traffic injuries\nRoad traffic deaths and injuries in Thailand\nLewin, I. (1982). Driver training: A perceptual-motor skill approach. Ergonomics, 25(10), 917–924.\nElander, J., West, R., & French, D. (1993). Behavioral correlates of individual differences in road-traffic crash risk: An examination of methods and findings. Psychological Bulletin, 113(2), 279."
  },
  {
    "objectID": "Take-home_Ex01.html#survival-tips",
    "href": "Take-home_Ex01.html#survival-tips",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Survival Tips",
    "text": "Survival Tips"
  },
  {
    "objectID": "Take-home_Ex01.html#learning-from-seniors",
    "href": "Take-home_Ex01.html#learning-from-seniors",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "Learning from seniors",
    "text": "Learning from seniors\n\nCHAI ZHIXUAN  This is one of the two submission that includes steps on how to download the Passenger O-D data by using LTA DataMall API and opensource Postmen. Refer to sub-section 3.1.1 Aspatial data. Although it is incomplete (Step 3 :)) but still one of the best.\n\nKRISTINE JOY PAAS  Have done well in all five grading criteria especially the reproducibility, geovisualisation and geocommunication criteria. Geospatial Analytics criterion can be improved by including a paragraph describing the purpose, concepts and methods of the geospatial analytics used.\nKYLIE TAN JING YI  Section 5: Spatial Association Analysis of this submission provides a comprehensive discussion of the methods used and analysis results.\nMUHAMAD AMEER NOOR  Have done well in all five grading criteria including a short write-up of the geospatial analytics methods used.\nNEO YI XIN This submission put function programming of R into good used. For example, subsection Processing the aspatial OD data for processing data with same structure repetitively, Task 1: Geovisulisation and Analysis to ensure that a same classification scale are used. Further more Sub-section Computing Distance-Based Spatial Weights Matrix serves as a good example on how to discussion geospatial analytics methods used. There are at least three other students did show the spatial weights map but they are way too messy."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-gwr.html#content",
    "href": "lesson/Lesson07/Lesson07-gwr.html#content",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "Content",
    "text": "Content\n\nIntroducing Regression Modelling\n\nSimple Linear Regression\nMultiple Linear Regression\n\nWhat is Spatial Non-stationary\nIntroducing Geographically Weighted Regression\n\nWeighting functions (kernel)\nWeighting schemes\nBandwidth\n\nInterpreting and Visualising"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-gwr.html#the-why-questions",
    "href": "lesson/Lesson07/Lesson07-gwr.html#the-why-questions",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "The WHY Questions",
    "text": "The WHY Questions\n\nWhy some condominium units were transacted at relatively higher prices than others?"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-gwr.html#the-why-questions-1",
    "href": "lesson/Lesson07/Lesson07-gwr.html#the-why-questions-1",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "The WHY Questions",
    "text": "The WHY Questions\nWhy condominium units located at the central part of Singapore were transacted at relatively higher prices than others?"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-gwr.html#what-is-regression-analysis",
    "href": "lesson/Lesson07/Lesson07-gwr.html#what-is-regression-analysis",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "What is regression analysis?",
    "text": "What is regression analysis?\n\nA set of statistical processes for explaining the relationships among variables.\nThe focus is on the relationship between a dependent variable (y) and one or more independent variables (x)\n\nDoes X affect Y? If so, how?\nWhat is the change in Y given a one unit change in X?\n\nEstimate outcomes based on the relationships modelled."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-gwr.html#assumptions-of-linear-regression-models",
    "href": "lesson/Lesson07/Lesson07-gwr.html#assumptions-of-linear-regression-models",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "Assumptions of linear regression models",
    "text": "Assumptions of linear regression models\n\nLinearity assumption. The relationship between the dependent variable and independent variables is (approximately) linear.\nNormality assumption. The residual errors are assumed to be normally distributed.\nHomogeneity of residuals variance. The residuals are assumed to have a constant variance (homoscedasticity).\nThe residuals are uncorrelated with each other.\n\nserial correlation, as with time series\n\n(Optional) The errors (residuals) are normally distributed and have a 0 population mean.]"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-gwr.html#spatial-non-stationary",
    "href": "lesson/Lesson07/Lesson07-gwr.html#spatial-non-stationary",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "Spatial Non-stationary",
    "text": "Spatial Non-stationary\n\nWhen applied to spatial data, as can be seen, it assumes a stationary spatial process.\n\nThe same stimulus provokes the same response in all parts of the study region.\nHighly untenable for spatial process."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-gwr.html#geographically-weighted-regression-gwr",
    "href": "lesson/Lesson07/Lesson07-gwr.html#geographically-weighted-regression-gwr",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "Geographically Weighted Regression (GWR)",
    "text": "Geographically Weighted Regression (GWR)\n\nLocal statistical technique to analyze spatial variations in relationships.\nSpatial non-stationarity is assumed and will be tested.\nBased on the “First Law of Geography”: everything is related with everything else, but closer things are more related."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-gwr.html#references",
    "href": "lesson/Lesson07/Lesson07-gwr.html#references",
    "title": "Lesson 7: Geographically Weighted Regression",
    "section": "References",
    "text": "References\nBrunsdon, C., Fotheringham, A.S., and Charlton, M. (2002) “Geographically weighted regression: A method for exploring spatial nonstationarity”. Geographical Analysis, 28: 281-289.\nBrunsdon, C., Fotheringham, A.S. and Charlton, M., (1999) [“Some Notes on Parametric Significance Tests for Geographically Weighted Regression”](https://onlinelibrary-wiley-com.libproxy.smu.edu.sg/doi/abs/10.1111/0022-4146.00146. Journal of Regional Science, 39(3), 497-524.\nMennis, Jeremy (2006) “Mapping the Results of Geographically Weighted Regression”, The Cartographic Journal, Vol.43 (2), p.171-179.\nStephen A. Matthews ; Tse-Chuan Yang (2012) “Mapping the results of local statistics: Using geographically weighted regression”, Demographic Research, Vol.26, p.151-166."
  },
  {
    "objectID": "lesson/Lesson08/Lesson09-GWRF.html#content",
    "href": "lesson/Lesson08/Lesson09-GWRF.html#content",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "Content",
    "text": "Content\n\nWhat is Predictive Modelling?\nWhat is Geospatial Predictive Modelling\nIntroducing Recursive Partitioning\nAdvanced Recursive Partitioning: Random Forest\nIntroducing Geographically Weighted Random Forest"
  },
  {
    "objectID": "lesson/Lesson08/Lesson09-GWRF.html#what-is-predictive-modelling",
    "href": "lesson/Lesson08/Lesson09-GWRF.html#what-is-predictive-modelling",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "What is Predictive Modelling?",
    "text": "What is Predictive Modelling?\n\n\n\nPredictive modelling uses statistical learning or machine learning techniques to predict outcomes.\n\nBy and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models."
  },
  {
    "objectID": "lesson/Lesson08/Lesson09-GWRF.html#what-is-geospatial-predictive-modelling",
    "href": "lesson/Lesson08/Lesson09-GWRF.html#what-is-geospatial-predictive-modelling",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "What is Geospatial Predictive Modelling",
    "text": "What is Geospatial Predictive Modelling\n\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution.\n\nWhen geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur.\nGeospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences."
  },
  {
    "objectID": "lesson/Lesson08/Lesson09-GWRF.html#predictive-modelling-process",
    "href": "lesson/Lesson08/Lesson09-GWRF.html#predictive-modelling-process",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "Predictive Modelling Process",
    "text": "Predictive Modelling Process"
  },
  {
    "objectID": "lesson/Lesson08/Lesson09-GWRF.html#introducing-recursive-partitioning",
    "href": "lesson/Lesson08/Lesson09-GWRF.html#introducing-recursive-partitioning",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "Introducing recursive partitioning",
    "text": "Introducing recursive partitioning\n\nA predictive methodology involving a dependent variable y and one and more predictors.\nThe dependent variable can be either a continuous or categorical scales.\nRules partition data into mutually exclusive groups.\nNo need to worry about transformations such as logs.\nNo prior distribution requirement."
  },
  {
    "objectID": "lesson/Lesson08/Lesson09-GWRF.html#advanced-recursive-partitioning-random-forest",
    "href": "lesson/Lesson08/Lesson09-GWRF.html#advanced-recursive-partitioning-random-forest",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "Advanced Recursive Partitioning: Random Forest",
    "text": "Advanced Recursive Partitioning: Random Forest\nRandom forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble.\n\nEach individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction as shown the figure."
  },
  {
    "objectID": "lesson/Lesson08/Lesson09-GWRF.html#introducing-geographically-weighted-random-forest-gwrf",
    "href": "lesson/Lesson08/Lesson09-GWRF.html#introducing-geographically-weighted-random-forest-gwrf",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "Introducing Geographically Weighted Random Forest (gwRF)",
    "text": "Introducing Geographically Weighted Random Forest (gwRF)\n\nGeographically Weighted Random Forest (GRF) is a spatial analysis method using a local version of the famous Machine Learning algorithm.\n\nThis technique adopts the idea of the Geographically Weighted Regression.\nThe main difference between a tradition (linear) GWR and GRF is that we can model non-stationarity coupled with a flexible non-linear model which is very hard to overfit due to its bootstrapping nature, thus relaxing the assumptions of traditional Gaussian statistics."
  },
  {
    "objectID": "lesson/Lesson08/Lesson08-GWRF.html#content",
    "href": "lesson/Lesson08/Lesson08-GWRF.html#content",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "Content",
    "text": "Content\n\nWhat is Predictive Modelling?\nWhat is Geospatial Predictive Modelling\nIntroducing Recursive Partitioning\nAdvanced Recursive Partitioning: Random Forest\nIntroducing Geographically Weighted Random Forest"
  },
  {
    "objectID": "lesson/Lesson08/Lesson08-GWRF.html#what-is-predictive-modelling",
    "href": "lesson/Lesson08/Lesson08-GWRF.html#what-is-predictive-modelling",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "What is Predictive Modelling?",
    "text": "What is Predictive Modelling?\n\n\n\nPredictive modelling uses statistical learning or machine learning techniques to predict outcomes.\n\nBy and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models."
  },
  {
    "objectID": "lesson/Lesson08/Lesson08-GWRF.html#what-is-geospatial-predictive-modelling",
    "href": "lesson/Lesson08/Lesson08-GWRF.html#what-is-geospatial-predictive-modelling",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "What is Geospatial Predictive Modelling",
    "text": "What is Geospatial Predictive Modelling\n\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution.\n\nWhen geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur.\nGeospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences."
  },
  {
    "objectID": "lesson/Lesson08/Lesson08-GWRF.html#predictive-modelling-process",
    "href": "lesson/Lesson08/Lesson08-GWRF.html#predictive-modelling-process",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "Predictive Modelling Process",
    "text": "Predictive Modelling Process"
  },
  {
    "objectID": "lesson/Lesson08/Lesson08-GWRF.html#introducing-recursive-partitioning",
    "href": "lesson/Lesson08/Lesson08-GWRF.html#introducing-recursive-partitioning",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "Introducing recursive partitioning",
    "text": "Introducing recursive partitioning\n\nA predictive methodology involving a dependent variable y and one and more predictors.\nThe dependent variable can be either a continuous or categorical scales.\nRules partition data into mutually exclusive groups.\nNo need to worry about transformations such as logs.\nNo prior distribution requirement."
  },
  {
    "objectID": "lesson/Lesson08/Lesson08-GWRF.html#advanced-recursive-partitioning-random-forest",
    "href": "lesson/Lesson08/Lesson08-GWRF.html#advanced-recursive-partitioning-random-forest",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "Advanced Recursive Partitioning: Random Forest",
    "text": "Advanced Recursive Partitioning: Random Forest\nRandom forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble.\n\nEach individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction as shown the figure."
  },
  {
    "objectID": "lesson/Lesson08/Lesson08-GWRF.html#introducing-geographically-weighted-random-forest-gwrf",
    "href": "lesson/Lesson08/Lesson08-GWRF.html#introducing-geographically-weighted-random-forest-gwrf",
    "title": "Lesson 8: Geographically Weighted Predictive Modelling",
    "section": "Introducing Geographically Weighted Random Forest (gwRF)",
    "text": "Introducing Geographically Weighted Random Forest (gwRF)\n\nGeographically Weighted Random Forest (GRF) is a spatial analysis method using a local version of the famous Machine Learning algorithm.\n\nThis technique adopts the idea of the Geographically Weighted Regression.\nThe main difference between a tradition (linear) GWR and GRF is that we can model non-stationarity coupled with a flexible non-linear model which is very hard to overfit due to its bootstrapping nature, thus relaxing the assumptions of traditional Gaussian statistics."
  },
  {
    "objectID": "lesson/Lesson09/Lesson09-GeoAcc.html#content",
    "href": "lesson/Lesson09/Lesson09-GeoAcc.html#content",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "Content",
    "text": "Content\n\nBasic Concepts of Geography of Accessibility\nAccessibility Models\n\nStewart Potential model\nReilly model\nHuff model"
  },
  {
    "objectID": "lesson/Lesson09/Lesson09-GeoAcc.html#what-is-geography-of-accessibility",
    "href": "lesson/Lesson09/Lesson09-GeoAcc.html#what-is-geography-of-accessibility",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "What is Geography of Accessibility?",
    "text": "What is Geography of Accessibility?\n\n\n\nAccessibility is the measure of the capacity of a location to be reached from, or to be reached by, different locations. Therefore, the capacity and the arrangement of transport infrastructure are key elements in the determination of accessibility."
  },
  {
    "objectID": "lesson/Lesson09/Lesson09-GeoAcc.html#measuring-distances",
    "href": "lesson/Lesson09/Lesson09-GeoAcc.html#measuring-distances",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "Measuring Distances",
    "text": "Measuring Distances\n\nDifferent spatial and distance conceptualizations that are commonly employed when measuring and modelling accessibility."
  },
  {
    "objectID": "lesson/Lesson09/Lesson09-GeoAcc.html#the-geographical-unit",
    "href": "lesson/Lesson09/Lesson09-GeoAcc.html#the-geographical-unit",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "The Geographical Unit",
    "text": "The Geographical Unit\n\nThis issue of irregularly shaped polygons created arbitrarily (such as county boundaries or block groups that have been created from a political process)."
  },
  {
    "objectID": "lesson/Lesson09/Lesson09-GeoAcc.html#the-potential-model",
    "href": "lesson/Lesson09/Lesson09-GeoAcc.html#the-potential-model",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "The Potential Model",
    "text": "The Potential Model\nThe classic model"
  },
  {
    "objectID": "lesson/Lesson09/Lesson09-GeoAcc.html#two-step-floating-catchment-area-method-2sfca",
    "href": "lesson/Lesson09/Lesson09-GeoAcc.html#two-step-floating-catchment-area-method-2sfca",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "Two-step floating catchment area method (2SFCA)",
    "text": "Two-step floating catchment area method (2SFCA)\n\n\n\nA special case of a potential model for measuring spatial accessibility to primary social services and public facilities.\nIt was inspired by the spatial decomposition idea first proposed by Radke and Mu (2000).\n\n\nReference: Luo, W.; Wang, F. (2003b). “Measures of spatial accessibility to health care in a GIS environment: synthesis and a case study in the Chicago region”. Environment and Planning B: Planning and Design. 30 (6): 865–884.\n\n\nAn earlier version of 2SFCA"
  },
  {
    "objectID": "lesson/Lesson09/Lesson09-GeoAcc.html#spatial-accessibility-measure-sam",
    "href": "lesson/Lesson09/Lesson09-GeoAcc.html#spatial-accessibility-measure-sam",
    "title": "Lesson 9: Modelling Geographic of Accessibility",
    "section": "Spatial Accessibility Measure (SAM)",
    "text": "Spatial Accessibility Measure (SAM)\nThe formula:\n\nwhere\n\nAai is the accessibility in ED i,\nnj is the capacity of the target facility j.\npi is the demand of this ED, and\ndij is the network distance between the EDi and each facility j.\n\n\nReference: Stamatis Kalogirou & Ronan Foley (2006) “Health, place and Hanly: Modelling accessibility to hospitals in Ireland”, Irish Geography, Volume 39(1), 2006, 52-68."
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#content",
    "href": "lesson/Lesson10/Lesson10-SIM.html#content",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Content",
    "text": "Content\n\nCharacteristics of Spatial Interaction Data\nSpatial Interaction Models\n\nUnconstrained\nOrigin constrined\nDestination constrained\nDoubly constrained\n\nWhat is Spatial Econometrics?\nWhat is Spatial Econometric Interaction Models?\nIntroducing spflow package\nSpatial Econometric Modelling of O-D Flows: spflow application"
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#what-spatial-interaction-models-are",
    "href": "lesson/Lesson10/Lesson10-SIM.html#what-spatial-interaction-models-are",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "What Spatial Interaction Models are?",
    "text": "What Spatial Interaction Models are?\n\n\nSpatial interaction or “gravity models” estimate the flow of people, material, or information between locations in geographical space.\n\n\n\n\n\n\n\n\nNote\n\n\nSpatial interaction models seek to explain existing spatial flows. As such it is possible to measure flows and predict the consequences of changes in the conditions generating them. When such attributes are known, it is possible to better allocate transport resources such as conveyances, infrastructure, and terminals."
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#constructing-an-od-matrix",
    "href": "lesson/Lesson10/Lesson10-SIM.html#constructing-an-od-matrix",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Constructing an O/D Matrix",
    "text": "Constructing an O/D Matrix\n\nThe construction of an origin / destination matrix requires directional flow information between a series of locations.\nFigure below represents movements (O/D pairs) between five locations (A, B, C, D and E). From this graph, an O/D matrix can be built where each O/D pair becomes a cell. A value of 0 is assigned for each O/D pair that does not have an observed flow."
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#three-basic-types-of-interaction-models",
    "href": "lesson/Lesson10/Lesson10-SIM.html#three-basic-types-of-interaction-models",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Three Basic Types of Interaction Models",
    "text": "Three Basic Types of Interaction Models\n\nThe general formulation of the spatial interaction model is stated as Tij, which is the interaction between location i (origin) and location j (destination). Vi are the attributes of the location of origin i, Wj are the attributes of the location of destination j, and Sij are the attributes of separation between the location of origin i and the location of destination j.\nFrom this general formulation, three basic types of interaction models can be derived:"
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#gravity-models",
    "href": "lesson/Lesson10/Lesson10-SIM.html#gravity-models",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Gravity Models",
    "text": "Gravity Models\n\n\n\nThe general formula (also known as unconstrained):\n\n\nTij is the transition/trip or flow, 𝑇, between origin 𝑖 (always the rows in a matrix) and destination 𝑗 (always the columns in a matrix). If you are not overly familiar with matrix notation, the 𝑖 and 𝑗 are just generic indexes to allow us to refer to any cell in the matrix.\n𝑉 is a vector (a 1 dimensional matrix – or, if you like, a single line of numbers) of origin attributes which relate to the emissivity of all origins in the dataset, 𝑖 – this could be any of the origin-related variables.\n\n\n\n𝑊 is a vector of destination attributes relating to the attractiveness of all destinations in the dataset, 𝑗 – similarly, this could be any of the destination related variables.\n𝑑 is a matrix of costs (frequently distances – hence, d) relating to the flows between 𝑖 and 𝑗.\n𝑘, 𝜇, 𝛼 and 𝛽 are all model parameters to be estimated. 𝛽 is assumed to be negative, as with an increase in cost/distance we would expect interaction to decrease."
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#spatial-econometric-interaction-models",
    "href": "lesson/Lesson10/Lesson10-SIM.html#spatial-econometric-interaction-models",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Spatial Econometric Interaction Models",
    "text": "Spatial Econometric Interaction Models\nLimitation of Spatial Interaction Models\n\nThe gravity model assumes independence among observations, and this assumption seems heroic for many fundamentally spatial problems."
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#spatial-econometric-model-for-origin-destination-flows",
    "href": "lesson/Lesson10/Lesson10-SIM.html#spatial-econometric-model-for-origin-destination-flows",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Spatial Econometric Model for Origin-Destination Flows",
    "text": "Spatial Econometric Model for Origin-Destination Flows"
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#spatial-econometric-interaction-model",
    "href": "lesson/Lesson10/Lesson10-SIM.html#spatial-econometric-interaction-model",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Spatial Econometric Interaction Model",
    "text": "Spatial Econometric Interaction Model\nThe general formula of Spatial Econometric Interaction Model is defined as follow:\n\nwhere by 𝐖𝓭, 𝐖𝒐 and 𝐖𝓌 are spatial weights of destination, origin and origin-destination."
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#what-is-econometrics",
    "href": "lesson/Lesson10/Lesson10-SIM.html#what-is-econometrics",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "What is Econometrics",
    "text": "What is Econometrics\n\nEconometrics is an application of statistical methods to economic data in order to give empirical content to economic relationships. More precisely, it is “the quantitative analysis of actual economic phenomena based on the concurrent development of theory and observation, related by appropriate methods of inference.\nA basic tool for econometrics is the multiple linear regression model.\nEconometric theory uses statistical theory and mathematical statistics to evaluate and develop econometric methods.\nEconometricians try to find estimators that have desirable statistical properties including unbiasedness, efficiency, and consistency.\nApplied econometrics uses theoretical econometrics and real-world data for assessing economic theories, developing econometric models, analysing economic history, and forecasting."
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#what-is-spatial-econometrics",
    "href": "lesson/Lesson10/Lesson10-SIM.html#what-is-spatial-econometrics",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "What is Spatial Econometrics?",
    "text": "What is Spatial Econometrics?\n\nA branch of economics that deals with the study of economic phenomena that exhibit spatial dependence.\nThis branch of economics has its roots in classical economics, which focused on the study of how economic activity was related to the location of factors of production.\nClassical economists developed theories of how businesses locate themselves in relation to their markets and to each other. These theories formed the basis for the development of modern spatial economics."
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#what-is-spatial-econometrics-1",
    "href": "lesson/Lesson10/Lesson10-SIM.html#what-is-spatial-econometrics-1",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "What is Spatial Econometrics?",
    "text": "What is Spatial Econometrics?\n\nIn a broader sense it is inclusive of the models and theoretical instruments of spatial statistics and spatial data analysis to analyze various economic effects such as externalities, interactions, spatial concentration and many others.\nDiscrete spatial data can take the form of points, lines and polygons. Point data refer to the position of the single economic agent observed at an individual level. Lines in space take the form of interactions between two spatial locations such as flows of goods, individuals and information. Finally data observed within polygons can take the form of predefined irregular portions of space, usually administrative partitions such as countries, regions or counties within one country."
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#what-are-the-examples-of-applications-using-spatial-econometrics",
    "href": "lesson/Lesson10/Lesson10-SIM.html#what-are-the-examples-of-applications-using-spatial-econometrics",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "What Are The Examples of Applications Using Spatial Econometrics ?",
    "text": "What Are The Examples of Applications Using Spatial Econometrics ?\nThere are many applications for spatial econometrics . Here are a few examples :\n\nEvaluating the impact of a new road or railway on property values.\nEstimating the effect of environmental regulations on firm location decisions.\nAnalyzing the determinants of crime rates across neighborhoods\nStudying the relationship between house prices and income levels in different regions.\nInvestigating the spread of infectious diseases through a population.\nModeling the relationship between land values and location-specific services.\nAnalyzing the relationship between proximity to facilities and job opportunities ."
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#spatial-model-specification-for-origin-destination-flows",
    "href": "lesson/Lesson10/Lesson10-SIM.html#spatial-model-specification-for-origin-destination-flows",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Spatial Model Specification for Origin-Destination Flows",
    "text": "Spatial Model Specification for Origin-Destination Flows"
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#spatial-model-specification-for-origin-destination-flows-1",
    "href": "lesson/Lesson10/Lesson10-SIM.html#spatial-model-specification-for-origin-destination-flows-1",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Spatial Model Specification for Origin-Destination Flows",
    "text": "Spatial Model Specification for Origin-Destination Flows"
  },
  {
    "objectID": "lesson/Lesson10/Lesson10-SIM.html#spatial-model-specification-for-origin-destination-flows-2",
    "href": "lesson/Lesson10/Lesson10-SIM.html#spatial-model-specification-for-origin-destination-flows-2",
    "title": "Lesson 10: Spatial Interaction Models",
    "section": "Spatial Model Specification for Origin-Destination Flows",
    "text": "Spatial Model Specification for Origin-Destination Flows"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "pacman::p_load(olsrr, ggstatsplot, ggpubr, \n               sf, spdep, GWmodel, tmap,\n               tidyverse, gtsummary, performance,\n               see, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#getting-started",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#getting-started",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "pacman::p_load(olsrr, ggstatsplot, ggpubr, \n               sf, spdep, GWmodel, tmap,\n               tidyverse, gtsummary, performance,\n               see, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#importing-the-data",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Importing the data",
    "text": "Importing the data\n\nURA Master Plan 2014 planning subzone boundary\n\ncondo_resale &lt;- read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n\nmpsz &lt;- read_rds(\"data/rds/mpsz.rds\")\n\n\ncondo_resale_sf &lt;- read_rds(\n  \"data/rds/condo_resale_sf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#correlation-analysis---ggstatsplot-methods",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#correlation-analysis---ggstatsplot-methods",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Correlation Analysis - ggstatsplot methods",
    "text": "Correlation Analysis - ggstatsplot methods\nInstead of using corrplot package, in the code chunk below, ggcorrmat() of ggstatsplot is used.\n\nggcorrmat(condo_resale[, 5:23])"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#building-multiple-linear-exploratory-data-analysis-eda",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#building-multiple-linear-exploratory-data-analysis-eda",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Building Multiple Linear Exploratory Data Analysis (EDA)",
    "text": "Building Multiple Linear Exploratory Data Analysis (EDA)\n\nBuilding a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\ncondo_mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + \n                  AGE   + PROX_CBD + PROX_CHILDCARE + \n                  PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n                  PROX_HAWKER_MARKET    + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + \n                  PROX_SUPERMARKET + PROX_BUS_STOP + \n                  NO_Of_UNITS + FAMILY_FRIENDLY + \n                  FREEHOLD + LEASEHOLD_99YR, \n                data=condo_resale_sf)\nsummary(condo_mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD + \n    LEASEHOLD_99YR, data = condo_resale_sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3471036  -286903   -22426   239412 12254549 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           543071.4   136210.9   3.987 7.03e-05 ***\nAREA_SQM               12688.7      370.1  34.283  &lt; 2e-16 ***\nAGE                   -24566.0     2766.0  -8.881  &lt; 2e-16 ***\nPROX_CBD              -78122.0     6791.4 -11.503  &lt; 2e-16 ***\nPROX_CHILDCARE       -333219.0   111020.3  -3.001 0.002734 ** \nPROX_ELDERLYCARE      170950.0    42110.8   4.060 5.19e-05 ***\nPROX_URA_GROWTH_AREA   38507.6    12523.7   3.075 0.002147 ** \nPROX_HAWKER_MARKET     23801.2    29299.9   0.812 0.416739    \nPROX_KINDERGARTEN     144098.0    82738.7   1.742 0.081795 .  \nPROX_MRT             -322775.9    58528.1  -5.515 4.14e-08 ***\nPROX_PARK             564487.9    66563.0   8.481  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      186170.5    65515.2   2.842 0.004553 ** \nPROX_TOP_PRIMARY_SCH    -477.1    20598.0  -0.023 0.981525    \nPROX_SHOPPING_MALL   -207721.5    42855.5  -4.847 1.39e-06 ***\nPROX_SUPERMARKET      -48074.7    77145.3  -0.623 0.533273    \nPROX_BUS_STOP         675755.0   138552.0   4.877 1.20e-06 ***\nNO_Of_UNITS             -216.2       90.3  -2.394 0.016797 *  \nFAMILY_FRIENDLY       142128.3    47055.1   3.020 0.002569 ** \nFREEHOLD              300646.5    77296.5   3.890 0.000105 ***\nLEASEHOLD_99YR        -77137.4    77570.9  -0.994 0.320192    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1416 degrees of freedom\nMultiple R-squared:  0.652, Adjusted R-squared:  0.6474 \nF-statistic: 139.6 on 19 and 1416 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nModel Assessment: olsrr method\n\nols_regress(condo_mlr)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     750537.537 \nR-Squared                    0.652       MSE                571262902261.223 \nAdj. R-Squared               0.647       Coef. Var                    43.160 \nPred R-Squared               0.637       AIC                       42971.173 \nMAE                     412117.987       SBC                       43081.835 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.515738e+15          19        7.977571e+13    139.648    0.0000 \nResidual      8.089083e+14        1416    571262902261.223                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     543071.420    136210.918                   3.987    0.000     275874.535     810268.305 \n            AREA_SQM      12688.669       370.119        0.579     34.283    0.000      11962.627      13414.710 \n                 AGE     -24566.001      2766.041       -0.166     -8.881    0.000     -29991.980     -19140.022 \n            PROX_CBD     -78121.985      6791.377       -0.267    -11.503    0.000     -91444.227     -64799.744 \n      PROX_CHILDCARE    -333219.036    111020.303       -0.087     -3.001    0.003    -551000.984    -115437.089 \n    PROX_ELDERLYCARE     170949.961     42110.748        0.083      4.060    0.000      88343.803     253556.120 \nPROX_URA_GROWTH_AREA      38507.622     12523.661        0.059      3.075    0.002      13940.700      63074.545 \n  PROX_HAWKER_MARKET      23801.197     29299.923        0.019      0.812    0.417     -33674.725      81277.120 \n   PROX_KINDERGARTEN     144097.972     82738.669        0.030      1.742    0.082     -18205.570     306401.514 \n            PROX_MRT    -322775.874     58528.079       -0.123     -5.515    0.000    -437586.937    -207964.811 \n           PROX_PARK     564487.876     66563.011        0.148      8.481    0.000     433915.162     695060.590 \n    PROX_PRIMARY_SCH     186170.524     65515.193        0.072      2.842    0.005      57653.253     314687.795 \nPROX_TOP_PRIMARY_SCH       -477.073     20597.972       -0.001     -0.023    0.982     -40882.894      39928.747 \n  PROX_SHOPPING_MALL    -207721.520     42855.500       -0.109     -4.847    0.000    -291788.613    -123654.427 \n    PROX_SUPERMARKET     -48074.679     77145.257       -0.012     -0.623    0.533    -199405.956     103256.599 \n       PROX_BUS_STOP     675755.044    138551.991        0.133      4.877    0.000     403965.817     947544.272 \n         NO_Of_UNITS       -216.180        90.302       -0.046     -2.394    0.017       -393.320        -39.040 \n     FAMILY_FRIENDLY     142128.272     47055.082        0.056      3.020    0.003      49823.107     234433.438 \n            FREEHOLD     300646.543     77296.529        0.117      3.890    0.000     149018.525     452274.561 \n      LEASEHOLD_99YR     -77137.375     77570.869       -0.030     -0.994    0.320    -229303.551      75028.801 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\nMulticolinearuty\n\nols_vif_tol(condo_mlr)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8601326 1.162611\n2                   AGE 0.7011585 1.426211\n3              PROX_CBD 0.4575471 2.185567\n4        PROX_CHILDCARE 0.2898233 3.450378\n5      PROX_ELDERLYCARE 0.5922238 1.688551\n6  PROX_URA_GROWTH_AREA 0.6614081 1.511926\n7    PROX_HAWKER_MARKET 0.4373874 2.286303\n8     PROX_KINDERGARTEN 0.8356793 1.196631\n9              PROX_MRT 0.4949877 2.020252\n10            PROX_PARK 0.8015728 1.247547\n11     PROX_PRIMARY_SCH 0.3823248 2.615577\n12 PROX_TOP_PRIMARY_SCH 0.4878620 2.049760\n13   PROX_SHOPPING_MALL 0.4903052 2.039546\n14     PROX_SUPERMARKET 0.6142127 1.628100\n15        PROX_BUS_STOP 0.3311024 3.020213\n16          NO_Of_UNITS 0.6543336 1.528272\n17      FAMILY_FRIENDLY 0.7191719 1.390488\n18             FREEHOLD 0.2728521 3.664990\n19       LEASEHOLD_99YR 0.2645988 3.779307\n\n\n\n\nVariable selection\n\ncondo_fw_mlr &lt;- ols_step_forward_p(\n  condo_mlr,\n  p_val = 0.05,\n  details = TRUE)\n\nForward Selection Method \n------------------------\n\nCandidate Terms: \n\n1. AREA_SQM \n2. AGE \n3. PROX_CBD \n4. PROX_CHILDCARE \n5. PROX_ELDERLYCARE \n6. PROX_URA_GROWTH_AREA \n7. PROX_HAWKER_MARKET \n8. PROX_KINDERGARTEN \n9. PROX_MRT \n10. PROX_PARK \n11. PROX_PRIMARY_SCH \n12. PROX_TOP_PRIMARY_SCH \n13. PROX_SHOPPING_MALL \n14. PROX_SUPERMARKET \n15. PROX_BUS_STOP \n16. NO_Of_UNITS \n17. FAMILY_FRIENDLY \n18. FREEHOLD \n19. LEASEHOLD_99YR \n\n\nStep   =&gt; 0 \nModel  =&gt; SELLING_PRICE ~ 1 \nR2     =&gt; 0 \n\nInitiating stepwise selection... \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nAREA_SQM                 0.00000        0.452             0.451    43587.753 \nPROX_CBD                 0.00000        0.243             0.242    44051.772 \nFREEHOLD                 0.00000        0.082             0.081    44328.539 \nLEASEHOLD_99YR           0.00000        0.066             0.065    44353.172 \nPROX_PARK                0.00000        0.049             0.048    44378.817 \nNO_Of_UNITS              0.00000        0.048             0.048    44380.124 \nPROX_PRIMARY_SCH         0.00000        0.032             0.032    44403.847 \nPROX_HAWKER_MARKET       0.00000        0.023             0.022    44417.505 \nPROX_CHILDCARE           0.00000        0.021             0.021    44420.298 \nPROX_ELDERLYCARE         0.00000        0.021             0.020    44420.546 \nPROX_BUS_STOP            0.00000        0.021             0.020    44420.742 \nPROX_KINDERGARTEN          2e-05        0.013             0.012    44432.322 \nPROX_SUPERMARKET         0.00088        0.008             0.007    44439.977 \nPROX_SHOPPING_MALL       0.00154        0.007             0.006    44441.023 \nFAMILY_FRIENDLY          0.00907        0.005             0.004    44444.248 \nPROX_MRT                 0.01071        0.005             0.004    44444.545 \nPROX_URA_GROWTH_AREA     0.13510        0.002             0.001    44448.832 \nPROX_TOP_PRIMARY_SCH     0.23180        0.001             0.000    44449.636 \nAGE                      0.52978        0.000             0.000    44450.673 \n----------------------------------------------------------------------------\n\nStep      =&gt; 1 \nSelected  =&gt; AREA_SQM \nModel     =&gt; SELLING_PRICE ~ AREA_SQM \nR2        =&gt; 0.452 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_CBD                 0.00000        0.569             0.569    43243.523 \nFREEHOLD                 0.00000        0.487             0.487    43493.627 \nPROX_PARK                0.00000        0.478             0.478    43518.542 \nLEASEHOLD_99YR           0.00000        0.475             0.474    43527.150 \nAGE                      0.00000        0.471             0.470    43538.063 \nPROX_SHOPPING_MALL       0.00000        0.467             0.466    43549.216 \nPROX_HAWKER_MARKET       0.00000        0.465             0.464    43555.065 \nPROX_MRT                 0.00000        0.465             0.464    43556.097 \nNO_Of_UNITS              0.00000        0.464             0.463    43557.089 \nPROX_SUPERMARKET         0.00000        0.461             0.461    43564.792 \nPROX_PRIMARY_SCH           3e-05        0.458             0.458    43572.418 \nPROX_ELDERLYCARE           5e-05        0.458             0.457    43573.203 \nPROX_URA_GROWTH_AREA       9e-05        0.458             0.457    43574.292 \nFAMILY_FRIENDLY          0.00026        0.457             0.456    43576.392 \nPROX_CHILDCARE           0.00275        0.455             0.455    43580.768 \nPROX_BUS_STOP            0.00381        0.455             0.454    43581.362 \nPROX_KINDERGARTEN        0.15757        0.453             0.452    43587.751 \nPROX_TOP_PRIMARY_SCH     0.47485        0.452             0.451    43589.241 \n----------------------------------------------------------------------------\n\nStep      =&gt; 2 \nSelected  =&gt; PROX_CBD \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD \nR2        =&gt; 0.569 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_PARK                0.00000        0.589             0.588    43177.691 \nAGE                      0.00000        0.586             0.585    43188.935 \nFREEHOLD                 0.00000        0.579             0.578    43213.005 \nPROX_ELDERLYCARE         0.00000        0.578             0.577    43216.850 \nPROX_TOP_PRIMARY_SCH     0.00000        0.577             0.576    43218.861 \nLEASEHOLD_99YR           0.00000        0.576             0.575    43224.500 \nPROX_HAWKER_MARKET         1e-05        0.575             0.574    43225.123 \nPROX_SHOPPING_MALL         8e-05        0.574             0.573    43229.948 \nPROX_SUPERMARKET         0.00147        0.572             0.571    43235.376 \nPROX_MRT                 0.00613        0.572             0.571    43237.989 \nNO_Of_UNITS              0.01059        0.571             0.570    43238.970 \nPROX_PRIMARY_SCH         0.04530        0.570             0.570    43241.503 \nPROX_BUS_STOP            0.06634        0.570             0.569    43242.142 \nFAMILY_FRIENDLY          0.11212        0.570             0.569    43242.991 \nPROX_CHILDCARE           0.29768        0.570             0.569    43244.435 \nPROX_URA_GROWTH_AREA     0.78658        0.569             0.568    43245.450 \nPROX_KINDERGARTEN        0.80879        0.569             0.568    43245.465 \n----------------------------------------------------------------------------\n\nStep      =&gt; 3 \nSelected  =&gt; PROX_PARK \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK \nR2        =&gt; 0.589 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nFREEHOLD                 0.00000        0.604             0.603    43125.474 \nAGE                      0.00000        0.602             0.601    43132.534 \nLEASEHOLD_99YR           0.00000        0.601             0.600    43138.902 \nPROX_ELDERLYCARE         0.00000        0.596             0.595    43153.932 \nPROX_TOP_PRIMARY_SCH       3e-05        0.594             0.593    43162.363 \nNO_Of_UNITS              0.00013        0.593             0.592    43164.977 \nPROX_SHOPPING_MALL       0.00015        0.593             0.592    43165.286 \nPROX_HAWKER_MARKET         7e-04        0.592             0.591    43168.151 \nPROX_MRT                 0.00250        0.592             0.591    43170.516 \nFAMILY_FRIENDLY          0.02445        0.591             0.589    43174.609 \nPROX_SUPERMARKET         0.02905        0.591             0.589    43174.908 \nPROX_URA_GROWTH_AREA     0.14518        0.590             0.589    43177.560 \nPROX_CHILDCARE           0.31093        0.589             0.588    43178.660 \nPROX_PRIMARY_SCH         0.34515        0.589             0.588    43178.796 \nPROX_BUS_STOP            0.47898        0.589             0.588    43179.188 \nPROX_KINDERGARTEN        0.87351        0.589             0.588    43179.665 \n----------------------------------------------------------------------------\n\nStep      =&gt; 4 \nSelected  =&gt; FREEHOLD \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD \nR2        =&gt; 0.604 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nAGE                      0.00000        0.620             0.619    43069.222 \nPROX_SHOPPING_MALL       0.00000        0.611             0.609    43104.195 \nPROX_ELDERLYCARE           5e-05        0.609             0.608    43111.036 \nPROX_TOP_PRIMARY_SCH       7e-05        0.609             0.607    43111.551 \nPROX_HAWKER_MARKET       0.00088        0.607             0.606    43116.360 \nPROX_SUPERMARKET         0.00324        0.607             0.605    43118.765 \nPROX_MRT                 0.00345        0.607             0.605    43118.882 \nPROX_BUS_STOP            0.09204        0.605             0.604    43124.623 \nFAMILY_FRIENDLY          0.11599        0.605             0.604    43124.992 \nPROX_PRIMARY_SCH         0.21752        0.605             0.603    43125.946 \nNO_Of_UNITS              0.25242        0.605             0.603    43126.158 \nPROX_URA_GROWTH_AREA     0.27640        0.605             0.603    43126.284 \nLEASEHOLD_99YR           0.49846        0.605             0.603    43127.014 \nPROX_KINDERGARTEN        0.66364        0.604             0.603    43127.284 \nPROX_CHILDCARE           0.82289        0.604             0.603    43127.424 \n----------------------------------------------------------------------------\n\nStep      =&gt; 5 \nSelected  =&gt; AGE \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE \nR2        =&gt; 0.62 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_ELDERLYCARE         0.00000        0.627             0.625    43046.515 \nPROX_SHOPPING_MALL       0.00014        0.624             0.622    43056.710 \nPROX_TOP_PRIMARY_SCH     0.00036        0.623             0.622    43058.400 \nPROX_MRT                 0.00118        0.623             0.621    43060.651 \nPROX_HAWKER_MARKET       0.00229        0.623             0.621    43061.874 \nNO_Of_UNITS              0.03614        0.621             0.620    43066.808 \nPROX_SUPERMARKET         0.03902        0.621             0.620    43066.940 \nPROX_PRIMARY_SCH         0.04454        0.621             0.620    43067.165 \nPROX_URA_GROWTH_AREA     0.05538        0.621             0.619    43067.532 \nFAMILY_FRIENDLY          0.06368        0.621             0.619    43067.765 \nPROX_BUS_STOP            0.09258        0.621             0.619    43068.378 \nLEASEHOLD_99YR           0.33191        0.620             0.619    43070.276 \nPROX_KINDERGARTEN        0.54422        0.620             0.619    43070.852 \nPROX_CHILDCARE           0.76117        0.620             0.619    43071.129 \n----------------------------------------------------------------------------\n\nStep      =&gt; 6 \nSelected  =&gt; PROX_ELDERLYCARE \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE \nR2        =&gt; 0.627 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_SHOPPING_MALL       0.00000        0.634             0.632    43020.990 \nPROX_MRT                 0.00000        0.633             0.631    43024.733 \nPROX_SUPERMARKET         0.00311        0.629             0.627    43039.719 \nPROX_CHILDCARE           0.00320        0.629             0.627    43039.776 \nPROX_TOP_PRIMARY_SCH     0.02859        0.628             0.626    43043.694 \nFAMILY_FRIENDLY          0.04001        0.628             0.626    43044.273 \nPROX_URA_GROWTH_AREA     0.06111        0.628             0.626    43044.987 \nPROX_HAWKER_MARKET       0.14370        0.627             0.625    43046.364 \nNO_Of_UNITS              0.21750        0.627             0.625    43046.985 \nLEASEHOLD_99YR           0.33225        0.627             0.625    43047.569 \nPROX_PRIMARY_SCH         0.72554        0.627             0.625    43048.391 \nPROX_BUS_STOP            0.73834        0.627             0.625    43048.403 \nPROX_KINDERGARTEN        0.96832        0.627             0.625    43048.513 \n----------------------------------------------------------------------------\n\nStep      =&gt; 7 \nSelected  =&gt; PROX_SHOPPING_MALL \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL \nR2        =&gt; 0.634 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_URA_GROWTH_AREA       2e-04        0.637             0.635    43009.092 \nPROX_MRT                 0.00038        0.637             0.635    43010.278 \nFAMILY_FRIENDLY          0.09004        0.634             0.632    43020.098 \nNO_Of_UNITS              0.09561        0.634             0.632    43020.195 \nPROX_BUS_STOP            0.10105        0.634             0.632    43020.284 \nPROX_CHILDCARE           0.16782        0.634             0.632    43021.075 \nPROX_PRIMARY_SCH         0.20169        0.634             0.632    43021.349 \nPROX_HAWKER_MARKET       0.28053        0.634             0.632    43021.818 \nPROX_SUPERMARKET         0.39017        0.634             0.632    43022.247 \nLEASEHOLD_99YR           0.41342        0.634             0.632    43022.317 \nPROX_KINDERGARTEN        0.64794        0.634             0.632    43022.781 \nPROX_TOP_PRIMARY_SCH     0.88928        0.634             0.632    43022.971 \n----------------------------------------------------------------------------\n\nStep      =&gt; 8 \nSelected  =&gt; PROX_URA_GROWTH_AREA \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA \nR2        =&gt; 0.637 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_MRT                 0.00055        0.640             0.638    42999.058 \nNO_Of_UNITS              0.04357        0.638             0.636    43006.989 \nPROX_BUS_STOP            0.07301        0.638             0.636    43007.854 \nFAMILY_FRIENDLY          0.07751        0.638             0.636    43007.953 \nPROX_CHILDCARE           0.17683        0.638             0.635    43009.255 \nLEASEHOLD_99YR           0.26341        0.638             0.635    43009.832 \nPROX_SUPERMARKET         0.32522        0.637             0.635    43010.117 \nPROX_TOP_PRIMARY_SCH     0.36995        0.637             0.635    43010.282 \nPROX_HAWKER_MARKET       0.48716        0.637             0.635    43010.606 \nPROX_KINDERGARTEN        0.49501        0.637             0.635    43010.623 \nPROX_PRIMARY_SCH         0.60814        0.637             0.635    43010.827 \n----------------------------------------------------------------------------\n\nStep      =&gt; 9 \nSelected  =&gt; PROX_MRT \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT \nR2        =&gt; 0.64 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_BUS_STOP              6e-05        0.644             0.642    42984.951 \nPROX_PRIMARY_SCH         0.01738        0.642             0.639    42995.355 \nNO_Of_UNITS              0.04105        0.641             0.639    42996.851 \nFAMILY_FRIENDLY          0.06468        0.641             0.639    42997.618 \nPROX_TOP_PRIMARY_SCH     0.16342        0.641             0.638    42999.100 \nLEASEHOLD_99YR           0.16895        0.641             0.638    42999.151 \nPROX_KINDERGARTEN        0.19107        0.641             0.638    42999.335 \nPROX_HAWKER_MARKET       0.19288        0.641             0.638    42999.349 \nPROX_SUPERMARKET         0.45603        0.640             0.638    43000.498 \nPROX_CHILDCARE           0.71809        0.640             0.638    43000.927 \n----------------------------------------------------------------------------\n\nStep      =&gt; 10 \nSelected  =&gt; PROX_BUS_STOP \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT + PROX_BUS_STOP \nR2        =&gt; 0.644 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nFAMILY_FRIENDLY          0.01590        0.646             0.643    42981.085 \nPROX_CHILDCARE           0.02032        0.646             0.643    42981.519 \nNO_Of_UNITS              0.03658        0.645             0.643    42982.543 \nPROX_PRIMARY_SCH         0.06688        0.645             0.642    42983.563 \nPROX_KINDERGARTEN        0.09160        0.645             0.642    42984.080 \nLEASEHOLD_99YR           0.10015        0.645             0.642    42984.224 \nPROX_TOP_PRIMARY_SCH     0.27924        0.645             0.642    42985.770 \nPROX_HAWKER_MARKET       0.53937        0.644             0.642    42986.571 \nPROX_SUPERMARKET         0.91393        0.644             0.641    42986.939 \n----------------------------------------------------------------------------\n\nStep      =&gt; 11 \nSelected  =&gt; FAMILY_FRIENDLY \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT + PROX_BUS_STOP + FAMILY_FRIENDLY \nR2        =&gt; 0.646 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nNO_Of_UNITS              0.00533        0.648             0.645    42975.246 \nPROX_CHILDCARE           0.01908        0.647             0.644    42977.539 \nPROX_PRIMARY_SCH         0.06018        0.647             0.644    42979.519 \nLEASEHOLD_99YR           0.06704        0.647             0.644    42979.699 \nPROX_KINDERGARTEN        0.09772        0.646             0.643    42980.317 \nPROX_TOP_PRIMARY_SCH     0.31070        0.646             0.643    42982.048 \nPROX_HAWKER_MARKET       0.66885        0.646             0.643    42982.901 \nPROX_SUPERMARKET         0.92593        0.646             0.643    42983.077 \n----------------------------------------------------------------------------\n\nStep      =&gt; 12 \nSelected  =&gt; NO_Of_UNITS \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT + PROX_BUS_STOP + FAMILY_FRIENDLY + NO_Of_UNITS \nR2        =&gt; 0.648 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_CHILDCARE           0.02092        0.649             0.646    42971.858 \nPROX_PRIMARY_SCH         0.05496        0.649             0.645    42973.525 \nPROX_KINDERGARTEN        0.13311        0.648             0.645    42974.967 \nLEASEHOLD_99YR           0.16053        0.648             0.645    42975.257 \nPROX_TOP_PRIMARY_SCH     0.28337        0.648             0.645    42976.084 \nPROX_HAWKER_MARKET       0.62348        0.648             0.644    42977.003 \nPROX_SUPERMARKET         0.65604        0.648             0.644    42977.046 \n----------------------------------------------------------------------------\n\nStep      =&gt; 13 \nSelected  =&gt; PROX_CHILDCARE \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT + PROX_BUS_STOP + FAMILY_FRIENDLY + NO_Of_UNITS + PROX_CHILDCARE \nR2        =&gt; 0.649 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_PRIMARY_SCH         0.00805        0.651             0.647    42966.758 \nPROX_KINDERGARTEN        0.08599        0.650             0.646    42970.878 \nPROX_TOP_PRIMARY_SCH     0.23060        0.649             0.646    42972.405 \nLEASEHOLD_99YR           0.32104        0.649             0.646    42972.863 \nPROX_HAWKER_MARKET       0.49652        0.649             0.646    42973.391 \nPROX_SUPERMARKET         0.59607        0.649             0.646    42973.574 \n----------------------------------------------------------------------------\n\nStep      =&gt; 14 \nSelected  =&gt; PROX_PRIMARY_SCH \nModel     =&gt; SELLING_PRICE ~ AREA_SQM + PROX_CBD + PROX_PARK + FREEHOLD + AGE + PROX_ELDERLYCARE + PROX_SHOPPING_MALL + PROX_URA_GROWTH_AREA + PROX_MRT + PROX_BUS_STOP + FAMILY_FRIENDLY + NO_Of_UNITS + PROX_CHILDCARE + PROX_PRIMARY_SCH \nR2        =&gt; 0.651 \n\n                          Selection Metrics Table                            \n----------------------------------------------------------------------------\nPredictor               Pr(&gt;|t|)    R-Squared    Adj. R-Squared       AIC    \n----------------------------------------------------------------------------\nPROX_KINDERGARTEN        0.07528        0.651             0.648    42965.558 \nLEASEHOLD_99YR           0.24093        0.651             0.647    42967.367 \nPROX_HAWKER_MARKET       0.29790        0.651             0.647    42967.662 \nPROX_TOP_PRIMARY_SCH     0.38435        0.651             0.647    42967.993 \nPROX_SUPERMARKET         0.76578        0.651             0.647    42968.669 \n----------------------------------------------------------------------------\n\n\nNo more variables to be added.\n\nVariables Selected: \n\n=&gt; AREA_SQM \n=&gt; PROX_CBD \n=&gt; PROX_PARK \n=&gt; FREEHOLD \n=&gt; AGE \n=&gt; PROX_ELDERLYCARE \n=&gt; PROX_SHOPPING_MALL \n=&gt; PROX_URA_GROWTH_AREA \n=&gt; PROX_MRT \n=&gt; PROX_BUS_STOP \n=&gt; FAMILY_FRIENDLY \n=&gt; NO_Of_UNITS \n=&gt; PROX_CHILDCARE \n=&gt; PROX_PRIMARY_SCH \n\n\n\nplot(condo_fw_mlr)\n\n\n\n\n\n\n\n\n\n\nVisualising model parameters\n\nggcoefstats(condo_mlr,\n            sort = \"ascending\")\n\n\n\n\n\n\n\n\n\n\nChecking for multicolinearity\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\nols_vif_tol(condo_fw_mlr$model)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2              PROX_CBD 0.6356147 1.573280\n3             PROX_PARK 0.8279261 1.207837\n4              FREEHOLD 0.6931163 1.442759\n5                   AGE 0.7071275 1.414172\n6      PROX_ELDERLYCARE 0.6598479 1.515501\n7    PROX_SHOPPING_MALL 0.6738795 1.483945\n8  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n9              PROX_MRT 0.5236090 1.909822\n10        PROX_BUS_STOP 0.3514118 2.845664\n11      FAMILY_FRIENDLY 0.7244157 1.380423\n12          NO_Of_UNITS 0.6901036 1.449058\n13       PROX_CHILDCARE 0.3066019 3.261559\n14     PROX_PRIMARY_SCH 0.4524628 2.210126\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\nTest for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\nTest for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo_fw_mlr$model)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\nTesting for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale_sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr_output &lt;- as.data.frame(condo_fw_mlr$model$residuals) %&gt;%\n  rename(`FW_MLR_RES` = `condo_fw_mlr$model$residuals`)\n\nNext, we will join the newly created data frame with condo_resale_sf object.\n\ncondo_resale_sf &lt;- cbind(condo_resale_sf, \n                        mlr_output$FW_MLR_RES) %&gt;%\n  rename(`MLR_RES` = `mlr_output.FW_MLR_RES`)\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\ntm_shape(mpsz)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale_sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\")\n\n\n\n\ntmap_mode(\"plot\")\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;%\n  mutate(nb = st_knn(geometry, k=6,\n                     longlat = FALSE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\n\nglobal_moran_perm(condo_resale_sf$MLR_RES, \n                  condo_resale_sf$nb, \n                  condo_resale_sf$wt, \n                  alternative = \"two.sided\", \n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.32254, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.25586 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Building Hedonic Pricing Models using GWmodel",
    "text": "Building Hedonic Pricing Models using GWmodel\nIn this section, you are going to learn how to modelling hedonic pricing by using geographically weighted regression model. Two spatial weights will be used, they are: fixed and adaptive bandwidth schemes.\n\nBuilding Fixed Bandwidth GWR Model\n\nComputing fixed bandwith\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach agreement.\n\nbw_fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                     PROX_CBD + PROX_CHILDCARE + \n                     PROX_ELDERLYCARE   + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                     NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale_sf, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres. (Quiz: Do you know why it is in metre?)\n\n\nGWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr_fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + \n                         AGE    + PROX_CBD + PROX_CHILDCARE + \n                         PROX_ELDERLYCARE   +PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH +\n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                         NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale_sf, \n                       bw=bw_fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\ngwr_fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-15 05:54:53.077074 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw_fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-10-15 05:54:53.992619 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.\n\n\n\nBuilding Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\nComputing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw_adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale_sf, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\nConstructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr_adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale_sf, \n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe code below can be used to display the model output.\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-15 05:55:00.974057 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-15 05:55:02.035114 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.\n\n\n\nVisualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\nConverting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\ngwr_adaptive_output &lt;- as.data.frame(\n  gwr_adaptive$SDF) %&gt;%\n  select(-c(2:15))\n\n\ngwr_sf_adaptive &lt;- cbind(condo_resale_sf,\n                         gwr_adaptive_output)\n\nNext, glimpse() is used to display the content of condo_resale_sf.adaptive sf data frame.\n\nglimpse(gwr_sf_adaptive)\n\nRows: 1,436\nColumns: 63\n$ nb                      &lt;nb&gt; &lt;66, 77, 123, 238, 239, 343&gt;, &lt;21, 162, 163, 19…\n$ wt                      &lt;list&gt; &lt;0.1666667, 0.1666667, 0.1666667, 0.1666667, …\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n$ geometry.1              &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr_adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n\nVisualising local R2\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\ntmap_options(check.and.fix = TRUE)\ntm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\nVisualising coefficient estimates\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\nAREA_SQM_SE &lt;- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\nBy URA Plannign Region\n\ntm_shape(mpsz[mpsz$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(gwr_sf_adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#reference",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#reference",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Reference",
    "text": "Reference\nGollini I, Lu B, Charlton M, Brunsdon C, Harris P (2015) “GWmodel: an R Package for exploring Spatial Heterogeneity using Geographically Weighted Models”. Journal of Statistical Software, 63(17):1-50, http://www.jstatsoft.org/v63/i17/\nLu B, Harris P, Charlton M, Brunsdon C (2014) “The GWmodel R Package: further topics for exploring Spatial Heterogeneity using GeographicallyWeighted Models”. Geo-spatial Information Science 17(2): 85-101, http://www.tandfonline.com/doi/abs/10.1080/1009502.2014.917453"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06-REDCAP.html",
    "title": "In-class Exercise 6: Spatially Constrained Clustering Analysis: REDCAP methods",
    "section": "",
    "text": "Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\nCategorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#building-a-hedonic-pricing-model-by-using-multiple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#building-a-hedonic-pricing-model-by-using-multiple-linear-regression-method",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Building a Hedonic Pricing Model by using Multiple Linear Regression Method",
    "text": "Building a Hedonic Pricing Model by using Multiple Linear Regression Method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\ncondo_mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + \n                  AGE   + PROX_CBD + PROX_CHILDCARE + \n                  PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n                  PROX_HAWKER_MARKET    + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + \n                  PROX_SUPERMARKET + PROX_BUS_STOP + \n                  NO_Of_UNITS + FAMILY_FRIENDLY + \n                  FREEHOLD + LEASEHOLD_99YR, \n                data=condo_resale_sf)\nsummary(condo_mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD + \n    LEASEHOLD_99YR, data = condo_resale_sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3471036  -286903   -22426   239412 12254549 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           543071.4   136210.9   3.987 7.03e-05 ***\nAREA_SQM               12688.7      370.1  34.283  &lt; 2e-16 ***\nAGE                   -24566.0     2766.0  -8.881  &lt; 2e-16 ***\nPROX_CBD              -78122.0     6791.4 -11.503  &lt; 2e-16 ***\nPROX_CHILDCARE       -333219.0   111020.3  -3.001 0.002734 ** \nPROX_ELDERLYCARE      170950.0    42110.8   4.060 5.19e-05 ***\nPROX_URA_GROWTH_AREA   38507.6    12523.7   3.075 0.002147 ** \nPROX_HAWKER_MARKET     23801.2    29299.9   0.812 0.416739    \nPROX_KINDERGARTEN     144098.0    82738.7   1.742 0.081795 .  \nPROX_MRT             -322775.9    58528.1  -5.515 4.14e-08 ***\nPROX_PARK             564487.9    66563.0   8.481  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      186170.5    65515.2   2.842 0.004553 ** \nPROX_TOP_PRIMARY_SCH    -477.1    20598.0  -0.023 0.981525    \nPROX_SHOPPING_MALL   -207721.5    42855.5  -4.847 1.39e-06 ***\nPROX_SUPERMARKET      -48074.7    77145.3  -0.623 0.533273    \nPROX_BUS_STOP         675755.0   138552.0   4.877 1.20e-06 ***\nNO_Of_UNITS             -216.2       90.3  -2.394 0.016797 *  \nFAMILY_FRIENDLY       142128.3    47055.1   3.020 0.002569 ** \nFREEHOLD              300646.5    77296.5   3.890 0.000105 ***\nLEASEHOLD_99YR        -77137.4    77570.9  -0.994 0.320192    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1416 degrees of freedom\nMultiple R-squared:  0.652, Adjusted R-squared:  0.6474 \nF-statistic: 139.6 on 19 and 1416 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#model-assessment-olsrr-method",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#model-assessment-olsrr-method",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Model Assessment: olsrr method",
    "text": "Model Assessment: olsrr method\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\n\nGenerating tidy linear regression report\n\nols_regress(condo_mlr)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     750537.537 \nR-Squared                    0.652       MSE                571262902261.223 \nAdj. R-Squared               0.647       Coef. Var                    43.160 \nPred R-Squared               0.637       AIC                       42971.173 \nMAE                     412117.987       SBC                       43081.835 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.515738e+15          19        7.977571e+13    139.648    0.0000 \nResidual      8.089083e+14        1416    571262902261.223                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     543071.420    136210.918                   3.987    0.000     275874.535     810268.305 \n            AREA_SQM      12688.669       370.119        0.579     34.283    0.000      11962.627      13414.710 \n                 AGE     -24566.001      2766.041       -0.166     -8.881    0.000     -29991.980     -19140.022 \n            PROX_CBD     -78121.985      6791.377       -0.267    -11.503    0.000     -91444.227     -64799.744 \n      PROX_CHILDCARE    -333219.036    111020.303       -0.087     -3.001    0.003    -551000.984    -115437.089 \n    PROX_ELDERLYCARE     170949.961     42110.748        0.083      4.060    0.000      88343.803     253556.120 \nPROX_URA_GROWTH_AREA      38507.622     12523.661        0.059      3.075    0.002      13940.700      63074.545 \n  PROX_HAWKER_MARKET      23801.197     29299.923        0.019      0.812    0.417     -33674.725      81277.120 \n   PROX_KINDERGARTEN     144097.972     82738.669        0.030      1.742    0.082     -18205.570     306401.514 \n            PROX_MRT    -322775.874     58528.079       -0.123     -5.515    0.000    -437586.937    -207964.811 \n           PROX_PARK     564487.876     66563.011        0.148      8.481    0.000     433915.162     695060.590 \n    PROX_PRIMARY_SCH     186170.524     65515.193        0.072      2.842    0.005      57653.253     314687.795 \nPROX_TOP_PRIMARY_SCH       -477.073     20597.972       -0.001     -0.023    0.982     -40882.894      39928.747 \n  PROX_SHOPPING_MALL    -207721.520     42855.500       -0.109     -4.847    0.000    -291788.613    -123654.427 \n    PROX_SUPERMARKET     -48074.679     77145.257       -0.012     -0.623    0.533    -199405.956     103256.599 \n       PROX_BUS_STOP     675755.044    138551.991        0.133      4.877    0.000     403965.817     947544.272 \n         NO_Of_UNITS       -216.180        90.302       -0.046     -2.394    0.017       -393.320        -39.040 \n     FAMILY_FRIENDLY     142128.272     47055.082        0.056      3.020    0.003      49823.107     234433.438 \n            FREEHOLD     300646.543     77296.529        0.117      3.890    0.000     149018.525     452274.561 \n      LEASEHOLD_99YR     -77137.375     77570.869       -0.030     -0.994    0.320    -229303.551      75028.801 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\nMulticolinearuty\n\nols_vif_tol(condo_mlr)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8601326 1.162611\n2                   AGE 0.7011585 1.426211\n3              PROX_CBD 0.4575471 2.185567\n4        PROX_CHILDCARE 0.2898233 3.450378\n5      PROX_ELDERLYCARE 0.5922238 1.688551\n6  PROX_URA_GROWTH_AREA 0.6614081 1.511926\n7    PROX_HAWKER_MARKET 0.4373874 2.286303\n8     PROX_KINDERGARTEN 0.8356793 1.196631\n9              PROX_MRT 0.4949877 2.020252\n10            PROX_PARK 0.8015728 1.247547\n11     PROX_PRIMARY_SCH 0.3823248 2.615577\n12 PROX_TOP_PRIMARY_SCH 0.4878620 2.049760\n13   PROX_SHOPPING_MALL 0.4903052 2.039546\n14     PROX_SUPERMARKET 0.6142127 1.628100\n15        PROX_BUS_STOP 0.3311024 3.020213\n16          NO_Of_UNITS 0.6543336 1.528272\n17      FAMILY_FRIENDLY 0.7191719 1.390488\n18             FREEHOLD 0.2728521 3.664990\n19       LEASEHOLD_99YR 0.2645988 3.779307\n\n\n\n\nVariable selection\n\ncondo_fw_mlr &lt;- ols_step_forward_p(\n  condo_mlr,\n  p_val = 0.05,\n  details = FALSE)\n\n\nplot(condo_fw_mlr)\n\n\n\n\n\n\n\n\n\n\n\nVisualising model parameters\n\nggcoefstats(condo_mlr,\n            sort = \"ascending\")\n\n\n\n\n\n\n\n\n\n\nTest for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\nTest for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo_fw_mlr$model)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#testing-for-spatial-autocorrelation",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07-gwr.html#testing-for-spatial-autocorrelation",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Testing for Spatial Autocorrelation",
    "text": "Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr_output &lt;- as.data.frame(condo_fw_mlr$model$residuals) %&gt;%\n  rename(`FW_MLR_RES` = `condo_fw_mlr$model$residuals`)\n\nNext, we will join the newly created data frame with condo_resale_sf object.\n\ncondo_resale_sf &lt;- cbind(condo_resale_sf, \n                        mlr_output$FW_MLR_RES) %&gt;%\n  rename(`MLR_RES` = `mlr_output.FW_MLR_RES`)\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\ntm_shape(mpsz)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale_sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\")\n\n\n\n\ntmap_mode(\"plot\")\n\nThe figure above reveal that there is sign of spatial autocorrelation.\n\nSpatial stationary test\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nHo: The residuals are randomly distributed (also known as spatial stationary) H1: The residuals are spatially non-stationary\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;%\n  mutate(nb = st_knn(geometry, k=6,\n                     longlat = FALSE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nNext, global_moran_perm() of sfdep is used to perform global Moran permutation test.\n\nglobal_moran_perm(condo_resale_sf$MLR_RES, \n                  condo_resale_sf$nb, \n                  condo_resale_sf$wt, \n                  alternative = \"two.sided\", \n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.32254, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.25586 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Take-home_Ex03b.html",
    "href": "Take-home_Ex03b.html",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods",
    "section": "",
    "text": "Important\n\n\n\nThis handout provides the context, the task, the expectation and the grading criteria of Take-home Exercise 2. Students must review and understand them before getting started with the take-home exercise."
  },
  {
    "objectID": "Take-home_Ex03b.html#setting-the-scene-hdb-resale-prices",
    "href": "Take-home_Ex03b.html#setting-the-scene-hdb-resale-prices",
    "title": "Take-home Exercise 3b: Applied Geospatial Analytics for Decision Support",
    "section": "Setting the Scene: HDB Resale Prices",
    "text": "Setting the Scene: HDB Resale Prices\nHousing is an essential component of household wealth worldwide. Buying a housing has always been a major investment for most people. The price of housing is affected by many factors. Some of them are global in nature such as the general economy of a country or inflation rate. Others can be more specific to the properties themselves. These factors can be further divided to structural and locational factors. Structural factors are variables related to the property themselves such as the size, fitting, and tenure of the property. Locational factors are variables related to the neighbourhood of the properties such as proximity to childcare centre, public transport service and shopping centre.\nConventional, housing resale prices predictive models were built by using Ordinary Least Square (OLS) method. However, this method failed to take into consideration that spatial autocorrelation and spatial heterogeneity exist in geographic data sets such as housing transactions. With the existence of spatial autocorrelation, the OLS estimation of predictive housing resale pricing models could lead to biased, inconsistent, or inefficient results (Anselin 1998). In view of this limitation, Geographical Weighted Models were introduced to better calibrate predictive models for housing resale prices."
  },
  {
    "objectID": "Take-home_Ex03b.html#the-task",
    "href": "Take-home_Ex03b.html#the-task",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods",
    "section": "The Task",
    "text": "The Task\nIn this take-home exercise, you are required to calibrate a predictive model to predict HDB resale prices between July-September 2024 by using HDB resale transaction records in 2023."
  },
  {
    "objectID": "Take-home_Ex03b.html#the-data",
    "href": "Take-home_Ex03b.html#the-data",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods",
    "section": "The Data",
    "text": "The Data\nFor the purpose of this take-home exercise, HDB Resale Flat Prices provided by Data.gov.sg should be used as the core data set. The study should focus on either three-room, four-room or five-room flat.\nBelow is a list of recommended predictors to consider. However, students are free to include other appropriate independent variables.\n\nStructural factors\n\nArea of the unit\nFloor level\nRemaining lease\nAge of the unit\nMain Upgrading Program (MUP) completed (optional)\n\nLocational factors\n\nProxomity to CBD\nProximity to eldercare\nProximity to foodcourt/hawker centres\nProximity to MRT\nProximity to park\nProximity to good primary school\nProximity to shopping mall\nProximity to supermarket\nNumbers of kindergartens within 350m\nNumbers of childcare centres within 350m\nNumbers of bus stop within 350m\nNumbers of primary school within 1km"
  },
  {
    "objectID": "Take-home_Ex03b.html#grading-criteria",
    "href": "Take-home_Ex03b.html#grading-criteria",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods",
    "section": "Grading Criteria",
    "text": "Grading Criteria\nThis exercise will be graded by using the following criteria:\n\nGeospatial Data Wrangling (20 marks): This is an important aspect of geospatial analytics. You will be assessed on your ability:\n\nto employ appropriate R functions from various R packages specifically designed for modern data science such as readxl, tidyverse (tidyr, dplyr, ggplot2), sf just to mention a few of them, to perform the import and extract the data.\nto clean and derive appropriate variables for meeting the analysis need.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAll data are like vast grassland full of land mines. Your job is to clear those mines and not to step on them.\n\n\n\nGeospatial Analysis (30 marks): In this exercise, you are expected to use conventional multiple linear regression, random forest and geographically weighted random forest methods learned in class to calibrate the predictive models including model comparison. You will be assessed on your ability:\n\nto describe the methods used correctly, and\nto provide accurate interpretation of the analysis results.\n\nGeovisualisation and geocommunication (20 marks): In this section, you will be assessed on your ability to communicate the results in business friendly visual representations. This course is geospatial centric, hence, it is important for you to demonstrate your competency in using appropriate geovisualisation techniques to reveal and communicate the findings of your analysis.\nReproducibility (15 marks): This is an important learning outcome of this exercise. You will be assessed on your ability to provide a comprehensive documentation of the analysis procedures in the form of code chunks of Quarto. It is important to note that it is not enough by merely providing the code chunk without any explanation on the purpose and R function(s) used.\nBonus (15 marks): Demonstrate your ability to employ methods beyond what you had learned in class to gain insights from the data."
  },
  {
    "objectID": "Take-home_Ex03b.html#submission-instructions",
    "href": "Take-home_Ex03b.html#submission-instructions",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods",
    "section": "Submission Instructions",
    "text": "Submission Instructions\n\nThe write-up of the take-home exercise must be in Quarto html document format. You are required to publish the write-up on Netlify.\nZip the take-home exercise folder and upload it onto eLearn. If the size of the zip file is beyond the capacity of eLearn, you can upload it on SMU OneDrive and provide the download link on eLearn.."
  },
  {
    "objectID": "Take-home_Ex03b.html#due-date",
    "href": "Take-home_Ex03b.html#due-date",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods",
    "section": "Due Date",
    "text": "Due Date\n10th November 2024 (Sunday), 11.59pm (midnight)."
  },
  {
    "objectID": "Take-home_Ex03b.html#learning-from-senior",
    "href": "Take-home_Ex03b.html#learning-from-senior",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods",
    "section": "Learning from senior",
    "text": "Learning from senior\nYou are advised to review these sample submissions prepared by your seniors."
  },
  {
    "objectID": "Take-home_Ex03b.html#learning-from-is415",
    "href": "Take-home_Ex03b.html#learning-from-is415",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning GeoML Methods",
    "section": "Learning from IS415",
    "text": "Learning from IS415"
  },
  {
    "objectID": "Take-home_Ex03b.html#q-a",
    "href": "Take-home_Ex03b.html#q-a",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods",
    "section": "Q & A",
    "text": "Q & A\nPlease submit your questions or queries related to this take-home exercise on Piazza."
  },
  {
    "objectID": "Take-home_Ex03b.html#peer-learning",
    "href": "Take-home_Ex03b.html#peer-learning",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods",
    "section": "Peer Learning",
    "text": "Peer Learning"
  },
  {
    "objectID": "Take-home_Ex03b.html#reference",
    "href": "Take-home_Ex03b.html#reference",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods",
    "section": "Reference",
    "text": "Reference\n\nSpatialML\nSpatialRF\n\n\nResearch articles\nWang, Shuli et. al. (2024) “Geographically weighted machine learning for modeling spatial heterogeneity in traffic crash frequency and determinants in US”, Accident analysis and prevention, Vol.199, p.107528-107528, Article 107528. SMU Library e-journal.\nLotfata, Aynaz & Georganos, Stefanos (2023) “Spatial machine learning for predicting physical inactivity prevalence from socioecological determinants in Chicago, Illinois, USA”, Journal of geographical systems, pp.1-21\nWu, Dongyu ; Zhang, Yingheng ; Xiang, Qiaojun (2024) “Geographically weighted random forests for macro-level crash frequency prediction”, Accident analysis and prevention, Vol.194, p.107370-107370, Article 107370."
  },
  {
    "objectID": "Take-home_Ex03b.html#setting-the-scene",
    "href": "Take-home_Ex03b.html#setting-the-scene",
    "title": "Take-home Exercise 3b: Predicting HDB Resale Prices with Geographically Weighted Machine Learning Methods",
    "section": "Setting the Scene",
    "text": "Setting the Scene\nHousing is an essential component of household wealth worldwide. Buying a housing has always been a major investment for most people. The price of housing is affected by many factors. Some of them are global in nature such as the general economy of a country or inflation rate. Others can be more specific to the properties themselves. These factors can be further divided to structural and locational factors. Structural factors are variables related to the property themselves such as the size, fitting, and tenure of the property. Locational factors are variables related to the neighbourhood of the properties such as proximity to childcare centre, public transport service and shopping centre.\nConventional, housing resale prices predictive models were built by using Ordinary Least Square (OLS) method. However, this method failed to take into consideration that spatial autocorrelation and spatial heterogeneity exist in geographic data sets such as housing transactions. With the existence of spatial autocorrelation, the OLS estimation of predictive housing resale pricing models could lead to biased, inconsistent, or inefficient results (Anselin 1998). In view of this limitation, Geographical Weighted Models were introduced to better calibrate predictive models for housing resale prices."
  },
  {
    "objectID": "Take-home_Ex03a.html",
    "href": "Take-home_Ex03a.html",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "",
    "text": "Important\n\n\n\nThis handout provides the context, the task, the expectation and the grading criteria of Take-home Exercise 3. Students must review and understand them before getting started with the take-home exercise."
  },
  {
    "objectID": "Take-home_Ex03a.html#setting-the-scene",
    "href": "Take-home_Ex03a.html#setting-the-scene",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "Setting the Scene",
    "text": "Setting the Scene\nAccording to Wikipedia, financial inclusion is the availability and equality of opportunities to access financial services. It refers to processes by which individuals and businesses can access appropriate, affordable, and timely financial products and services - which include banking, loan, equity, and insurance products. It provides paths to enhance inclusiveness in economic growth by enabling the unbanked population to access the means for savings, investment, and insurance towards improving household income and reducing income inequality."
  },
  {
    "objectID": "Take-home_Ex03a.html#the-task",
    "href": "Take-home_Ex03a.html#the-task",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "The Task",
    "text": "The Task\nIn this take-home exercise, you are required to build an explanatory model to determine factors affecting financial inclusion by using geographical weighted regression methods."
  },
  {
    "objectID": "Take-home_Ex03a.html#the-data",
    "href": "Take-home_Ex03a.html#the-data",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "The Data",
    "text": "The Data\nFor the purpose of this take-home exercise, either FinScope Uganda 2023 or FinScope Tanzania 2023 should be used. The study should be conducted at the district level. The district level boundary GIS data can be downloaded from geoBoundaries portal."
  },
  {
    "objectID": "Take-home_Ex03a.html#grading-criteria",
    "href": "Take-home_Ex03a.html#grading-criteria",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "Grading Criteria",
    "text": "Grading Criteria\nThis exercise will be graded by using the following criteria:\n\nGeospatial Data Wrangling (20 marks): This is an important aspect of geospatial analytics. You will be assessed on your ability:\n\nto employ appropriate R functions from various R packages specifically designed for modern data science such as readxl, tidyverse (tidyr, dplyr, ggplot2), sf just to mention a few of them, to perform the import and extract the data.\nto clean and derive appropriate variables for meeting the analysis need.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAll data are like vast grassland full of land mines. Your job is to clear those mines and not to step on them.\n\n\n\nGeospatial Analysis (30 marks): In this exercise, you are expected to use the appropriate non-spatial regression method and geographically weighted regression methods learned in Lesson 7 to perform the analysis. You will be assessed on your ability:\n\nto describe the methods used correctly including model diagnostics, and\nto provide accurate interpretation of the analysis results.\n\nGeovisualisation and geocommunication (20 marks): In this section, you will be assessed on your ability to communicate the results in business friendly visual representations. This course is geospatial centric, hence, it is important for you to demonstrate your competency in using appropriate geovisualisation techniques to reveal and communicate the findings of your analysis.\nReproducibility (15 marks): This is an important learning outcome of this exercise. You will be assessed on your ability to provide a comprehensive documentation of the analysis procedures in the form of code chunks of Quarto. It is important to note that it is not enough by merely providing the code chunk without any explanation on the purpose and R function(s) used.\nBonus (15 marks): Demonstrate your ability to employ methods beyond what you had learned in class to gain insights from the data."
  },
  {
    "objectID": "Take-home_Ex03a.html#submission-instructions",
    "href": "Take-home_Ex03a.html#submission-instructions",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "Submission Instructions",
    "text": "Submission Instructions\n\nThe write-up of the take-home exercise must be in Quarto html document format. You are required to publish the write-up on Netlify.\nZip the take-home exercise folder and upload it onto eLearn. If the size of the zip file is beyond the capacity of eLearn, you can upload it on SMU OneDrive and provide the download link on eLearn.."
  },
  {
    "objectID": "Take-home_Ex03a.html#due-date",
    "href": "Take-home_Ex03a.html#due-date",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "Due Date",
    "text": "Due Date\n10th November 2024 (Sunday), 11.59pm (midnight)."
  },
  {
    "objectID": "Take-home_Ex03a.html#learning-from-senior",
    "href": "Take-home_Ex03a.html#learning-from-senior",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "Learning from senior",
    "text": "Learning from senior\nYou are advised to review these sample submissions prepared by your seniors."
  },
  {
    "objectID": "Take-home_Ex03a.html#learning-from-is415",
    "href": "Take-home_Ex03a.html#learning-from-is415",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "Learning from IS415",
    "text": "Learning from IS415"
  },
  {
    "objectID": "Take-home_Ex03a.html#q-a",
    "href": "Take-home_Ex03a.html#q-a",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "Q & A",
    "text": "Q & A\nPlease submit your questions or queries related to this take-home exercise on Piazza."
  },
  {
    "objectID": "Take-home_Ex03a.html#peer-learning",
    "href": "Take-home_Ex03a.html#peer-learning",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "Peer Learning",
    "text": "Peer Learning"
  },
  {
    "objectID": "Take-home_Ex03a.html#reference",
    "href": "Take-home_Ex03a.html#reference",
    "title": "Take-home Exercise 3a: Modelling Geography of Financial Inclusion with Geographically Weighted Methods",
    "section": "Reference",
    "text": "Reference\n\nFinScope Tanzania 2023\nFinScope Uganda 2023\n\n\nResearch articles\n\nKaliba, Aloyce R ; Bishagazi, Kaihula P ; Gongwe, Anne G (2023) “Financial Inclusion in Tanzania Determinants, Barriers, and Impact”, The Journal of developing areas, Vol.57 (2), pp.65-87. SMU library e-journal.\nJana S. Hamdan, Katharina Lehmann-Uschner & Lukas Menkhoff (2022) Mobile Money, Financial Inclusion, and Unmet Opportunities: Evidence from Uganda, The Journal of Development Studies, 58:4, 671-691. SMU library e-journal.\nNguyen, Nhan Thien, et. al. (2021) “The convergence of financial inclusion across provinces in Vietnam: A novel approach” PloS one, Vol.16 (8). SMU library e-journal."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#installing-and-loading-r-packages",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#installing-and-loading-r-packages",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "Installing and Loading R packages",
    "text": "Installing and Loading R packages\n\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse,\n               knitr, kableExtra)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#preparing-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#preparing-data",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "Preparing Data",
    "text": "Preparing Data\nData import\n\n\nmdata &lt;- read_rds(\"data/model/mdata.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#building-a-non-spatial-multiple-linear-regression",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#building-a-non-spatial-multiple-linear-regression",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "Building a non-spatial multiple linear regression",
    "text": "Building a non-spatial multiple linear regression\n\nThe reportThe code chunk\n\n\n\n\n                              Model Summary                                \n--------------------------------------------------------------------------\nR                           0.859       RMSE                    61604.120 \nR-Squared                   0.737       MSE                3800583670.022 \nAdj. R-Squared              0.737       Coef. Var                  14.193 \nPred R-Squared              0.737       AIC                    257320.224 \nMAE                     47485.556       SBC                    257436.117 \n--------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares           DF       Mean Square       F          Sig. \n--------------------------------------------------------------------------------\nRegression    1.100899e+14           14      7.863561e+12     2069.04    0.0000 \nResidual      3.922202e+13        10320    3800583670.022                       \nTotal         1.493119e+14        10334                                         \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                 \n------------------------------------------------------------------------------------------------------------------\n                   model          Beta    Std. Error    Std. Beta       t        Sig          lower         upper \n------------------------------------------------------------------------------------------------------------------\n             (Intercept)    107601.073     10601.261                  10.150    0.000     86820.546    128381.599 \n          floor_area_sqm      2780.698        90.579        0.164     30.699    0.000      2603.146      2958.251 \n            storey_order     14299.298       339.115        0.234     42.167    0.000     13634.567     14964.029 \n    remaining_lease_mths       344.490         4.592        0.442     75.027    0.000       335.489       353.490 \n                PROX_CBD    -16930.196       201.254       -0.586    -84.124    0.000    -17324.693    -16535.700 \n        PROX_ELDERLYCARE    -14441.025       994.867       -0.079    -14.516    0.000    -16391.157    -12490.893 \n             PROX_HAWKER    -19265.648      1273.597       -0.083    -15.127    0.000    -21762.144    -16769.151 \n                PROX_MRT    -32564.272      1744.232       -0.105    -18.670    0.000    -35983.305    -29145.240 \n               PROX_PARK     -5712.625      1483.885       -0.021     -3.850    0.000     -8621.328     -2803.922 \n               PROX_MALL    -14717.388      2007.818       -0.044     -7.330    0.000    -18653.100    -10781.675 \n        PROX_SUPERMARKET    -26881.938      4189.624       -0.035     -6.416    0.000    -35094.414    -18669.462 \nWITHIN_350M_KINDERGARTEN      8520.472       632.812        0.072     13.464    0.000      7280.038      9760.905 \n   WITHIN_350M_CHILDCARE     -4510.650       354.015       -0.074    -12.741    0.000     -5204.589     -3816.711 \n         WITHIN_350M_BUS       813.493       222.574        0.020      3.655    0.000       377.205      1249.781 \n       WITHIN_1KM_PRISCH     -8010.834       491.512       -0.102    -16.298    0.000     -8974.293     -7047.376 \n------------------------------------------------------------------------------------------------------------------\n\n\n\n\n\n\nprice_mlr &lt;- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\nolsrr::ols_regress(price_mlr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#predictive-modelling-with-mlr",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#predictive-modelling-with-mlr",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "Predictive Modelling with MLR",
    "text": "Predictive Modelling with MLR\n\nComputing adaptive bandwidthModel calibrationModelling results\n\n\n\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\n\n\n[1] 40\n\n\n\n\n\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\n\n\n\n\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-19 09:40:27.26906 \n   Call:\n   gwr.basic(formula = resale_price ~ floor_area_sqm + storey_order + \n    remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n    PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data_sp, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 10335\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\n   Coefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\n   floor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\n   storey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\n   remaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\n   PROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\n   PROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\n   PROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\n   PROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\n   PROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\n   PROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\n   WITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\n   WITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\n   WITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\n   WITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61650 on 10320 degrees of freedom\n   Multiple R-squared: 0.7373\n   Adjusted R-squared: 0.737 \n   F-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.922202e+13\n   Sigma(hat): 61610.08\n   AIC:  257320.2\n   AICc:  257320.3\n   BIC:  247249\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 40 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -3.2478e+08 -4.7727e+05 -8.3004e+03  5.5025e+05\n   floor_area_sqm           -2.8714e+04  1.4475e+03  2.3011e+03  3.3900e+03\n   storey_order              3.3186e+03  8.5899e+03  1.0826e+04  1.3397e+04\n   remaining_lease_mths     -1.4431e+03  2.6063e+02  3.9048e+02  5.2865e+02\n   PROX_CBD                 -1.0837e+07 -5.7697e+04 -1.3787e+04  2.6552e+04\n   PROX_ELDERLYCARE         -3.2195e+07 -4.0643e+04  1.0562e+04  6.1054e+04\n   PROX_HAWKER              -2.3985e+08 -5.1365e+04  3.0026e+03  6.4287e+04\n   PROX_MRT                 -1.1632e+07 -1.0488e+05 -4.9373e+04  5.1037e+03\n   PROX_PARK                -6.5961e+06 -4.8671e+04 -8.8128e+02  5.3498e+04\n   PROX_MALL                -1.8112e+07 -7.4238e+04 -1.3982e+04  4.9779e+04\n   PROX_SUPERMARKET         -4.5761e+06 -6.3461e+04 -1.7429e+04  3.5616e+04\n   WITHIN_350M_KINDERGARTEN -4.1823e+05 -6.0040e+03  9.0209e+01  4.7127e+03\n   WITHIN_350M_CHILDCARE    -1.0273e+05 -2.2375e+03  2.6668e+02  2.6388e+03\n   WITHIN_350M_BUS          -1.1757e+05 -1.4719e+03  1.1626e+02  1.7584e+03\n   WITHIN_1KM_PRISCH        -6.6465e+05 -5.5959e+03  2.6916e+02  5.7500e+03\n                                  Max.\n   Intercept                1.6493e+08\n   floor_area_sqm           5.0907e+04\n   storey_order             2.9537e+04\n   remaining_lease_mths     1.8119e+03\n   PROX_CBD                 2.2411e+07\n   PROX_ELDERLYCARE         8.2444e+07\n   PROX_HAWKER              5.9654e+06\n   PROX_MRT                 2.0189e+08\n   PROX_PARK                1.5188e+07\n   PROX_MALL                1.0443e+07\n   PROX_SUPERMARKET         3.8330e+06\n   WITHIN_350M_KINDERGARTEN 6.6799e+05\n   WITHIN_350M_CHILDCARE    1.0802e+05\n   WITHIN_350M_BUS          3.7313e+04\n   WITHIN_1KM_PRISCH        5.0231e+05\n   ************************Diagnostic information*************************\n   Number of data points: 10335 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1730.101 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 8604.899 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 238871.9 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 237036.9 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 238209.1 \n   Residual sum of squares: 4.829191e+12 \n   R-square value:  0.967657 \n   Adjusted R-square value:  0.9611534 \n\n   ***********************************************************************\n   Program stops at: 2023-03-19 09:41:39.408622"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#predictive-modelling-with-mlr-1",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#predictive-modelling-with-mlr-1",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "Predictive Modelling with MLR",
    "text": "Predictive Modelling with MLR\nPredicting with test data\n\nTest data bwPredicting\n\n\n\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\n\n\n\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data, \n                        predictdata = test_data, \n                        bw=bw_adaptive, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#predictive-modelling-spatialml-methods",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#predictive-modelling-spatialml-methods",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "Predictive Modelling: SpatialML methods",
    "text": "Predictive Modelling: SpatialML methods\n\nPreparing coordinate dataDropping geometry fieldCalibrating RF modelCalibrating with grf()The model\n\n\n\n\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\n\n\n\n\n\ntrain_data_nogeom &lt;- train_data %&gt;%\n  st_drop_geometry()\n\n\n\n\n\n\nset.seed(1234)\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data_nogeom)\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       728602496 \nR squared (OOB):                  0.9495728 \n\n\n\n\n\n\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + \n                       storey_order + remaining_lease_mths + \n                       PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + \n                       PROX_MALL + PROX_SUPERMARKET + \n                       WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + \n                       WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data_nogeom, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n\n\n\n\n\n\ngwRF_adaptive &lt;- read_rds(\"data/model/gwRF_adaptive.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#predicting-by-using-the-test-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#predicting-by-using-the-test-data",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "Predicting by using the test data",
    "text": "Predicting by using the test data\n\nPreparing the test dataPredicting with the test dataCreating DF\n\n\n\n\ntest_data_nogeom &lt;- cbind(\n  test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n\n\n\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data_nogeom, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\n\n\n\n\n\nGRF_pred &lt;- read_rds(\"data/model/GRF_pred.rds\")\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\n\n\n\n\ntest_data_pred &lt;- cbind(test_data, \n                        GRF_pred_df)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#visualising-the-predicted-values",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08-gwRF.html#visualising-the-predicted-values",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Modelling",
    "section": "Visualising the predicted values",
    "text": "Visualising the predicted values\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = test_data_pred,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#getting-started",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#getting-started",
    "title": "In-class Exercise 9: Geography of Accessibility",
    "section": "Getting Started",
    "text": "Getting Started\n\n\npacman::p_load(SpatialAcc, sf, tidyverse, \n               tmap, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#importing-data",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#importing-data",
    "title": "In-class Exercise 9: Geography of Accessibility",
    "section": "Importing Data",
    "text": "Importing Data\n\nGeospatail dataOD Matrix\n\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_NO_SEA_PL\") %&gt;%\n  st_transform(crs = 3414)\n\nhexagons &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"hexagons\") %&gt;%\n  st_transform(crs = 3414)\n\neldercare &lt;- st_read(dsn = \"data/geospatial\",\n                     layer = \"ELDERCARE\") %&gt;%\n  st_transform(csr = 3414)\n\n\n\n\n\n\nODMatrix &lt;- read_csv(\"data/aspatial/OD_Matrix.csv\", \n                     skip = 0)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#data-cleaning-and-updating-attributes",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#data-cleaning-and-updating-attributes",
    "title": "In-class Exercise 9: Geography of Accessibility",
    "section": "Data cleaning and Updating Attributes",
    "text": "Data cleaning and Updating Attributes\n\nSupplyDemandOD Matrix\n\n\n\n\neldercare &lt;- eldercare %&gt;%\n  select(fid, ADDRESSPOS) %&gt;%\n  mutate(capacity = 100)\n\n\n\n\n\n\nhexagons &lt;- hexagons %&gt;%\n  select(fid) %&gt;%\n  mutate(demand = 100)\n\n\n\n\n\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  spread(destination_id, total_cost)%&gt;%\n  select(c(-c('origin_id')))\n\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#computing-handsens-accessibility",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#computing-handsens-accessibility",
    "title": "In-class Exercise 9: Geography of Accessibility",
    "section": "Computing Handsen’s Accessibility",
    "text": "Computing Handsen’s Accessibility\n\nThe base codeTidy the outputCombine code chunk\n\n\n\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 2, \n                            family = \"Hansen\"))\n\n\n\n\n\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n\nacc_Hansen &lt;- as_tibble(acc_Hansen)\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)\n\n\n\n\n\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 0.5, \n                            family = \"Hansen\"))\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\nacc_Hansen &lt;- as_tibble(acc_Hansen)\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/data/geospatial/hexagons.html",
    "href": "In-class_Ex/In-class_Ex09/data/geospatial/hexagons.html",
    "title": "ISSS626 Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                 0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/data/geospatial/ELDERCARE.html",
    "href": "In-class_Ex/In-class_Ex09/data/geospatial/ELDERCARE.html",
    "title": "ISSS626 Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  ELDERCARE  ENG dataset\n\nELDERCARE\n\n                 0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#count-number-of-points-within-a-distance",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#count-number-of-points-within-a-distance",
    "title": "In-class Exercise 9: Geography of Accessibility",
    "section": "Count Number of Points within a Distance",
    "text": "Count Number of Points within a Distance\n\nThe taskDIYThe codeBufferingVisualisingCounting points\n\n\n\nTo count number of point features (i.e. CHAS clinics) within 1km of another point features (i.e. eldercare centre).\n\n\n\n\n\n\n\nNote\n\n\nTo complete this section of the in-class exercise, you need to download both the CHAS Clinics and Eldercare Services data sets from data.gov.sg portal. The in-class exercise assumes explicitly the downloaded data sets are saved in rawdata sub-folder of In-class_Ex09 folder. Remember to unzip the file if necessary.\n\n\n\n\n\n\nDownload ELDERCARE shapefile and CHAS kml file from data.gov.sg\nUsing the steps your learned in Hands-on Exercise 1, import ELDERCARE shapefile and CHAS kml file into R\n\n\n\nELDERCARE is in shapefile format, the code chunk below will be used:\n\n\neldercare &lt;- st_read(dsn = \"data/rawdata\",\n                     layer = \"ELDERCARE\") %&gt;%\n  st_transform(crs = 3414)\n\n\nThe code chunk below is used to import kml file.\n\n\nCHAS &lt;- st_read(\"data/rawdata/CHASClinics.kml\") %&gt;%\n  st_transform(crs = 3414)\n\n\n\n\nNext, st_buffer() of sf package is used to create a buffer of 1km around each eldercare features\n\n\nbuffer_1km &lt;- st_buffer(eldercare, \n                        dist = 1000)\n\n\n\n\n\n\nThe code chunk below is used to plot the newly created buffers and the CHAS clinics.\n\n\ntmap_mode(\"view\")\ntm_shape(buffer_1km) +\n  tm_polygons() +\ntm_shape(CHAS) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLastly, the code chunk below is used to count the number of CHAS clinics with 1km of each eldercare centre.\n\n\nbuffer_1km$pts_count &lt;- lengths(\n  st_intersects(buffer_1km, CHAS))"
  },
  {
<<<<<<< HEAD
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#learning-outcome",
    "title": "In-class Exercise 10: Working with Open Government Data",
    "section": "Learning Outcome",
    "text": "Learning Outcome\nBy the end of this hands-on exercise, you will be able to:\n\nPreparing data downloaded from REALIS portal for geocoding,\nGeocoding by using SLA OneMap API,\nConverting the geocoded transaction data into sf point feature data.frame, and\nWrangling the sf point features to avoid overlapping point features."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#loading-the-r-package",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#loading-the-r-package",
    "title": "In-class Exercise 10: Working with Open Government Data",
    "section": "Loading the R package",
    "text": "Loading the R package\n\n\npacman::p_load(tidyverse, sf, tmap, httr, performance)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#importing-data",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#importing-data",
    "title": "In-class Exercise 10: Working with Open Government Data",
    "section": "Importing data",
    "text": "Importing data\nThe code chunk below imports multiple csv files in a specified folder and append them into a single tibble data frame.\n\n\nfolder_path &lt;- \"data/aspatial\"\nfile_list &lt;- list.files(path = folder_path, \n                        pattern = \"^realis.*\\\\.csv$\", \n                        full.names = TRUE)\n\nrealis_data &lt;- file_list %&gt;%\n  map_dfr(read_csv)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#wrangling-data",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#wrangling-data",
    "title": "In-class Exercise 10: Working with Open Government Data",
    "section": "Wrangling data",
    "text": "Wrangling data\n\nThe taskThe code\n\n\nWrite a code chunk to perform the followings: - converting values in Sale Date field from character to numerical date format, and - extracting resale and condominium transaction records.\n\n\n\n\ncondo_resale &lt;- realis_data %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`)) %&gt;%\n  filter(`Type of Sale` == \"Resale\" &\n           `Property Type` == \"Condominium\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#geocoding",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#geocoding",
    "title": "In-class Exercise 10: Working with Open Government Data",
    "section": "Geocoding",
    "text": "Geocoding\n\nPreparing dataGeocoding\n\n\n\n\npostcode &lt;- unique(condo_resale$`Postal Code`)\n\n\n\n\n\n\nurl &lt;- \"https://onemap.gov.sg/api/common/elastic/search\"\nfound &lt;- data.frame()\nnot_found &lt;- data.frame()\n\nfor (postcode in postcode){\n  query &lt;- list('searchVal'=postcode, 'returnGeom'='Y', \n                'getAddrDetails'='Y', 'pageNum'='1')\n  res &lt;- GET(url, query=query)\n  if ((content(res)$found)!=0){\n    found &lt;- rbind(found, data.frame(content(res))[4:13])\n  } else {not_found = data.frame(postcode)\n  }\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#tidying-field-names",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#tidying-field-names",
    "title": "In-class Exercise 10: Working with Open Government Data",
    "section": "Tidying field names",
    "text": "Tidying field names\n\n\nfound &lt;- found %&gt;%\n  select(c(6:8)) %&gt;%\n  rename(POSTAL = `results.POSTAL`,\n         XCOORD = `results.X`,\n         YCOORD = `results.Y`)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#converting-to-point-feature-data-frame",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#converting-to-point-feature-data-frame",
    "title": "In-class Exercise 10: Working with Open Government Data",
    "section": "Converting to Point Feature Data Frame",
    "text": "Converting to Point Feature Data Frame\n\nThe tasksJoining tablesConvering to sf\n\n\n\nWrite a code chunk to join condo_resale and found. Name the output condo_resale_geocoded.\nWrite a code chunk to convert condo_resale_geocoded from tibble data frame to sf point feature data frame.\n\n\n\n\n\ncondo_resale_geocoded = left_join(\n  condo_resale, found, \n  by = c('Postal Code' = 'POSTAL'))\n\n\n\n\n\n\ncondo_resale_sf &lt;- st_as_sf(condo_resale_geocoded, \n                            coords = c(\"XCOORD\",\n                                       \"YCOORD\"),\n                            crs=3414)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#cleaning-spatial-data",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10.html#cleaning-spatial-data",
    "title": "In-class Exercise 10: Working with Open Government Data",
    "section": "Cleaning Spatial Data",
    "text": "Cleaning Spatial Data\n\nChecking for overlapping point featuresSpatial jittering\n\n\nThe code chunk below is used to check if there are overlapping point features.\n\n\noverlapping_points &lt;- condo_resale_sf %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\n\n\n\nIn the code code chunk below, st_jitter() of sf package is used to move the point features by 5m to avoid overlapping point features.\n\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;%\n  st_jitter(amount = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html",
    "title": "Calibrating Spatial Interaction Models with R",
    "section": "",
    "text": "Spatial Interaction Models (SIMs) are mathematical models for estimating flows between spatial entities developed by Alan Wilson in the late 1960s and early 1970, with considerable uptake and refinement for transport modelling since then Boyce and Williams (2015).\nThere are four main types of traditional SIMs (Wilson 1971):\n\nUnconstrained\nProduction-constrained\nAttraction-constrained\nDoubly-constrained\n\nOrdinary least square (OLS), log-normal, Poisson and negative binomial (NB) regression methods have been used extensively to calibrate OD flow models by processing flow data as different types of dependent variables. In this chapter, you will gain hands-on experiences on using appropriate R packages to calibrate SIM by using there four regression methods.\n\n\n\n\n\n\nNote\n\n\n\nCalibration is the process of adjusting parameters in the model to try and get the estimates to agree with the observed data as much as possible. Adjusting the parameters is the sort of iterative process that computers are particularly good at and the goodness-of-fit statistics can be used to indicate when the optimum solution is found. Historically this process required a researcher with the requisite programming skills to write a computer algorithm to iteratively adjust each parameter, check the goodness-of-fit, and then start all over again until the goodness-of-fit statistic was maximised/minimised. (Adam Dennett, 2018)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#overview",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#overview",
    "title": "Calibrating Spatial Interaction Models with R",
    "section": "",
    "text": "Spatial Interaction Models (SIMs) are mathematical models for estimating flows between spatial entities developed by Alan Wilson in the late 1960s and early 1970, with considerable uptake and refinement for transport modelling since then Boyce and Williams (2015).\nThere are four main types of traditional SIMs (Wilson 1971):\n\nUnconstrained\nProduction-constrained\nAttraction-constrained\nDoubly-constrained\n\nOrdinary least square (OLS), log-normal, Poisson and negative binomial (NB) regression methods have been used extensively to calibrate OD flow models by processing flow data as different types of dependent variables. In this chapter, you will gain hands-on experiences on using appropriate R packages to calibrate SIM by using there four regression methods.\n\n\n\n\n\n\nNote\n\n\n\nCalibration is the process of adjusting parameters in the model to try and get the estimates to agree with the observed data as much as possible. Adjusting the parameters is the sort of iterative process that computers are particularly good at and the goodness-of-fit statistics can be used to indicate when the optimum solution is found. Historically this process required a researcher with the requisite programming skills to write a computer algorithm to iteratively adjust each parameter, check the goodness-of-fit, and then start all over again until the goodness-of-fit statistic was maximised/minimised. (Adam Dennett, 2018)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#the-case-study-and-data",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#the-case-study-and-data",
    "title": "Calibrating Spatial Interaction Models with R",
    "section": "The Case Study and Data",
    "text": "The Case Study and Data\nIn this exercise, we are going to calibrate SIM to determine factors affecting the public bus passenger flows during the morning peak in Singapore."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#getting-started",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#getting-started",
    "title": "Calibrating Spatial Interaction Models with R",
    "section": "Getting Started",
    "text": "Getting Started\nFor the purpose of this exercise, four r packages will be used. They are:\n\nsf for importing, integrating, processing and transforming geospatial data.\ntidyverse for importing, integrating, wrangling and visualising data.\ntmap for creating thematic maps.\n\n\npacman::p_load(tmap, sf, sp,\n               performance, reshape2,\n               ggpubr, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#the-data",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#the-data",
    "title": "Calibrating Spatial Interaction Models with R",
    "section": "The Data",
    "text": "The Data\nThis exercise is a continuation of Chapter 15: Processing and Visualising Flow Data and the following data will be used:\n\nod_data.rds, weekday morning peak passenger flows at planning subzone level.\nmpsz.rds, URA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.\n\nBeside these two data sets, an additional attribute data file called pop.csv will be provided. It"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#computing-distance-matrix",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#computing-distance-matrix",
    "title": "Calibrating Spatial Interaction Models with R",
    "section": "Computing Distance Matrix",
    "text": "Computing Distance Matrix\nIn spatial interaction, a distance matrix is a table that shows the distance between pairs of locations. For example, in the table below we can see an Euclidean distance of 3926.0025 between MESZ01 and RVSZ05, of 3939.1079 between MESZ01 and SRSZ01, and so on. By definition, an location’s distance from itself, which is shown in the main diagonal of the table, is 0.\n\nIn this section, you will learn how to compute a distance matrix by using URA Master Plan 2019 Planning Subzone boundary in which you saved as an rds file called mpsz.\nFirst, let us import mpsz.rds into R environemnt by using the code chunk below.\n\nmpsz &lt;- read_rds(\"data/rds/mpsz.rds\")\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\nNotice that it is a sf tibble dataframe object class.\n\nConverting from sf data.table to SpatialPolygonsDataFrame\nThere are at least two ways to compute the required distance matrix. One is based on sf and the other is based on sp. Past experience shown that computing distance matrix by using sf function took relatively longer time that sp method especially the data set is large. In view of this, sp method is used in the code chunks below.\nFirst as.Spatial() will be used to convert mpsz from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.\n\nmpsz_sp &lt;- as(mpsz, \"Spatial\")\nmpsz_sp\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR \n\n\n\n\nComputing the distance matrix\nNext, spDists() of sp package will be used to compute the Euclidean distance between the centroids of the planning subzones.\n\n\n\n\n\n\nQ&A\n\n\n\nDo you know why the distance is calculated between two centroids of a pair of spatial polygons?\n\n\n\ndist &lt;- spDists(mpsz_sp, \n                longlat = FALSE)\n\n\nhead(dist, n=c(10, 10))\n\n           [,1]       [,2]      [,3]      [,4]       [,5]      [,6]      [,7]\n [1,]     0.000  3926.0025  3939.108 20252.964  2989.9839  1431.330 19211.836\n [2,]  3926.003     0.0000   305.737 16513.865   951.8314  5254.066 16242.523\n [3,]  3939.108   305.7370     0.000 16412.062  1045.9088  5299.849 16026.146\n [4,] 20252.964 16513.8648 16412.062     0.000 17450.3044 21665.795  7229.017\n [5,]  2989.984   951.8314  1045.909 17450.304     0.0000  4303.232 17020.916\n [6,]  1431.330  5254.0664  5299.849 21665.795  4303.2323     0.000 20617.082\n [7,] 19211.836 16242.5230 16026.146  7229.017 17020.9161 20617.082     0.000\n [8,] 14960.942 12749.4101 12477.871 11284.279 13336.0421 16281.453  5606.082\n [9,]  7515.256  7934.8082  7649.776 18427.503  7801.6163  8403.896 14810.930\n[10,]  6391.342  4975.0021  4669.295 15469.566  5226.8731  7707.091 13111.391\n           [,8]      [,9]     [,10]\n [1,] 14960.942  7515.256  6391.342\n [2,] 12749.410  7934.808  4975.002\n [3,] 12477.871  7649.776  4669.295\n [4,] 11284.279 18427.503 15469.566\n [5,] 13336.042  7801.616  5226.873\n [6,] 16281.453  8403.896  7707.091\n [7,]  5606.082 14810.930 13111.391\n [8,]     0.000  9472.024  8575.490\n [9,]  9472.024     0.000  3780.800\n[10,]  8575.490  3780.800     0.000\n\n\nNotice that the output dist is a matrix object class of R. Also notice that the column heanders and row headers are not labeled with the planning subzone codes.\n\n\nLabelling column and row heanders of a distance matrix\nFirst, we will create a list sorted according to the the distance matrix by planning sub-zone code.\n\nsz_names &lt;- mpsz$SUBZONE_C\n\nNext we will attach SUBZONE_C to row and column for distance matrix matching ahead\n\ncolnames(dist) &lt;- paste0(sz_names)\nrownames(dist) &lt;- paste0(sz_names)\n\n\n\nPivoting distance value by SUBZONE_C\nNext, we will pivot the distance matrix into a long table by using the row and column subzone codes as show in the code chunk below.\n\ndistPair &lt;- melt(dist) %&gt;%\n  rename(dist = value)\nhead(distPair, 10)\n\nNotice that the within zone distance is 0.\n\n\nUpdating intra-zonal distances\nIn this section, we are going to append a constant value to replace the intra-zonal distance of 0.\nFirst, we will select and find out the minimum value of the distance by using summary().\n\ndistPair %&gt;%\n  filter(dist &gt; 0) %&gt;%\n  summary()\n\nNext, a constant distance value of 50m is added into intra-zones distance.\n\ndistPair$dist &lt;- ifelse(distPair$dist == 0,\n                        50, distPair$dist)\n\nThe code chunk below will be used to check the result data.frame.\n\ndistPair %&gt;%\n  summary()\n\nThe code chunk below is used to rename the origin and destination fields.\n\ndistPair &lt;- distPair %&gt;%\n  rename(orig = Var1,\n         dest = Var2)\n\nLastly, the code chunk below is used to save the dataframe for future use.\n\nwrite_rds(distPair, \"data/rds/distPair.rds\") \n\n\ndistPair &lt;- read_rds(\"data/rds/distPair.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#preparing-flow-data",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#preparing-flow-data",
    "title": "Calibrating Spatial Interaction Models with R",
    "section": "Preparing flow data",
    "text": "Preparing flow data\nThe code chunk below is used import od_data save in Chapter 15 into R environment.\n\nod_data_fii &lt;- read_rds(\"data/rds/od_data_fii.rds\")\n\nNext, we will compute the total passenger trip between and within planning subzones by using the code chunk below. The output is all flow_data.\n\nflow_data &lt;- od_data_fii %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;% \n  summarize(TRIPS = sum(MORNING_PEAK)) \n\nUse the code chunk below to display flow_data dataframe.\n\nhead(flow_data, 10)\n\n\nSeparating intra-flow from passenger volume df\nCode chunk below is used to add three new fields in flow_data dataframe.\n\nflow_data$FlowNoIntra &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0, flow_data$TRIPS)\nflow_data$offset &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0.000001, 1)\n\n\n\nCombining passenger volume data with distance value\nBefore we can join flow_data and distPair, we need to convert data value type of ORIGIN_SZ and DESTIN_SZ fields of flow_data dataframe into factor data type.\n\nflow_data$ORIGIN_SZ &lt;- as.factor(flow_data$ORIGIN_SZ)\nflow_data$DESTIN_SZ &lt;- as.factor(flow_data$DESTIN_SZ)\n\nNow, left_join() of dplyr will be used to flow_data dataframe and distPair dataframe. The output is called flow_data1.\n\nflow_data1 &lt;- flow_data %&gt;%\n  left_join (distPair,\n             by = c(\"ORIGIN_SZ\" = \"orig\",\n                    \"DESTIN_SZ\" = \"dest\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#preparing-origin-and-destination-attributes",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#preparing-origin-and-destination-attributes",
    "title": "Calibrating Spatial Interaction Models with R",
    "section": "Preparing Origin and Destination Attributes",
    "text": "Preparing Origin and Destination Attributes\n\nImporting population data\n\npop &lt;- read_csv(\"data/aspatial/pop.csv\")\n\n\n\nGeospatial data wrangling\n\npop &lt;- pop %&gt;%\n  left_join(mpsz,\n            by = c(\"PA\" = \"PLN_AREA_N\",\n                   \"SZ\" = \"SUBZONE_N\")) %&gt;%\n  select(1:6) %&gt;%\n  rename(SZ_NAME = SZ,\n         SZ = SUBZONE_C)\n\n\n\nPreparing origin attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(ORIGIN_SZ = \"SZ\")) %&gt;%\n  rename(ORIGIN_AGE7_12 = AGE7_12,\n         ORIGIN_AGE13_24 = AGE13_24,\n         ORIGIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\n\n\nPreparing destination attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(DESTIN_SZ = \"SZ\")) %&gt;%\n  rename(DESTIN_AGE7_12 = AGE7_12,\n         DESTIN_AGE13_24 = AGE13_24,\n         DESTIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\nWe will called the output data file SIM_data. it is in rds data file format.\n\nwrite_rds(flow_data1, \"data/rds/flow_data_6-9.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#calibrating-spatial-interaction-models",
    "href": "In-class_Ex/In-class_Ex10/In-class_Ex10-SIM.html#calibrating-spatial-interaction-models",
    "title": "Calibrating Spatial Interaction Models with R",
    "section": "Calibrating Spatial Interaction Models",
    "text": "Calibrating Spatial Interaction Models\nIn this section, you will learn how to calibrate Spatial Interaction Models by using Poisson Regression method.\n\nImporting the modelling data\nFirstly, let us import the modelling data by using the code chunk below.\n\nSIM_data &lt;- read_rds(\"data/rds/SIM_data.rds\")\n\n\n\nVisualising the dependent variable\nFirstly, let us plot the distribution of the dependent variable (i.e. TRIPS) by using histogram method by using the code chunk below.\n\nggplot(data = SIM_data,\n       aes(x = TRIPS)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nNotice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.\nNext, let us visualise the relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance.\n\nggplot(data = SIM_data,\n       aes(x = dist,\n           y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\nNotice that their relationship hardly resemble linear relationship.\nOn the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship is more resemble linear relationship.\n\nggplot(data = SIM_data,\n       aes(x = log(dist),\n           y = log(TRIPS))) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\n\n\nChecking for variables with zero values\nSince Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that no 0 values in the explanatory variables.\nIn the code chunk below, summary() of Base R is used to compute the summary statistics of all variables in SIM_data data frame.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS           FlowNoIntra      \n Length:14274       Length:14274       Min.   :     1.0   Min.   :     1.0  \n Class :character   Class :character   1st Qu.:    11.0   1st Qu.:    11.0  \n Mode  :character   Mode  :character   Median :    56.0   Median :    56.0  \n                                       Mean   :   664.3   Mean   :   664.3  \n                                       3rd Qu.:   296.0   3rd Qu.:   296.0  \n                                       Max.   :104167.0   Max.   :104167.0  \n     offset       dist         ORIGIN_AGE7_12 ORIGIN_AGE13_24 ORIGIN_AGE25_64\n Min.   :1   Min.   :  173.8   Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.:1   1st Qu.: 3465.4   1st Qu.: 240   1st Qu.:  460   1st Qu.: 2210  \n Median :1   Median : 6121.0   Median : 710   Median : 1400   Median : 7030  \n Mean   :1   Mean   : 6951.8   Mean   :1037   Mean   : 2278   Mean   :10536  \n 3rd Qu.:1   3rd Qu.: 9725.1   3rd Qu.:1500   3rd Qu.: 3282   3rd Qu.:15830  \n Max.   :1   Max.   :26135.8   Max.   :6340   Max.   :16380   Max.   :74610  \n DESTIN_AGE7_12 DESTIN_AGE13_24 DESTIN_AGE25_64\n Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.: 250   1st Qu.:  460   1st Qu.: 2210  \n Median : 720   Median : 1430   Median : 7120  \n Mean   :1040   Mean   : 2305   Mean   :10648  \n 3rd Qu.:1500   3rd Qu.: 3290   3rd Qu.:15830  \n Max.   :6340   Max.   :16380   Max.   :74610  \n\n\nThe print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.\nIn view of this, code chunk below will be used to replace zero values to 0.99.\n\nSIM_data$DESTIN_AGE7_12 &lt;- ifelse(\n  SIM_data$DESTIN_AGE7_12 == 0,\n  0.99, SIM_data$DESTIN_AGE7_12)\nSIM_data$DESTIN_AGE13_24 &lt;- ifelse(\n  SIM_data$DESTIN_AGE13_24 == 0,\n  0.99, SIM_data$DESTIN_AGE13_24)\nSIM_data$DESTIN_AGE25_64 &lt;- ifelse(\n  SIM_data$DESTIN_AGE25_64 == 0,\n  0.99, SIM_data$DESTIN_AGE25_64)\nSIM_data$ORIGIN_AGE7_12 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE7_12 == 0,\n  0.99, SIM_data$ORIGIN_AGE7_12)\nSIM_data$ORIGIN_AGE13_24 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE13_24 == 0,\n  0.99, SIM_data$ORIGIN_AGE13_24)\nSIM_data$ORIGIN_AGE25_64 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE25_64 == 0,\n  0.99, SIM_data$ORIGIN_AGE25_64)\n\nYou can run the summary() again.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS           FlowNoIntra      \n Length:14274       Length:14274       Min.   :     1.0   Min.   :     1.0  \n Class :character   Class :character   1st Qu.:    11.0   1st Qu.:    11.0  \n Mode  :character   Mode  :character   Median :    56.0   Median :    56.0  \n                                       Mean   :   664.3   Mean   :   664.3  \n                                       3rd Qu.:   296.0   3rd Qu.:   296.0  \n                                       Max.   :104167.0   Max.   :104167.0  \n     offset       dist         ORIGIN_AGE7_12    ORIGIN_AGE13_24   \n Min.   :1   Min.   :  173.8   Min.   :   0.99   Min.   :    0.99  \n 1st Qu.:1   1st Qu.: 3465.4   1st Qu.: 240.00   1st Qu.:  460.00  \n Median :1   Median : 6121.0   Median : 710.00   Median : 1400.00  \n Mean   :1   Mean   : 6951.8   Mean   :1036.73   Mean   : 2278.59  \n 3rd Qu.:1   3rd Qu.: 9725.1   3rd Qu.:1500.00   3rd Qu.: 3282.50  \n Max.   :1   Max.   :26135.8   Max.   :6340.00   Max.   :16380.00  \n ORIGIN_AGE25_64    DESTIN_AGE7_12    DESTIN_AGE13_24    DESTIN_AGE25_64   \n Min.   :    0.99   Min.   :   0.99   Min.   :    0.99   Min.   :    0.99  \n 1st Qu.: 2210.00   1st Qu.: 250.00   1st Qu.:  460.00   1st Qu.: 2210.00  \n Median : 7030.00   Median : 720.00   Median : 1430.00   Median : 7120.00  \n Mean   :10535.93   Mean   :1039.98   Mean   : 2305.33   Mean   :10647.95  \n 3rd Qu.:15830.00   3rd Qu.:1500.00   3rd Qu.: 3290.00   3rd Qu.:15830.00  \n Max.   :74610.00   Max.   :6340.00   Max.   :16380.00   Max.   :74610.00  \n\n\nNotice that all the 0 values have been replaced by 0.99.\n\n\nUnconstrained Spatial Interaction Model\nIn this section, you will learn how to calibrate an unconstrained spatial interaction model by using glm() of Base Stats. The explanatory variables are origin population by different age cohort, destination population by different age cohort (i.e. ORIGIN_AGE25_64) and distance between origin and destination in km (i.e. dist).\nThe general formula of Unconstrained Spatial Interaction Model\n\nThe code chunk used to calibrate to model is shown below:\n\nuncSIM &lt;- glm(formula = TRIPS ~ \n                log(ORIGIN_AGE25_64) + \n                log(DESTIN_AGE25_64) +\n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nuncSIM\n\n\nCall:  glm(formula = TRIPS ~ log(ORIGIN_AGE25_64) + log(DESTIN_AGE25_64) + \n    log(dist), family = poisson(link = \"log\"), data = SIM_data, \n    na.action = na.exclude)\n\nCoefficients:\n         (Intercept)  log(ORIGIN_AGE25_64)  log(DESTIN_AGE25_64)  \n            17.00287               0.21001               0.01289  \n           log(dist)  \n            -1.51785  \n\nDegrees of Freedom: 14273 Total (i.e. Null);  14270 Residual\nNull Deviance:      36120000 \nResidual Deviance: 19960000     AIC: 20040000\n\n\n\n\nR-squared function\nIn order to measure how much variation of the trips can be accounted by the model we will write a function to calculate R-Squared value as shown below.\n\nCalcRSquared &lt;- function(observed,estimated){\n  r &lt;- cor(observed,estimated)\n  R2 &lt;- r^2\n  R2\n}\n\nNext, we will compute the R-squared of the unconstrained SIM by using the code chunk below.\n\nCalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)\n\n[1] 0.1694734\n\n\n\nr2_mcfadden(uncSIM)\n\n# R2 for Generalized Linear Regression\n       R2: 0.446\n  adj. R2: 0.446\n\n\n\n\nOrigin (Production) constrained SIM\nIn this section, we will fit an origin constrained SIM by using the code3 chunk below.\nThe general formula of Origin Constrained Spatial Interaction Model\n\n\norcSIM &lt;- glm(formula = TRIPS ~ \n                 ORIGIN_SZ +\n                 log(DESTIN_AGE25_64) +\n                 log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(orcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + log(DESTIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          19.9309957  0.0054015  3689.887  &lt; 2e-16 ***\nORIGIN_SZAMSZ02       0.6805710  0.0052686   129.175  &lt; 2e-16 ***\nORIGIN_SZAMSZ03       0.3597850  0.0054884    65.554  &lt; 2e-16 ***\nORIGIN_SZAMSZ04      -0.1106566  0.0060027   -18.434  &lt; 2e-16 ***\nORIGIN_SZAMSZ05      -0.3140561  0.0067998   -46.186  &lt; 2e-16 ***\nORIGIN_SZAMSZ06       0.0634425  0.0060258    10.528  &lt; 2e-16 ***\nORIGIN_SZAMSZ07      -1.1301580  0.0110298  -102.464  &lt; 2e-16 ***\nORIGIN_SZAMSZ08      -0.6330394  0.0102949   -61.491  &lt; 2e-16 ***\nORIGIN_SZAMSZ09       0.1064915  0.0063450    16.784  &lt; 2e-16 ***\nORIGIN_SZAMSZ10       0.5061899  0.0053889    93.931  &lt; 2e-16 ***\nORIGIN_SZAMSZ11      -1.3167911  0.0144870   -90.895  &lt; 2e-16 ***\nORIGIN_SZAMSZ12      -1.5103004  0.0127453  -118.499  &lt; 2e-16 ***\nORIGIN_SZBDSZ01       1.3626004  0.0051433   264.929  &lt; 2e-16 ***\nORIGIN_SZBDSZ02       0.9554084  0.0059655   160.156  &lt; 2e-16 ***\nORIGIN_SZBDSZ03       1.1476190  0.0054278   211.433  &lt; 2e-16 ***\nORIGIN_SZBDSZ04       2.0110410  0.0046344   433.940  &lt; 2e-16 ***\nORIGIN_SZBDSZ05       1.0658940  0.0053976   197.477  &lt; 2e-16 ***\nORIGIN_SZBDSZ06       1.2719222  0.0054774   232.213  &lt; 2e-16 ***\nORIGIN_SZBDSZ07      -0.5053039  0.0111553   -45.297  &lt; 2e-16 ***\nORIGIN_SZBDSZ08      -0.3556193  0.0102947   -34.544  &lt; 2e-16 ***\nORIGIN_SZBKSZ01      -0.3606399  0.0075473   -47.784  &lt; 2e-16 ***\nORIGIN_SZBKSZ02       0.1357265  0.0061394    22.107  &lt; 2e-16 ***\nORIGIN_SZBKSZ03       0.4101999  0.0058983    69.545  &lt; 2e-16 ***\nORIGIN_SZBKSZ04      -0.3418645  0.0070764   -48.310  &lt; 2e-16 ***\nORIGIN_SZBKSZ05      -0.2986750  0.0074073   -40.322  &lt; 2e-16 ***\nORIGIN_SZBKSZ06      -0.2637855  0.0068739   -38.375  &lt; 2e-16 ***\nORIGIN_SZBKSZ07       0.5498323  0.0051476   106.813  &lt; 2e-16 ***\nORIGIN_SZBKSZ08      -0.0527393  0.0061457    -8.582  &lt; 2e-16 ***\nORIGIN_SZBKSZ09      -0.1564691  0.0067300   -23.249  &lt; 2e-16 ***\nORIGIN_SZBLSZ01      -1.7551329  0.0176599   -99.385  &lt; 2e-16 ***\nORIGIN_SZBLSZ02      -1.9493637  0.0213859   -91.152  &lt; 2e-16 ***\nORIGIN_SZBLSZ03      -2.9057732  0.0535995   -54.213  &lt; 2e-16 ***\nORIGIN_SZBLSZ04      -1.4672066  0.0254726   -57.599  &lt; 2e-16 ***\nORIGIN_SZBMSZ01       0.1806064  0.0060563    29.821  &lt; 2e-16 ***\nORIGIN_SZBMSZ02      -1.4026549  0.0078244  -179.267  &lt; 2e-16 ***\nORIGIN_SZBMSZ03      -0.5976236  0.0063808   -93.660  &lt; 2e-16 ***\nORIGIN_SZBMSZ04      -0.5456513  0.0059061   -92.388  &lt; 2e-16 ***\nORIGIN_SZBMSZ05      -3.1095195  0.0188118  -165.297  &lt; 2e-16 ***\nORIGIN_SZBMSZ06      -3.0273827  0.0194319  -155.794  &lt; 2e-16 ***\nORIGIN_SZBMSZ07      -0.7378197  0.0066865  -110.345  &lt; 2e-16 ***\nORIGIN_SZBMSZ08      -0.9306150  0.0067188  -138.510  &lt; 2e-16 ***\nORIGIN_SZBMSZ09      -1.4137345  0.0101071  -139.876  &lt; 2e-16 ***\nORIGIN_SZBMSZ10      -1.7054195  0.0101582  -167.886  &lt; 2e-16 ***\nORIGIN_SZBMSZ11      -1.2418380  0.0076792  -161.714  &lt; 2e-16 ***\nORIGIN_SZBMSZ12      -1.3746537  0.0109769  -125.231  &lt; 2e-16 ***\nORIGIN_SZBMSZ13      -0.4339494  0.0069335   -62.587  &lt; 2e-16 ***\nORIGIN_SZBMSZ14      -0.9950458  0.0076302  -130.410  &lt; 2e-16 ***\nORIGIN_SZBMSZ15      -0.6544196  0.0068964   -94.892  &lt; 2e-16 ***\nORIGIN_SZBMSZ16      -1.5193747  0.0105329  -144.250  &lt; 2e-16 ***\nORIGIN_SZBMSZ17      -1.6536771  0.0180672   -91.529  &lt; 2e-16 ***\nORIGIN_SZBPSZ01       0.1484355  0.0064734    22.930  &lt; 2e-16 ***\nORIGIN_SZBPSZ02      -0.3602094  0.0073902   -48.741  &lt; 2e-16 ***\nORIGIN_SZBPSZ03      -0.1567975  0.0072226   -21.709  &lt; 2e-16 ***\nORIGIN_SZBPSZ04       0.4504873  0.0058418    77.115  &lt; 2e-16 ***\nORIGIN_SZBPSZ05       0.5028646  0.0053682    93.675  &lt; 2e-16 ***\nORIGIN_SZBPSZ06      -1.0125668  0.0105638   -95.853  &lt; 2e-16 ***\nORIGIN_SZBPSZ07      -0.3859065  0.0098561   -39.154  &lt; 2e-16 ***\nORIGIN_SZBSSZ01       0.1488497  0.0065504    22.724  &lt; 2e-16 ***\nORIGIN_SZBSSZ02       0.4269498  0.0055893    76.387  &lt; 2e-16 ***\nORIGIN_SZBSSZ03      -0.2437385  0.0062020   -39.300  &lt; 2e-16 ***\nORIGIN_SZBTSZ01       0.1987940  0.0066672    29.817  &lt; 2e-16 ***\nORIGIN_SZBTSZ02      -0.4571546  0.0090784   -50.356  &lt; 2e-16 ***\nORIGIN_SZBTSZ03      -0.2697243  0.0077941   -34.606  &lt; 2e-16 ***\nORIGIN_SZBTSZ04      -1.0997236  0.0115225   -95.441  &lt; 2e-16 ***\nORIGIN_SZBTSZ05      -1.0053122  0.0132594   -75.819  &lt; 2e-16 ***\nORIGIN_SZBTSZ06      -1.0841201  0.0102242  -106.035  &lt; 2e-16 ***\nORIGIN_SZBTSZ07      -2.3134497  0.0158499  -145.960  &lt; 2e-16 ***\nORIGIN_SZBTSZ08      -1.1581618  0.0121161   -95.589  &lt; 2e-16 ***\nORIGIN_SZCBSZ01      -1.0805930  0.0577831   -18.701  &lt; 2e-16 ***\nORIGIN_SZCCSZ01      -0.8145372  0.0152638   -53.364  &lt; 2e-16 ***\nORIGIN_SZCHSZ01       0.0377079  0.0133240     2.830 0.004654 ** \nORIGIN_SZCHSZ02      -0.6209553  0.0096388   -64.422  &lt; 2e-16 ***\nORIGIN_SZCHSZ03       1.6790244  0.0069559   241.381  &lt; 2e-16 ***\nORIGIN_SZCKSZ01       0.0839586  0.0059934    14.008  &lt; 2e-16 ***\nORIGIN_SZCKSZ02       0.4379511  0.0062289    70.309  &lt; 2e-16 ***\nORIGIN_SZCKSZ03       0.7956950  0.0051892   153.335  &lt; 2e-16 ***\nORIGIN_SZCKSZ04       1.2740323  0.0053165   239.637  &lt; 2e-16 ***\nORIGIN_SZCKSZ05       0.9326213  0.0061807   150.893  &lt; 2e-16 ***\nORIGIN_SZCKSZ06       0.3976273  0.0085639    46.431  &lt; 2e-16 ***\nORIGIN_SZCLSZ01      -0.7522917  0.0094655   -79.477  &lt; 2e-16 ***\nORIGIN_SZCLSZ02      -1.3937450  0.0153260   -90.940  &lt; 2e-16 ***\nORIGIN_SZCLSZ03      -0.7898683  0.0091016   -86.784  &lt; 2e-16 ***\nORIGIN_SZCLSZ04       0.8451512  0.0051258   164.882  &lt; 2e-16 ***\nORIGIN_SZCLSZ05      -1.6573818  0.0166091   -99.788  &lt; 2e-16 ***\nORIGIN_SZCLSZ06       0.9478181  0.0048182   196.716  &lt; 2e-16 ***\nORIGIN_SZCLSZ07      -0.2499753  0.0064632   -38.677  &lt; 2e-16 ***\nORIGIN_SZCLSZ08       0.1350119  0.0069296    19.483  &lt; 2e-16 ***\nORIGIN_SZCLSZ09      -1.3868782  0.0192743   -71.955  &lt; 2e-16 ***\nORIGIN_SZDTSZ02      -3.7535792  0.0871325   -43.079  &lt; 2e-16 ***\nORIGIN_SZDTSZ03      -3.8462041  0.0840156   -45.780  &lt; 2e-16 ***\nORIGIN_SZDTSZ13      -2.9738127  0.0349241   -85.151  &lt; 2e-16 ***\nORIGIN_SZGLSZ01      -1.5175198  0.0110135  -137.787  &lt; 2e-16 ***\nORIGIN_SZGLSZ02       0.2405712  0.0058742    40.954  &lt; 2e-16 ***\nORIGIN_SZGLSZ03       0.1940241  0.0061989    31.300  &lt; 2e-16 ***\nORIGIN_SZGLSZ04       1.0292572  0.0049028   209.931  &lt; 2e-16 ***\nORIGIN_SZGLSZ05       0.9864552  0.0050898   193.811  &lt; 2e-16 ***\nORIGIN_SZHGSZ01       0.3073609  0.0054307    56.597  &lt; 2e-16 ***\nORIGIN_SZHGSZ02       0.3827293  0.0054555    70.154  &lt; 2e-16 ***\nORIGIN_SZHGSZ03       0.2342580  0.0059240    39.544  &lt; 2e-16 ***\nORIGIN_SZHGSZ04       0.8750090  0.0049639   176.275  &lt; 2e-16 ***\nORIGIN_SZHGSZ05       1.1695280  0.0049468   236.420  &lt; 2e-16 ***\nORIGIN_SZHGSZ06      -0.0462411  0.0063805    -7.247 4.25e-13 ***\nORIGIN_SZHGSZ07       0.4488583  0.0055139    81.404  &lt; 2e-16 ***\nORIGIN_SZHGSZ08       0.2236095  0.0061279    36.490  &lt; 2e-16 ***\nORIGIN_SZHGSZ09      -1.6376674  0.0084442  -193.941  &lt; 2e-16 ***\nORIGIN_SZHGSZ10      -2.9849025  0.0501042   -59.574  &lt; 2e-16 ***\nORIGIN_SZJESZ01       0.3926525  0.0056268    69.783  &lt; 2e-16 ***\nORIGIN_SZJESZ02       0.1230160  0.0056864    21.633  &lt; 2e-16 ***\nORIGIN_SZJESZ03       0.0188276  0.0061020     3.085 0.002032 ** \nORIGIN_SZJESZ04      -1.3611618  0.0117184  -116.156  &lt; 2e-16 ***\nORIGIN_SZJESZ05      -2.0643662  0.0157083  -131.419  &lt; 2e-16 ***\nORIGIN_SZJESZ06       0.1556368  0.0055245    28.172  &lt; 2e-16 ***\nORIGIN_SZJESZ07      -1.7664532  0.0133171  -132.646  &lt; 2e-16 ***\nORIGIN_SZJESZ08      -0.9115981  0.0138203   -65.961  &lt; 2e-16 ***\nORIGIN_SZJESZ09       0.6121916  0.0060381   101.388  &lt; 2e-16 ***\nORIGIN_SZJESZ10      -1.1953045  0.0233216   -51.253  &lt; 2e-16 ***\nORIGIN_SZJESZ11      -1.4088748  0.0220921   -63.773  &lt; 2e-16 ***\nORIGIN_SZJWSZ01       0.5759093  0.0077741    74.081  &lt; 2e-16 ***\nORIGIN_SZJWSZ02       0.9769314  0.0053029   184.227  &lt; 2e-16 ***\nORIGIN_SZJWSZ03       1.3242695  0.0049068   269.882  &lt; 2e-16 ***\nORIGIN_SZJWSZ04       0.5621088  0.0057831    97.199  &lt; 2e-16 ***\nORIGIN_SZJWSZ05      -1.5744341  0.0146904  -107.174  &lt; 2e-16 ***\nORIGIN_SZJWSZ06      -0.9113320  0.0126913   -71.807  &lt; 2e-16 ***\nORIGIN_SZJWSZ07      -2.3083419  0.0357843   -64.507  &lt; 2e-16 ***\nORIGIN_SZJWSZ08       2.0114225  0.0047956   419.429  &lt; 2e-16 ***\nORIGIN_SZJWSZ09       1.9086705  0.0045255   421.759  &lt; 2e-16 ***\nORIGIN_SZKLSZ01       0.2743166  0.0056908    48.204  &lt; 2e-16 ***\nORIGIN_SZKLSZ02      -0.6443386  0.0074521   -86.463  &lt; 2e-16 ***\nORIGIN_SZKLSZ03      -0.3990113  0.0067213   -59.366  &lt; 2e-16 ***\nORIGIN_SZKLSZ04      -2.1413876  0.0138405  -154.719  &lt; 2e-16 ***\nORIGIN_SZKLSZ05      -1.0913697  0.0121512   -89.816  &lt; 2e-16 ***\nORIGIN_SZKLSZ06      -5.6240764  0.1857405   -30.279  &lt; 2e-16 ***\nORIGIN_SZKLSZ07      -1.1885897  0.0096830  -122.750  &lt; 2e-16 ***\nORIGIN_SZKLSZ08      -1.7018593  0.0114317  -148.872  &lt; 2e-16 ***\nORIGIN_SZLKSZ01      -1.6659670  0.0446420   -37.318  &lt; 2e-16 ***\nORIGIN_SZMDSZ01      -1.1210505  0.0318834   -35.161  &lt; 2e-16 ***\nORIGIN_SZMDSZ02      -0.5096299  0.0116645   -43.691  &lt; 2e-16 ***\nORIGIN_SZMDSZ03      -1.9187039  0.0198291   -96.762  &lt; 2e-16 ***\nORIGIN_SZMPSZ01      -0.5260512  0.0094201   -55.844  &lt; 2e-16 ***\nORIGIN_SZMPSZ02      -0.2905084  0.0077974   -37.257  &lt; 2e-16 ***\nORIGIN_SZMPSZ03       0.3342293  0.0063715    52.457  &lt; 2e-16 ***\nORIGIN_SZMUSZ02      -3.8337096  0.1105053   -34.693  &lt; 2e-16 ***\nORIGIN_SZNTSZ01      -2.9845040  0.0397028   -75.171  &lt; 2e-16 ***\nORIGIN_SZNTSZ02      -3.1812985  0.0249470  -127.522  &lt; 2e-16 ***\nORIGIN_SZNTSZ03      -0.9742991  0.0085424  -114.054  &lt; 2e-16 ***\nORIGIN_SZNTSZ05      -4.2086932  0.0579737   -72.597  &lt; 2e-16 ***\nORIGIN_SZNTSZ06      -4.5831822  0.0583494   -78.547  &lt; 2e-16 ***\nORIGIN_SZNVSZ01       0.3186962  0.0052944    60.195  &lt; 2e-16 ***\nORIGIN_SZNVSZ02      -0.5321136  0.0073747   -72.154  &lt; 2e-16 ***\nORIGIN_SZNVSZ03      -0.9911852  0.0090560  -109.451  &lt; 2e-16 ***\nORIGIN_SZNVSZ04      -0.8329721  0.0099590   -83.640  &lt; 2e-16 ***\nORIGIN_SZNVSZ05      -2.1460777  0.0182401  -117.657  &lt; 2e-16 ***\nORIGIN_SZPGSZ01      -0.5604078  0.0151515   -36.987  &lt; 2e-16 ***\nORIGIN_SZPGSZ02      -0.4025139  0.0085135   -47.279  &lt; 2e-16 ***\nORIGIN_SZPGSZ03       0.6975483  0.0055534   125.608  &lt; 2e-16 ***\nORIGIN_SZPGSZ04       1.2175486  0.0051080   238.363  &lt; 2e-16 ***\nORIGIN_SZPGSZ05       0.3895354  0.0069851    55.767  &lt; 2e-16 ***\nORIGIN_SZPLSZ01      -0.5572701  0.0134473   -41.441  &lt; 2e-16 ***\nORIGIN_SZPLSZ02      -0.9854214  0.0172337   -57.180  &lt; 2e-16 ***\nORIGIN_SZPLSZ03      -1.6991954  0.0472629   -35.952  &lt; 2e-16 ***\nORIGIN_SZPLSZ04      -2.2000217  0.0373580   -58.890  &lt; 2e-16 ***\nORIGIN_SZPLSZ05      -1.7086663  0.0260920   -65.486  &lt; 2e-16 ***\nORIGIN_SZPNSZ01       1.5292867  0.0055102   277.535  &lt; 2e-16 ***\nORIGIN_SZPNSZ02       0.7457519  0.0127815    58.346  &lt; 2e-16 ***\nORIGIN_SZPNSZ03      -1.3659046  0.0216180   -63.184  &lt; 2e-16 ***\nORIGIN_SZPNSZ04      -2.0025379  0.0360655   -55.525  &lt; 2e-16 ***\nORIGIN_SZPNSZ05      -0.9157959  0.0320955   -28.533  &lt; 2e-16 ***\nORIGIN_SZPRSZ01       0.0522611  0.0139142     3.756 0.000173 ***\nORIGIN_SZPRSZ02       1.3063371  0.0053809   242.774  &lt; 2e-16 ***\nORIGIN_SZPRSZ03       0.9963670  0.0054293   183.516  &lt; 2e-16 ***\nORIGIN_SZPRSZ04      -0.0300950  0.0088010    -3.419 0.000627 ***\nORIGIN_SZPRSZ05       1.6840313  0.0050839   331.245  &lt; 2e-16 ***\nORIGIN_SZPRSZ06      -0.8277202  0.0131296   -63.042  &lt; 2e-16 ***\nORIGIN_SZPRSZ07      -2.1698449  0.0177362  -122.340  &lt; 2e-16 ***\nORIGIN_SZPRSZ08       0.4559353  0.0072609    62.793  &lt; 2e-16 ***\nORIGIN_SZQTSZ01      -0.3517047  0.0078770   -44.650  &lt; 2e-16 ***\nORIGIN_SZQTSZ02      -0.8199353  0.0071544  -114.605  &lt; 2e-16 ***\nORIGIN_SZQTSZ03      -0.2457614  0.0065555   -37.490  &lt; 2e-16 ***\nORIGIN_SZQTSZ04      -1.2216614  0.0084050  -145.349  &lt; 2e-16 ***\nORIGIN_SZQTSZ05      -0.7219952  0.0072360   -99.778  &lt; 2e-16 ***\nORIGIN_SZQTSZ06      -0.6729363  0.0076658   -87.784  &lt; 2e-16 ***\nORIGIN_SZQTSZ07      -1.4497690  0.0109365  -132.563  &lt; 2e-16 ***\nORIGIN_SZQTSZ08      -0.2770151  0.0070193   -39.465  &lt; 2e-16 ***\nORIGIN_SZQTSZ09      -0.6157554  0.0078739   -78.202  &lt; 2e-16 ***\nORIGIN_SZQTSZ10      -0.3091547  0.0075471   -40.963  &lt; 2e-16 ***\nORIGIN_SZQTSZ11      -1.9698881  0.0151247  -130.243  &lt; 2e-16 ***\nORIGIN_SZQTSZ12      -2.6449643  0.0205857  -128.485  &lt; 2e-16 ***\nORIGIN_SZQTSZ13      -0.3754107  0.0088433   -42.452  &lt; 2e-16 ***\nORIGIN_SZQTSZ14      -1.6537473  0.0134378  -123.067  &lt; 2e-16 ***\nORIGIN_SZQTSZ15      -0.3435351  0.0131956   -26.034  &lt; 2e-16 ***\nORIGIN_SZRCSZ01      -1.7104390  0.0141179  -121.154  &lt; 2e-16 ***\nORIGIN_SZRCSZ06      -1.1250727  0.0094909  -118.542  &lt; 2e-16 ***\nORIGIN_SZRVSZ01      -3.0220116  0.0339694   -88.963  &lt; 2e-16 ***\nORIGIN_SZRVSZ02      -3.6040075  0.0297641  -121.086  &lt; 2e-16 ***\nORIGIN_SZRVSZ03      -3.2345594  0.0259149  -124.814  &lt; 2e-16 ***\nORIGIN_SZRVSZ04      -3.6900313  0.0575908   -64.073  &lt; 2e-16 ***\nORIGIN_SZRVSZ05      -2.9527570  0.0178582  -165.344  &lt; 2e-16 ***\nORIGIN_SZSBSZ01       0.0238445  0.0078563     3.035 0.002405 ** \nORIGIN_SZSBSZ02      -0.5780602  0.0093054   -62.121  &lt; 2e-16 ***\nORIGIN_SZSBSZ03       0.8961719  0.0054586   164.175  &lt; 2e-16 ***\nORIGIN_SZSBSZ04       0.8421798  0.0061888   136.080  &lt; 2e-16 ***\nORIGIN_SZSBSZ05      -0.1682984  0.0078342   -21.482  &lt; 2e-16 ***\nORIGIN_SZSBSZ06      -1.1482701  0.0196421   -58.460  &lt; 2e-16 ***\nORIGIN_SZSBSZ07      -0.8830317  0.0160709   -54.946  &lt; 2e-16 ***\nORIGIN_SZSBSZ08      -1.1039492  0.0174602   -63.226  &lt; 2e-16 ***\nORIGIN_SZSBSZ09      -0.5946691  0.0101961   -58.323  &lt; 2e-16 ***\nORIGIN_SZSESZ02       1.1144933  0.0050948   218.749  &lt; 2e-16 ***\nORIGIN_SZSESZ03       1.1058963  0.0049026   225.574  &lt; 2e-16 ***\nORIGIN_SZSESZ04       0.7427975  0.0056948   130.433  &lt; 2e-16 ***\nORIGIN_SZSESZ05      -0.2812684  0.0069596   -40.414  &lt; 2e-16 ***\nORIGIN_SZSESZ06       0.8168315  0.0055800   146.387  &lt; 2e-16 ***\nORIGIN_SZSESZ07      -2.2842043  0.0231232   -98.784  &lt; 2e-16 ***\nORIGIN_SZSGSZ01      -0.7313790  0.0098957   -73.909  &lt; 2e-16 ***\nORIGIN_SZSGSZ02      -1.1185406  0.0110919  -100.843  &lt; 2e-16 ***\nORIGIN_SZSGSZ03       0.1752618  0.0060508    28.965  &lt; 2e-16 ***\nORIGIN_SZSGSZ04       0.3764395  0.0056165    67.023  &lt; 2e-16 ***\nORIGIN_SZSGSZ05      -1.7203916  0.0118945  -144.637  &lt; 2e-16 ***\nORIGIN_SZSGSZ06       0.4630857  0.0052886    87.563  &lt; 2e-16 ***\nORIGIN_SZSGSZ07      -0.7051233  0.0073133   -96.417  &lt; 2e-16 ***\nORIGIN_SZSKSZ01       0.2053928  0.0100710    20.395  &lt; 2e-16 ***\nORIGIN_SZSKSZ02       1.2630428  0.0063490   198.935  &lt; 2e-16 ***\nORIGIN_SZSKSZ03      -0.3035297  0.0096788   -31.360  &lt; 2e-16 ***\nORIGIN_SZSKSZ04      -1.7952886  0.0359225   -49.977  &lt; 2e-16 ***\nORIGIN_SZSKSZ05      -0.3836861  0.0176686   -21.716  &lt; 2e-16 ***\nORIGIN_SZSLSZ01      -2.5916326  0.0348001   -74.472  &lt; 2e-16 ***\nORIGIN_SZSLSZ04      -0.2251549  0.0088517   -25.436  &lt; 2e-16 ***\nORIGIN_SZSRSZ01      -2.9590365  0.0173638  -170.414  &lt; 2e-16 ***\nORIGIN_SZTHSZ01      -1.9639893  0.0570321   -34.437  &lt; 2e-16 ***\nORIGIN_SZTHSZ03      -1.7281304  0.0272797   -63.349  &lt; 2e-16 ***\nORIGIN_SZTHSZ04      -2.7837906  0.0343179   -81.118  &lt; 2e-16 ***\nORIGIN_SZTHSZ06      -2.1800693  0.0205491  -106.091  &lt; 2e-16 ***\nORIGIN_SZTMSZ01       0.8228136  0.0066824   123.131  &lt; 2e-16 ***\nORIGIN_SZTMSZ02       2.3174781  0.0044978   515.243  &lt; 2e-16 ***\nORIGIN_SZTMSZ03       1.7061757  0.0048615   350.957  &lt; 2e-16 ***\nORIGIN_SZTMSZ04       1.2407899  0.0058389   212.504  &lt; 2e-16 ***\nORIGIN_SZTMSZ05      -0.1000526  0.0124079    -8.064 7.41e-16 ***\nORIGIN_SZTNSZ01      -2.0347519  0.0139596  -145.760  &lt; 2e-16 ***\nORIGIN_SZTNSZ02      -1.8682671  0.0107901  -173.146  &lt; 2e-16 ***\nORIGIN_SZTNSZ03      -2.1737183  0.0146759  -148.115  &lt; 2e-16 ***\nORIGIN_SZTNSZ04      -0.5006452  0.0081501   -61.428  &lt; 2e-16 ***\nORIGIN_SZTPSZ01      -0.6722487  0.0075606   -88.914  &lt; 2e-16 ***\nORIGIN_SZTPSZ02       0.4552916  0.0050191    90.711  &lt; 2e-16 ***\nORIGIN_SZTPSZ03      -0.7865781  0.0072250  -108.869  &lt; 2e-16 ***\nORIGIN_SZTPSZ04      -0.7049044  0.0066456  -106.071  &lt; 2e-16 ***\nORIGIN_SZTPSZ05      -0.5574925  0.0070366   -79.227  &lt; 2e-16 ***\nORIGIN_SZTPSZ06      -0.4247282  0.0068709   -61.815  &lt; 2e-16 ***\nORIGIN_SZTPSZ07      -0.2846984  0.0071030   -40.081  &lt; 2e-16 ***\nORIGIN_SZTPSZ08      -1.0898051  0.0110046   -99.031  &lt; 2e-16 ***\nORIGIN_SZTPSZ09      -0.8092746  0.0079160  -102.232  &lt; 2e-16 ***\nORIGIN_SZTPSZ10      -0.9332072  0.0086809  -107.502  &lt; 2e-16 ***\nORIGIN_SZTPSZ11      -0.0421981  0.0064343    -6.558 5.44e-11 ***\nORIGIN_SZTPSZ12      -0.6330081  0.0078324   -80.819  &lt; 2e-16 ***\nORIGIN_SZTSSZ01      -1.7650409  0.0517357   -34.116  &lt; 2e-16 ***\nORIGIN_SZTSSZ02       1.1707267  0.0094178   124.310  &lt; 2e-16 ***\nORIGIN_SZTSSZ03       0.6581679  0.0095894    68.635  &lt; 2e-16 ***\nORIGIN_SZTSSZ04       0.8736493  0.0104965    83.233  &lt; 2e-16 ***\nORIGIN_SZTSSZ05       0.0957248  0.0178709     5.356 8.49e-08 ***\nORIGIN_SZTSSZ06       1.7581609  0.0206810    85.013  &lt; 2e-16 ***\nORIGIN_SZWCSZ01       0.8097950  0.0105622    76.669  &lt; 2e-16 ***\nORIGIN_SZWCSZ02      -1.9966163  0.0345747   -57.748  &lt; 2e-16 ***\nORIGIN_SZWCSZ03      -5.0687420  0.1474971   -34.365  &lt; 2e-16 ***\nORIGIN_SZWDSZ01       1.4926003  0.0047216   316.124  &lt; 2e-16 ***\nORIGIN_SZWDSZ02       0.9916597  0.0055755   177.859  &lt; 2e-16 ***\nORIGIN_SZWDSZ03       1.5918065  0.0052180   305.062  &lt; 2e-16 ***\nORIGIN_SZWDSZ04       1.3717152  0.0060516   226.669  &lt; 2e-16 ***\nORIGIN_SZWDSZ05       0.6700111  0.0062287   107.569  &lt; 2e-16 ***\nORIGIN_SZWDSZ06       0.8115996  0.0060947   133.165  &lt; 2e-16 ***\nORIGIN_SZWDSZ07      -0.6488914  0.0093567   -69.351  &lt; 2e-16 ***\nORIGIN_SZWDSZ08      -0.3610234  0.0096440   -37.435  &lt; 2e-16 ***\nORIGIN_SZWDSZ09       1.4445461  0.0052279   276.317  &lt; 2e-16 ***\nORIGIN_SZYSSZ01      -0.2039272  0.0069548   -29.322  &lt; 2e-16 ***\nORIGIN_SZYSSZ02       0.8707707  0.0058957   147.697  &lt; 2e-16 ***\nORIGIN_SZYSSZ03       1.8348842  0.0050377   364.231  &lt; 2e-16 ***\nORIGIN_SZYSSZ04       1.0780641  0.0052960   203.564  &lt; 2e-16 ***\nORIGIN_SZYSSZ05       0.3222765  0.0069700    46.237  &lt; 2e-16 ***\nORIGIN_SZYSSZ06      -0.4424689  0.0124866   -35.435  &lt; 2e-16 ***\nORIGIN_SZYSSZ07      -1.0267883  0.0155821   -65.895  &lt; 2e-16 ***\nORIGIN_SZYSSZ08       0.1833117  0.0070935    25.842  &lt; 2e-16 ***\nORIGIN_SZYSSZ09       1.0766070  0.0050451   213.396  &lt; 2e-16 ***\nlog(DESTIN_AGE25_64)  0.0295428  0.0001051   280.998  &lt; 2e-16 ***\nlog(dist)            -1.7024691  0.0004625 -3681.042  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 36117615  on 14273  degrees of freedom\nResidual deviance: 12983718  on 13993  degrees of freedom\nAIC: 13068835\n\nNumber of Fisher Scoring iterations: 6\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)\n\n[1] 0.4029115\n\n\n\n\nDestination constrained\nIn this section, we will fit a destination constrained SIM by using the code chunk below.\nThe general formula of Destination Constrained Spatial Interaction Model\n\n\ndecSIM &lt;- glm(formula = TRIPS ~ \n                DESTIN_SZ + \n                log(ORIGIN_AGE25_64) + \n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(decSIM)\n\n\nCall:\nglm(formula = TRIPS ~ DESTIN_SZ + log(ORIGIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          19.4822997  0.0050784  3836.298  &lt; 2e-16 ***\nDESTIN_SZAMSZ02       0.1263056  0.0049743    25.392  &lt; 2e-16 ***\nDESTIN_SZAMSZ03       0.0421788  0.0049859     8.460  &lt; 2e-16 ***\nDESTIN_SZAMSZ04      -1.1668479  0.0074254  -157.143  &lt; 2e-16 ***\nDESTIN_SZAMSZ05      -1.2586639  0.0075854  -165.931  &lt; 2e-16 ***\nDESTIN_SZAMSZ06      -1.1414791  0.0073474  -155.359  &lt; 2e-16 ***\nDESTIN_SZAMSZ07      -1.5565804  0.0109476  -142.185  &lt; 2e-16 ***\nDESTIN_SZAMSZ08      -0.3990754  0.0074159   -53.813  &lt; 2e-16 ***\nDESTIN_SZAMSZ09      -1.0109118  0.0076802  -131.626  &lt; 2e-16 ***\nDESTIN_SZAMSZ10       0.0159285  0.0051765     3.077  0.00209 ** \nDESTIN_SZAMSZ11      -0.3653273  0.0094866   -38.510  &lt; 2e-16 ***\nDESTIN_SZAMSZ12       0.5297606  0.0053243    99.500  &lt; 2e-16 ***\nDESTIN_SZBDSZ01       1.0394822  0.0044226   235.037  &lt; 2e-16 ***\nDESTIN_SZBDSZ02       0.1956964  0.0059564    32.855  &lt; 2e-16 ***\nDESTIN_SZBDSZ03       0.3209267  0.0053718    59.742  &lt; 2e-16 ***\nDESTIN_SZBDSZ04       1.2429874  0.0043104   288.370  &lt; 2e-16 ***\nDESTIN_SZBDSZ05       0.8535842  0.0046360   184.122  &lt; 2e-16 ***\nDESTIN_SZBDSZ06       0.5181443  0.0053736    96.423  &lt; 2e-16 ***\nDESTIN_SZBDSZ07      -0.5849371  0.0110468   -52.951  &lt; 2e-16 ***\nDESTIN_SZBDSZ08      -1.2871050  0.0128623  -100.068  &lt; 2e-16 ***\nDESTIN_SZBKSZ01      -1.0633560  0.0077771  -136.730  &lt; 2e-16 ***\nDESTIN_SZBKSZ02      -0.4065316  0.0066712   -60.938  &lt; 2e-16 ***\nDESTIN_SZBKSZ03      -0.6815674  0.0066509  -102.477  &lt; 2e-16 ***\nDESTIN_SZBKSZ04      -0.4185485  0.0058306   -71.785  &lt; 2e-16 ***\nDESTIN_SZBKSZ05      -0.8887654  0.0073867  -120.319  &lt; 2e-16 ***\nDESTIN_SZBKSZ06      -0.9436078  0.0068625  -137.501  &lt; 2e-16 ***\nDESTIN_SZBKSZ07      -0.0067325  0.0048408    -1.391  0.16430    \nDESTIN_SZBKSZ08      -1.2680903  0.0079177  -160.160  &lt; 2e-16 ***\nDESTIN_SZBKSZ09      -0.0350151  0.0054287    -6.450 1.12e-10 ***\nDESTIN_SZBLSZ01      -0.3045203  0.0081978   -37.146  &lt; 2e-16 ***\nDESTIN_SZBLSZ02       0.6432424  0.0074449    86.400  &lt; 2e-16 ***\nDESTIN_SZBLSZ03       1.9595113  0.0084705   231.333  &lt; 2e-16 ***\nDESTIN_SZBLSZ04       0.0149756  0.0172081     0.870  0.38415    \nDESTIN_SZBMSZ01      -0.0378127  0.0055294    -6.838 8.00e-12 ***\nDESTIN_SZBMSZ02      -0.8458055  0.0054043  -156.505  &lt; 2e-16 ***\nDESTIN_SZBMSZ03      -1.1334399  0.0063720  -177.878  &lt; 2e-16 ***\nDESTIN_SZBMSZ04      -1.1164759  0.0057743  -193.353  &lt; 2e-16 ***\nDESTIN_SZBMSZ05      -1.1078742  0.0078703  -140.766  &lt; 2e-16 ***\nDESTIN_SZBMSZ06      -2.2787234  0.0155126  -146.895  &lt; 2e-16 ***\nDESTIN_SZBMSZ07      -0.2739089  0.0051924   -52.752  &lt; 2e-16 ***\nDESTIN_SZBMSZ08      -1.6825978  0.0071842  -234.209  &lt; 2e-16 ***\nDESTIN_SZBMSZ09      -3.0047801  0.0159980  -187.823  &lt; 2e-16 ***\nDESTIN_SZBMSZ10      -2.2232689  0.0096907  -229.423  &lt; 2e-16 ***\nDESTIN_SZBMSZ11      -1.9657136  0.0086445  -227.394  &lt; 2e-16 ***\nDESTIN_SZBMSZ12      -1.5359286  0.0089658  -171.310  &lt; 2e-16 ***\nDESTIN_SZBMSZ13      -0.5657561  0.0059960   -94.355  &lt; 2e-16 ***\nDESTIN_SZBMSZ14      -1.6904858  0.0084858  -199.214  &lt; 2e-16 ***\nDESTIN_SZBMSZ15      -1.5268383  0.0079959  -190.953  &lt; 2e-16 ***\nDESTIN_SZBMSZ16      -2.2045600  0.0130872  -168.452  &lt; 2e-16 ***\nDESTIN_SZBMSZ17      -2.2992381  0.0184895  -124.353  &lt; 2e-16 ***\nDESTIN_SZBPSZ01      -0.8549497  0.0065168  -131.191  &lt; 2e-16 ***\nDESTIN_SZBPSZ02      -1.7470549  0.0095751  -182.457  &lt; 2e-16 ***\nDESTIN_SZBPSZ03      -1.4015145  0.0090888  -154.203  &lt; 2e-16 ***\nDESTIN_SZBPSZ04      -0.5250632  0.0066496   -78.962  &lt; 2e-16 ***\nDESTIN_SZBPSZ05       0.3413171  0.0046404    73.553  &lt; 2e-16 ***\nDESTIN_SZBPSZ06      -0.8569188  0.0090795   -94.380  &lt; 2e-16 ***\nDESTIN_SZBPSZ07      -0.0751284  0.0089704    -8.375  &lt; 2e-16 ***\nDESTIN_SZBSSZ01       0.1015228  0.0055735    18.215  &lt; 2e-16 ***\nDESTIN_SZBSSZ02      -0.7066412  0.0063845  -110.682  &lt; 2e-16 ***\nDESTIN_SZBSSZ03       0.1622730  0.0046689    34.756  &lt; 2e-16 ***\nDESTIN_SZBTSZ01       0.5470615  0.0047984   114.009  &lt; 2e-16 ***\nDESTIN_SZBTSZ02      -0.1393371  0.0078266   -17.803  &lt; 2e-16 ***\nDESTIN_SZBTSZ03       0.1474771  0.0059428    24.816  &lt; 2e-16 ***\nDESTIN_SZBTSZ04      -1.2857827  0.0122000  -105.392  &lt; 2e-16 ***\nDESTIN_SZBTSZ05      -0.2629188  0.0081769   -32.154  &lt; 2e-16 ***\nDESTIN_SZBTSZ06      -0.8319920  0.0081401  -102.209  &lt; 2e-16 ***\nDESTIN_SZBTSZ07      -1.8829448  0.0121227  -155.324  &lt; 2e-16 ***\nDESTIN_SZBTSZ08      -1.5732123  0.0116752  -134.748  &lt; 2e-16 ***\nDESTIN_SZCBSZ01      -3.5334327  0.3333510   -10.600  &lt; 2e-16 ***\nDESTIN_SZCCSZ01      -0.2129306  0.0093782   -22.705  &lt; 2e-16 ***\nDESTIN_SZCHSZ01      -0.1494972  0.0113078   -13.221  &lt; 2e-16 ***\nDESTIN_SZCHSZ02       0.0041774  0.0063195     0.661  0.50860    \nDESTIN_SZCHSZ03       2.5565450  0.0046495   549.857  &lt; 2e-16 ***\nDESTIN_SZCKSZ01       0.0489719  0.0053801     9.102  &lt; 2e-16 ***\nDESTIN_SZCKSZ02      -0.3548993  0.0060671   -58.496  &lt; 2e-16 ***\nDESTIN_SZCKSZ03       0.5386351  0.0044913   119.928  &lt; 2e-16 ***\nDESTIN_SZCKSZ04      -0.4425512  0.0073837   -59.936  &lt; 2e-16 ***\nDESTIN_SZCKSZ05      -0.4092591  0.0077267   -52.967  &lt; 2e-16 ***\nDESTIN_SZCKSZ06       0.2207041  0.0074252    29.724  &lt; 2e-16 ***\nDESTIN_SZCLSZ01       0.2851460  0.0052362    54.457  &lt; 2e-16 ***\nDESTIN_SZCLSZ02      -1.9270528  0.0147688  -130.482  &lt; 2e-16 ***\nDESTIN_SZCLSZ03      -0.6266521  0.0086780   -72.212  &lt; 2e-16 ***\nDESTIN_SZCLSZ04      -0.1335581  0.0054216   -24.634  &lt; 2e-16 ***\nDESTIN_SZCLSZ05      -0.8912963  0.0096015   -92.829  &lt; 2e-16 ***\nDESTIN_SZCLSZ06       0.1781234  0.0048150    36.993  &lt; 2e-16 ***\nDESTIN_SZCLSZ07      -0.5609619  0.0062277   -90.075  &lt; 2e-16 ***\nDESTIN_SZCLSZ08      -0.3875308  0.0068390   -56.665  &lt; 2e-16 ***\nDESTIN_SZCLSZ09       0.2539453  0.0072623    34.968  &lt; 2e-16 ***\nDESTIN_SZDTSZ02      -2.5036295  0.0373421   -67.046  &lt; 2e-16 ***\nDESTIN_SZDTSZ03      -0.8956407  0.0149971   -59.721  &lt; 2e-16 ***\nDESTIN_SZDTSZ13      -1.6562176  0.0175441   -94.403  &lt; 2e-16 ***\nDESTIN_SZGLSZ01      -0.2716152  0.0056553   -48.029  &lt; 2e-16 ***\nDESTIN_SZGLSZ02      -0.1735665  0.0055548   -31.246  &lt; 2e-16 ***\nDESTIN_SZGLSZ03       0.7029507  0.0044934   156.441  &lt; 2e-16 ***\nDESTIN_SZGLSZ04       0.5788027  0.0045449   127.351  &lt; 2e-16 ***\nDESTIN_SZGLSZ05       0.6865291  0.0045131   152.118  &lt; 2e-16 ***\nDESTIN_SZHGSZ01       0.3275950  0.0043866    74.681  &lt; 2e-16 ***\nDESTIN_SZHGSZ02      -0.6326974  0.0063517   -99.610  &lt; 2e-16 ***\nDESTIN_SZHGSZ03      -1.0597982  0.0073914  -143.382  &lt; 2e-16 ***\nDESTIN_SZHGSZ04      -0.2267013  0.0052178   -43.448  &lt; 2e-16 ***\nDESTIN_SZHGSZ05      -0.3063050  0.0055452   -55.238  &lt; 2e-16 ***\nDESTIN_SZHGSZ06      -0.7483961  0.0065544  -114.182  &lt; 2e-16 ***\nDESTIN_SZHGSZ07       0.1096958  0.0051309    21.379  &lt; 2e-16 ***\nDESTIN_SZHGSZ08      -0.1374201  0.0056692   -24.240  &lt; 2e-16 ***\nDESTIN_SZHGSZ09       0.0775400  0.0060230    12.874  &lt; 2e-16 ***\nDESTIN_SZHGSZ10      -3.3017475  0.0289292  -114.132  &lt; 2e-16 ***\nDESTIN_SZJESZ01      -0.0489065  0.0057246    -8.543  &lt; 2e-16 ***\nDESTIN_SZJESZ02      -0.5101614  0.0060074   -84.921  &lt; 2e-16 ***\nDESTIN_SZJESZ03      -0.5328921  0.0064129   -83.097  &lt; 2e-16 ***\nDESTIN_SZJESZ04      -0.7348953  0.0082249   -89.351  &lt; 2e-16 ***\nDESTIN_SZJESZ05      -1.0864570  0.0111740   -97.231  &lt; 2e-16 ***\nDESTIN_SZJESZ06       0.2407920  0.0046801    51.451  &lt; 2e-16 ***\nDESTIN_SZJESZ07      -1.1523093  0.0090103  -127.888  &lt; 2e-16 ***\nDESTIN_SZJESZ08      -0.4627356  0.0094529   -48.952  &lt; 2e-16 ***\nDESTIN_SZJESZ09       0.0528616  0.0068126     7.759 8.53e-15 ***\nDESTIN_SZJESZ10       1.0240660  0.0084045   121.848  &lt; 2e-16 ***\nDESTIN_SZJESZ11       0.7875517  0.0076251   103.284  &lt; 2e-16 ***\nDESTIN_SZJWSZ01      -0.1533418  0.0076198   -20.124  &lt; 2e-16 ***\nDESTIN_SZJWSZ02      -0.0011019  0.0059389    -0.186  0.85280    \nDESTIN_SZJWSZ03       0.9063789  0.0046747   193.892  &lt; 2e-16 ***\nDESTIN_SZJWSZ04       0.7019286  0.0049743   141.112  &lt; 2e-16 ***\nDESTIN_SZJWSZ05      -0.5197057  0.0072971   -71.220  &lt; 2e-16 ***\nDESTIN_SZJWSZ06       0.3350986  0.0061171    54.780  &lt; 2e-16 ***\nDESTIN_SZJWSZ07      -0.5961960  0.0328336   -18.158  &lt; 2e-16 ***\nDESTIN_SZJWSZ08       0.8054662  0.0056006   143.819  &lt; 2e-16 ***\nDESTIN_SZJWSZ09       1.5860146  0.0040282   393.723  &lt; 2e-16 ***\nDESTIN_SZKLSZ01      -0.6500838  0.0063560  -102.279  &lt; 2e-16 ***\nDESTIN_SZKLSZ02      -0.7039434  0.0064465  -109.197  &lt; 2e-16 ***\nDESTIN_SZKLSZ03      -1.1972384  0.0075577  -158.413  &lt; 2e-16 ***\nDESTIN_SZKLSZ04      -1.7172228  0.0097573  -175.993  &lt; 2e-16 ***\nDESTIN_SZKLSZ05      -0.6042386  0.0093730   -64.466  &lt; 2e-16 ***\nDESTIN_SZKLSZ06      -3.0201496  0.0389503   -77.539  &lt; 2e-16 ***\nDESTIN_SZKLSZ07      -1.1522413  0.0076607  -150.409  &lt; 2e-16 ***\nDESTIN_SZKLSZ08      -0.6977825  0.0057610  -121.122  &lt; 2e-16 ***\nDESTIN_SZLKSZ01      -0.6895952  0.0268661   -25.668  &lt; 2e-16 ***\nDESTIN_SZMDSZ01      -0.7155951  0.0228203   -31.358  &lt; 2e-16 ***\nDESTIN_SZMDSZ02      -0.8153643  0.0123003   -66.288  &lt; 2e-16 ***\nDESTIN_SZMDSZ03      -2.7745226  0.0301326   -92.077  &lt; 2e-16 ***\nDESTIN_SZMPSZ01      -0.5492095  0.0087198   -62.984  &lt; 2e-16 ***\nDESTIN_SZMPSZ02      -0.6104744  0.0069346   -88.033  &lt; 2e-16 ***\nDESTIN_SZMPSZ03       0.2775047  0.0054964    50.489  &lt; 2e-16 ***\nDESTIN_SZMUSZ02      -2.6322870  0.0214943  -122.464  &lt; 2e-16 ***\nDESTIN_SZNTSZ01      -4.0762008  0.0531046   -76.758  &lt; 2e-16 ***\nDESTIN_SZNTSZ02      -1.9765545  0.0125659  -157.296  &lt; 2e-16 ***\nDESTIN_SZNTSZ03      -1.4563069  0.0085433  -170.462  &lt; 2e-16 ***\nDESTIN_SZNTSZ05      -2.0125598  0.0270737   -74.336  &lt; 2e-16 ***\nDESTIN_SZNTSZ06      -3.0145357  0.0504986   -59.695  &lt; 2e-16 ***\nDESTIN_SZNVSZ01      -0.4693625  0.0053866   -87.135  &lt; 2e-16 ***\nDESTIN_SZNVSZ02      -0.4525631  0.0060428   -74.894  &lt; 2e-16 ***\nDESTIN_SZNVSZ03      -0.4821492  0.0064725   -74.492  &lt; 2e-16 ***\nDESTIN_SZNVSZ04      -1.8929756  0.0128397  -147.432  &lt; 2e-16 ***\nDESTIN_SZNVSZ05      -1.4501752  0.0099737  -145.400  &lt; 2e-16 ***\nDESTIN_SZPGSZ01      -1.2305867  0.0174321   -70.593  &lt; 2e-16 ***\nDESTIN_SZPGSZ02      -0.8232919  0.0080153  -102.715  &lt; 2e-16 ***\nDESTIN_SZPGSZ03       0.2138480  0.0050850    42.054  &lt; 2e-16 ***\nDESTIN_SZPGSZ04       0.1045757  0.0053579    19.518  &lt; 2e-16 ***\nDESTIN_SZPGSZ05      -0.7542450  0.0088883   -84.858  &lt; 2e-16 ***\nDESTIN_SZPLSZ01      -0.0098642  0.0080428    -1.226  0.22003    \nDESTIN_SZPLSZ02      -1.2630412  0.0152594   -82.771  &lt; 2e-16 ***\nDESTIN_SZPLSZ03      -0.1554479  0.0108611   -14.312  &lt; 2e-16 ***\nDESTIN_SZPLSZ04      -1.5505819  0.0114768  -135.105  &lt; 2e-16 ***\nDESTIN_SZPLSZ05      -0.2417805  0.0130391   -18.543  &lt; 2e-16 ***\nDESTIN_SZPNSZ01       0.7926715  0.0073628   107.659  &lt; 2e-16 ***\nDESTIN_SZPNSZ02       2.1914920  0.0073537   298.013  &lt; 2e-16 ***\nDESTIN_SZPNSZ03       1.0246845  0.0086874   117.951  &lt; 2e-16 ***\nDESTIN_SZPNSZ04       2.5522612  0.0091789   278.057  &lt; 2e-16 ***\nDESTIN_SZPNSZ05       1.7995301  0.0138562   129.872  &lt; 2e-16 ***\nDESTIN_SZPRSZ01      -0.6576686  0.0096037   -68.481  &lt; 2e-16 ***\nDESTIN_SZPRSZ02       0.3113532  0.0059851    52.021  &lt; 2e-16 ***\nDESTIN_SZPRSZ03       0.9255296  0.0044779   206.687  &lt; 2e-16 ***\nDESTIN_SZPRSZ04      -0.0028578  0.0093218    -0.307  0.75917    \nDESTIN_SZPRSZ05       0.2457863  0.0058261    42.187  &lt; 2e-16 ***\nDESTIN_SZPRSZ06       0.3692137  0.0064542    57.205  &lt; 2e-16 ***\nDESTIN_SZPRSZ07      -1.6733306  0.0138440  -120.871  &lt; 2e-16 ***\nDESTIN_SZPRSZ08      -0.2221048  0.0074846   -29.675  &lt; 2e-16 ***\nDESTIN_SZQTSZ01      -1.0185488  0.0093179  -109.311  &lt; 2e-16 ***\nDESTIN_SZQTSZ02      -1.2802688  0.0081670  -156.761  &lt; 2e-16 ***\nDESTIN_SZQTSZ03      -1.3322708  0.0079106  -168.415  &lt; 2e-16 ***\nDESTIN_SZQTSZ04      -1.1803631  0.0077366  -152.568  &lt; 2e-16 ***\nDESTIN_SZQTSZ05      -1.2215818  0.0072829  -167.734  &lt; 2e-16 ***\nDESTIN_SZQTSZ06      -1.3213145  0.0074858  -176.509  &lt; 2e-16 ***\nDESTIN_SZQTSZ07      -1.6426306  0.0123347  -133.171  &lt; 2e-16 ***\nDESTIN_SZQTSZ08      -0.2224169  0.0058405   -38.082  &lt; 2e-16 ***\nDESTIN_SZQTSZ09      -0.8142678  0.0069796  -116.665  &lt; 2e-16 ***\nDESTIN_SZQTSZ10      -0.1090496  0.0062573   -17.428  &lt; 2e-16 ***\nDESTIN_SZQTSZ11      -0.0108951  0.0061145    -1.782  0.07477 .  \nDESTIN_SZQTSZ12      -0.8582515  0.0090243   -95.105  &lt; 2e-16 ***\nDESTIN_SZQTSZ13       0.1834409  0.0065231    28.122  &lt; 2e-16 ***\nDESTIN_SZQTSZ14       0.1994454  0.0073615    27.093  &lt; 2e-16 ***\nDESTIN_SZQTSZ15       0.6740197  0.0088699    75.990  &lt; 2e-16 ***\nDESTIN_SZRCSZ01      -0.7746427  0.0079375   -97.593  &lt; 2e-16 ***\nDESTIN_SZRCSZ06      -1.4394098  0.0209931   -68.566  &lt; 2e-16 ***\nDESTIN_SZRVSZ01      -2.6060495  0.0175759  -148.274  &lt; 2e-16 ***\nDESTIN_SZRVSZ02      -2.5823769  0.0354706   -72.803  &lt; 2e-16 ***\nDESTIN_SZRVSZ03      -2.5890601  0.0152644  -169.614  &lt; 2e-16 ***\nDESTIN_SZRVSZ04      -2.2277482  0.0165661  -134.477  &lt; 2e-16 ***\nDESTIN_SZRVSZ05      -3.8610445  0.0298251  -129.456  &lt; 2e-16 ***\nDESTIN_SZSBSZ01      -1.2035529  0.0103954  -115.777  &lt; 2e-16 ***\nDESTIN_SZSBSZ02      -1.0267199  0.0085239  -120.452  &lt; 2e-16 ***\nDESTIN_SZSBSZ03       0.5977382  0.0050336   118.750  &lt; 2e-16 ***\nDESTIN_SZSBSZ04       0.5362769  0.0060573    88.534  &lt; 2e-16 ***\nDESTIN_SZSBSZ05      -1.0440525  0.0089622  -116.495  &lt; 2e-16 ***\nDESTIN_SZSBSZ06      -1.3939595  0.0246679   -56.509  &lt; 2e-16 ***\nDESTIN_SZSBSZ07       0.1029116  0.0235414     4.372 1.23e-05 ***\nDESTIN_SZSBSZ08       1.3564902  0.0060529   224.105  &lt; 2e-16 ***\nDESTIN_SZSBSZ09       0.4573712  0.0056585    80.829  &lt; 2e-16 ***\nDESTIN_SZSESZ02      -0.1553609  0.0056716   -27.393  &lt; 2e-16 ***\nDESTIN_SZSESZ03       0.5412776  0.0043801   123.576  &lt; 2e-16 ***\nDESTIN_SZSESZ04      -0.6382091  0.0065411   -97.568  &lt; 2e-16 ***\nDESTIN_SZSESZ05      -0.3332093  0.0055002   -60.581  &lt; 2e-16 ***\nDESTIN_SZSESZ06      -0.3085951  0.0072340   -42.659  &lt; 2e-16 ***\nDESTIN_SZSESZ07      -2.6237684  0.0245753  -106.764  &lt; 2e-16 ***\nDESTIN_SZSGSZ01      -0.1062372  0.0066634   -15.943  &lt; 2e-16 ***\nDESTIN_SZSGSZ02      -0.0475568  0.0058908    -8.073 6.85e-16 ***\nDESTIN_SZSGSZ03      -0.2118402  0.0055056   -38.477  &lt; 2e-16 ***\nDESTIN_SZSGSZ04      -0.1099618  0.0054841   -20.051  &lt; 2e-16 ***\nDESTIN_SZSGSZ05      -2.1556963  0.0113821  -189.394  &lt; 2e-16 ***\nDESTIN_SZSGSZ06       0.4416352  0.0043842   100.734  &lt; 2e-16 ***\nDESTIN_SZSGSZ07      -0.3949335  0.0059250   -66.655  &lt; 2e-16 ***\nDESTIN_SZSISZ01      -1.2847094  0.0288610   -44.514  &lt; 2e-16 ***\nDESTIN_SZSKSZ01       0.3089834  0.0082924    37.261  &lt; 2e-16 ***\nDESTIN_SZSKSZ02       1.4139309  0.0059981   235.729  &lt; 2e-16 ***\nDESTIN_SZSKSZ03       0.2427688  0.0067373    36.034  &lt; 2e-16 ***\nDESTIN_SZSKSZ04      -0.2527488  0.0161286   -15.671  &lt; 2e-16 ***\nDESTIN_SZSKSZ05       0.6046051  0.0122766    49.249  &lt; 2e-16 ***\nDESTIN_SZSLSZ01      -0.3927387  0.0099790   -39.356  &lt; 2e-16 ***\nDESTIN_SZSLSZ04      -0.5942110  0.0086225   -68.914  &lt; 2e-16 ***\nDESTIN_SZSRSZ01      -2.6855766  0.0138707  -193.615  &lt; 2e-16 ***\nDESTIN_SZTHSZ01      -3.2750084  0.0402668   -81.333  &lt; 2e-16 ***\nDESTIN_SZTHSZ03      -1.7964408  0.0261810   -68.616  &lt; 2e-16 ***\nDESTIN_SZTHSZ04      -2.6323994  0.0241831  -108.853  &lt; 2e-16 ***\nDESTIN_SZTHSZ06      -1.9444390  0.0166052  -117.098  &lt; 2e-16 ***\nDESTIN_SZTMSZ01       0.3856054  0.0063086    61.123  &lt; 2e-16 ***\nDESTIN_SZTMSZ02       1.8586526  0.0039229   473.790  &lt; 2e-16 ***\nDESTIN_SZTMSZ03       1.2601385  0.0044018   286.278  &lt; 2e-16 ***\nDESTIN_SZTMSZ04       1.5884327  0.0043362   366.316  &lt; 2e-16 ***\nDESTIN_SZTMSZ05       1.0377553  0.0063271   164.018  &lt; 2e-16 ***\nDESTIN_SZTNSZ01      -0.9954275  0.0080345  -123.895  &lt; 2e-16 ***\nDESTIN_SZTNSZ02      -2.1032696  0.0109228  -192.557  &lt; 2e-16 ***\nDESTIN_SZTNSZ03      -2.0044892  0.0129215  -155.128  &lt; 2e-16 ***\nDESTIN_SZTNSZ04      -0.9750326  0.0081677  -119.377  &lt; 2e-16 ***\nDESTIN_SZTPSZ01      -0.7788383  0.0068769  -113.254  &lt; 2e-16 ***\nDESTIN_SZTPSZ02       0.2866080  0.0042843    66.898  &lt; 2e-16 ***\nDESTIN_SZTPSZ03      -0.8749841  0.0065470  -133.646  &lt; 2e-16 ***\nDESTIN_SZTPSZ04      -1.6852792  0.0081488  -206.812  &lt; 2e-16 ***\nDESTIN_SZTPSZ05      -1.3721346  0.0068230  -201.104  &lt; 2e-16 ***\nDESTIN_SZTPSZ06      -0.7832133  0.0069164  -113.239  &lt; 2e-16 ***\nDESTIN_SZTPSZ07      -2.3109126  0.0130830  -176.635  &lt; 2e-16 ***\nDESTIN_SZTPSZ08      -1.6406531  0.0104897  -156.406  &lt; 2e-16 ***\nDESTIN_SZTPSZ09      -0.5636273  0.0076848   -73.343  &lt; 2e-16 ***\nDESTIN_SZTPSZ10      -1.5640843  0.0099984  -156.433  &lt; 2e-16 ***\nDESTIN_SZTPSZ11      -0.3700482  0.0059834   -61.846  &lt; 2e-16 ***\nDESTIN_SZTPSZ12      -0.8828228  0.0072302  -122.102  &lt; 2e-16 ***\nDESTIN_SZTSSZ01       0.3529526  0.0221887    15.907  &lt; 2e-16 ***\nDESTIN_SZTSSZ02       1.0265792  0.0153515    66.871  &lt; 2e-16 ***\nDESTIN_SZTSSZ03       1.9647347  0.0092388   212.662  &lt; 2e-16 ***\nDESTIN_SZTSSZ04       1.8649836  0.0089976   207.275  &lt; 2e-16 ***\nDESTIN_SZTSSZ05       2.8437058  0.0085738   331.673  &lt; 2e-16 ***\nDESTIN_SZTSSZ06       3.4238870  0.0161304   212.263  &lt; 2e-16 ***\nDESTIN_SZWCSZ01       2.9550693  0.0051690   571.689  &lt; 2e-16 ***\nDESTIN_SZWCSZ02      -0.8214103  0.0129213   -63.570  &lt; 2e-16 ***\nDESTIN_SZWCSZ03      -1.7393427  0.0347472   -50.057  &lt; 2e-16 ***\nDESTIN_SZWDSZ01       1.3424417  0.0039957   335.972  &lt; 2e-16 ***\nDESTIN_SZWDSZ02      -0.2103694  0.0068601   -30.666  &lt; 2e-16 ***\nDESTIN_SZWDSZ03       0.8268551  0.0051363   160.983  &lt; 2e-16 ***\nDESTIN_SZWDSZ04      -0.0643997  0.0079076    -8.144 3.82e-16 ***\nDESTIN_SZWDSZ05       0.0451985  0.0075732     5.968 2.40e-09 ***\nDESTIN_SZWDSZ06       0.6981330  0.0051936   134.423  &lt; 2e-16 ***\nDESTIN_SZWDSZ07      -0.0403233  0.0067749    -5.952 2.65e-09 ***\nDESTIN_SZWDSZ08       0.2850631  0.0069225    41.179  &lt; 2e-16 ***\nDESTIN_SZWDSZ09       1.3016106  0.0050365   258.433  &lt; 2e-16 ***\nDESTIN_SZYSSZ01       0.7598564  0.0044144   172.133  &lt; 2e-16 ***\nDESTIN_SZYSSZ02       0.2648061  0.0058239    45.469  &lt; 2e-16 ***\nDESTIN_SZYSSZ03      -0.0412163  0.0068337    -6.031 1.63e-09 ***\nDESTIN_SZYSSZ04      -0.0561054  0.0060829    -9.223  &lt; 2e-16 ***\nDESTIN_SZYSSZ05      -0.9970159  0.0121827   -81.839  &lt; 2e-16 ***\nDESTIN_SZYSSZ06      -1.3808376  0.0125738  -109.819  &lt; 2e-16 ***\nDESTIN_SZYSSZ07      -0.7128364  0.0165296   -43.125  &lt; 2e-16 ***\nDESTIN_SZYSSZ08       0.9409510  0.0045886   205.064  &lt; 2e-16 ***\nDESTIN_SZYSSZ09       0.3738436  0.0047971    77.930  &lt; 2e-16 ***\nlog(ORIGIN_AGE25_64)  0.1928847  0.0001667  1157.214  &lt; 2e-16 ***\nlog(dist)            -1.7828141  0.0004794 -3718.501  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 36117615  on 14273  degrees of freedom\nResidual deviance: 12319763  on 13992  degrees of freedom\nAIC: 12404881\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)\n\n[1] 0.496166\n\n\n\n\nDoubly constrained\nIn this section, we will fit a doubly constrained SIM by using the code chunk below.\nThe general formula of Doubly Constrained Spatial Interaction Model\n\n\ndbcSIM &lt;- glm(formula = TRIPS ~ \n                ORIGIN_SZ + \n                DESTIN_SZ + \n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(dbcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + DESTIN_SZ + log(dist), family = poisson(link = \"log\"), \n    data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                  Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)     21.9587595  0.0066831  3285.715  &lt; 2e-16 ***\nORIGIN_SZAMSZ02  0.4778050  0.0054127    88.275  &lt; 2e-16 ***\nORIGIN_SZAMSZ03  0.2895973  0.0055517    52.163  &lt; 2e-16 ***\nORIGIN_SZAMSZ04 -0.2628080  0.0060720   -43.282  &lt; 2e-16 ***\nORIGIN_SZAMSZ05 -0.2631404  0.0069008   -38.132  &lt; 2e-16 ***\nORIGIN_SZAMSZ06  0.1722337  0.0062028    27.767  &lt; 2e-16 ***\nORIGIN_SZAMSZ07 -0.9883200  0.0111224   -88.859  &lt; 2e-16 ***\nORIGIN_SZAMSZ08 -0.4052821  0.0104095   -38.934  &lt; 2e-16 ***\nORIGIN_SZAMSZ09  0.0356290  0.0064816     5.497 3.86e-08 ***\nORIGIN_SZAMSZ10  0.4815569  0.0055521    86.735  &lt; 2e-16 ***\nORIGIN_SZAMSZ11 -1.4440079  0.0146079   -98.851  &lt; 2e-16 ***\nORIGIN_SZAMSZ12 -1.7862677  0.0128071  -139.475  &lt; 2e-16 ***\nORIGIN_SZBDSZ01  0.8653749  0.0054381   159.132  &lt; 2e-16 ***\nORIGIN_SZBDSZ02  0.0841000  0.0062834    13.385  &lt; 2e-16 ***\nORIGIN_SZBDSZ03  0.3158343  0.0057510    54.918  &lt; 2e-16 ***\nORIGIN_SZBDSZ04  1.4556701  0.0049986   291.215  &lt; 2e-16 ***\nORIGIN_SZBDSZ05  0.6363125  0.0057193   111.257  &lt; 2e-16 ***\nORIGIN_SZBDSZ06  0.6749341  0.0058650   115.078  &lt; 2e-16 ***\nORIGIN_SZBDSZ07 -1.2176407  0.0113698  -107.095  &lt; 2e-16 ***\nORIGIN_SZBDSZ08 -0.9803580  0.0105604   -92.833  &lt; 2e-16 ***\nORIGIN_SZBKSZ01 -0.2919642  0.0080763   -36.151  &lt; 2e-16 ***\nORIGIN_SZBKSZ02  0.4609570  0.0067997    67.791  &lt; 2e-16 ***\nORIGIN_SZBKSZ03  0.6273448  0.0065989    95.068  &lt; 2e-16 ***\nORIGIN_SZBKSZ04 -0.2499063  0.0076555   -32.644  &lt; 2e-16 ***\nORIGIN_SZBKSZ05 -0.2628428  0.0078905   -33.311  &lt; 2e-16 ***\nORIGIN_SZBKSZ06 -0.2174034  0.0075134   -28.936  &lt; 2e-16 ***\nORIGIN_SZBKSZ07  0.7094093  0.0058574   121.114  &lt; 2e-16 ***\nORIGIN_SZBKSZ08 -0.1614362  0.0067626   -23.872  &lt; 2e-16 ***\nORIGIN_SZBKSZ09 -0.2739085  0.0072969   -37.537  &lt; 2e-16 ***\nORIGIN_SZBLSZ01 -2.4281074  0.0181172  -134.022  &lt; 2e-16 ***\nORIGIN_SZBLSZ02 -2.7305447  0.0219341  -124.489  &lt; 2e-16 ***\nORIGIN_SZBLSZ03 -3.3071431  0.0540398   -61.198  &lt; 2e-16 ***\nORIGIN_SZBLSZ04 -2.4550671  0.0263946   -93.014  &lt; 2e-16 ***\nORIGIN_SZBMSZ01  0.1198976  0.0065964    18.176  &lt; 2e-16 ***\nORIGIN_SZBMSZ02 -1.3908667  0.0083230  -167.112  &lt; 2e-16 ***\nORIGIN_SZBMSZ03 -0.6999122  0.0069754  -100.339  &lt; 2e-16 ***\nORIGIN_SZBMSZ04 -0.2691159  0.0066184   -40.662  &lt; 2e-16 ***\nORIGIN_SZBMSZ05 -2.6163780  0.0190989  -136.991  &lt; 2e-16 ***\nORIGIN_SZBMSZ06 -2.9729956  0.0197182  -150.774  &lt; 2e-16 ***\nORIGIN_SZBMSZ07 -0.7309916  0.0072407  -100.956  &lt; 2e-16 ***\nORIGIN_SZBMSZ08 -1.0019514  0.0073169  -136.936  &lt; 2e-16 ***\nORIGIN_SZBMSZ09 -1.3667460  0.0105325  -129.764  &lt; 2e-16 ***\nORIGIN_SZBMSZ10 -1.6907268  0.0106687  -158.476  &lt; 2e-16 ***\nORIGIN_SZBMSZ11 -1.2288802  0.0082919  -148.202  &lt; 2e-16 ***\nORIGIN_SZBMSZ12 -1.6517767  0.0115101  -143.507  &lt; 2e-16 ***\nORIGIN_SZBMSZ13 -0.7251351  0.0075289   -96.314  &lt; 2e-16 ***\nORIGIN_SZBMSZ14 -1.1534912  0.0082629  -139.599  &lt; 2e-16 ***\nORIGIN_SZBMSZ15 -0.5476774  0.0075710   -72.339  &lt; 2e-16 ***\nORIGIN_SZBMSZ16 -1.5195034  0.0111459  -136.329  &lt; 2e-16 ***\nORIGIN_SZBMSZ17 -1.6026767  0.0184419   -86.904  &lt; 2e-16 ***\nORIGIN_SZBPSZ01  0.5571291  0.0071866    77.523  &lt; 2e-16 ***\nORIGIN_SZBPSZ02  0.0523197  0.0082259     6.360 2.01e-10 ***\nORIGIN_SZBPSZ03  0.2942047  0.0080482    36.555  &lt; 2e-16 ***\nORIGIN_SZBPSZ04  0.6246296  0.0065878    94.816  &lt; 2e-16 ***\nORIGIN_SZBPSZ05  0.8663708  0.0060852   142.372  &lt; 2e-16 ***\nORIGIN_SZBPSZ06 -0.9896182  0.0109551   -90.334  &lt; 2e-16 ***\nORIGIN_SZBPSZ07 -0.5219250  0.0101830   -51.255  &lt; 2e-16 ***\nORIGIN_SZBSSZ01  0.3299588  0.0066440    49.663  &lt; 2e-16 ***\nORIGIN_SZBSSZ02  0.2851357  0.0057077    49.956  &lt; 2e-16 ***\nORIGIN_SZBSSZ03 -0.2084740  0.0063364   -32.901  &lt; 2e-16 ***\nORIGIN_SZBTSZ01  0.1425664  0.0071103    20.051  &lt; 2e-16 ***\nORIGIN_SZBTSZ02 -0.5591999  0.0093616   -59.733  &lt; 2e-16 ***\nORIGIN_SZBTSZ03 -0.3648190  0.0081677   -44.666  &lt; 2e-16 ***\nORIGIN_SZBTSZ04 -1.4555078  0.0120138  -121.152  &lt; 2e-16 ***\nORIGIN_SZBTSZ05 -0.8635510  0.0133848   -64.517  &lt; 2e-16 ***\nORIGIN_SZBTSZ06 -1.1383111  0.0106421  -106.963  &lt; 2e-16 ***\nORIGIN_SZBTSZ07 -2.3477669  0.0160858  -145.953  &lt; 2e-16 ***\nORIGIN_SZBTSZ08 -1.2918779  0.0124862  -103.464  &lt; 2e-16 ***\nORIGIN_SZCBSZ01 -3.3713588  0.0578683   -58.259  &lt; 2e-16 ***\nORIGIN_SZCCSZ01 -0.6029242  0.0153385   -39.308  &lt; 2e-16 ***\nORIGIN_SZCHSZ01 -0.7641380  0.0135100   -56.561  &lt; 2e-16 ***\nORIGIN_SZCHSZ02 -0.8400736  0.0101951   -82.400  &lt; 2e-16 ***\nORIGIN_SZCHSZ03  1.2753127  0.0072576   175.720  &lt; 2e-16 ***\nORIGIN_SZCKSZ01  0.2470943  0.0067135    36.806  &lt; 2e-16 ***\nORIGIN_SZCKSZ02  0.5793581  0.0070498    82.181  &lt; 2e-16 ***\nORIGIN_SZCKSZ03  1.0795767  0.0060642   178.025  &lt; 2e-16 ***\nORIGIN_SZCKSZ04  1.4947920  0.0063122   236.808  &lt; 2e-16 ***\nORIGIN_SZCKSZ05  0.7457580  0.0074071   100.681  &lt; 2e-16 ***\nORIGIN_SZCKSZ06  0.5760952  0.0094861    60.730  &lt; 2e-16 ***\nORIGIN_SZCLSZ01 -0.9061335  0.0098617   -91.884  &lt; 2e-16 ***\nORIGIN_SZCLSZ02 -1.7609479  0.0156124  -112.791  &lt; 2e-16 ***\nORIGIN_SZCLSZ03 -1.0081325  0.0095171  -105.929  &lt; 2e-16 ***\nORIGIN_SZCLSZ04  0.6181200  0.0057953   106.659  &lt; 2e-16 ***\nORIGIN_SZCLSZ05 -2.0462335  0.0168934  -121.127  &lt; 2e-16 ***\nORIGIN_SZCLSZ06  0.7902389  0.0055680   141.924  &lt; 2e-16 ***\nORIGIN_SZCLSZ07 -0.5472929  0.0071001   -77.082  &lt; 2e-16 ***\nORIGIN_SZCLSZ08 -0.2197650  0.0077460   -28.372  &lt; 2e-16 ***\nORIGIN_SZCLSZ09 -1.8175782  0.0195989   -92.739  &lt; 2e-16 ***\nORIGIN_SZDTSZ02 -3.7618796  0.0872098   -43.136  &lt; 2e-16 ***\nORIGIN_SZDTSZ03 -3.4514766  0.0840812   -41.049  &lt; 2e-16 ***\nORIGIN_SZDTSZ13 -3.0627578  0.0352485   -86.891  &lt; 2e-16 ***\nORIGIN_SZGLSZ01 -1.8055929  0.0111938  -161.303  &lt; 2e-16 ***\nORIGIN_SZGLSZ02 -0.1588829  0.0061413   -25.871  &lt; 2e-16 ***\nORIGIN_SZGLSZ03 -0.2508524  0.0064276   -39.027  &lt; 2e-16 ***\nORIGIN_SZGLSZ04  0.8819358  0.0051993   169.627  &lt; 2e-16 ***\nORIGIN_SZGLSZ05  0.6062778  0.0053735   112.828  &lt; 2e-16 ***\nORIGIN_SZHGSZ01  0.3841503  0.0056776    67.660  &lt; 2e-16 ***\nORIGIN_SZHGSZ02  0.3962330  0.0057579    68.815  &lt; 2e-16 ***\nORIGIN_SZHGSZ03  0.2159531  0.0061671    35.017  &lt; 2e-16 ***\nORIGIN_SZHGSZ04  0.7831941  0.0052216   149.992  &lt; 2e-16 ***\nORIGIN_SZHGSZ05  1.1741558  0.0051799   226.677  &lt; 2e-16 ***\nORIGIN_SZHGSZ06 -0.1891403  0.0065556   -28.852  &lt; 2e-16 ***\nORIGIN_SZHGSZ07  0.3105421  0.0057186    54.304  &lt; 2e-16 ***\nORIGIN_SZHGSZ08 -0.0766364  0.0063474   -12.074  &lt; 2e-16 ***\nORIGIN_SZHGSZ09 -1.2211107  0.0101434  -120.384  &lt; 2e-16 ***\nORIGIN_SZHGSZ10 -3.4844709  0.0504793   -69.028  &lt; 2e-16 ***\nORIGIN_SZJESZ01  0.4916496  0.0063444    77.493  &lt; 2e-16 ***\nORIGIN_SZJESZ02  0.1343893  0.0063762    21.077  &lt; 2e-16 ***\nORIGIN_SZJESZ03 -0.2761723  0.0068085   -40.563  &lt; 2e-16 ***\nORIGIN_SZJESZ04 -1.5932744  0.0121402  -131.240  &lt; 2e-16 ***\nORIGIN_SZJESZ05 -2.3041311  0.0160245  -143.788  &lt; 2e-16 ***\nORIGIN_SZJESZ06  0.2811076  0.0062495    44.981  &lt; 2e-16 ***\nORIGIN_SZJESZ07 -1.9413956  0.0136276  -142.461  &lt; 2e-16 ***\nORIGIN_SZJESZ08 -1.3315645  0.0143168   -93.007  &lt; 2e-16 ***\nORIGIN_SZJESZ09  0.4418314  0.0069208    63.841  &lt; 2e-16 ***\nORIGIN_SZJESZ10 -1.5551555  0.0236523   -65.751  &lt; 2e-16 ***\nORIGIN_SZJESZ11 -1.8888230  0.0224630   -84.086  &lt; 2e-16 ***\nORIGIN_SZJWSZ01  0.2564586  0.0084699    30.279  &lt; 2e-16 ***\nORIGIN_SZJWSZ02  0.6899398  0.0061751   111.729  &lt; 2e-16 ***\nORIGIN_SZJWSZ03  1.4761229  0.0057392   257.198  &lt; 2e-16 ***\nORIGIN_SZJWSZ04  0.5701272  0.0065749    86.713  &lt; 2e-16 ***\nORIGIN_SZJWSZ05 -2.1253657  0.0150769  -140.968  &lt; 2e-16 ***\nORIGIN_SZJWSZ06 -1.5307265  0.0131906  -116.047  &lt; 2e-16 ***\nORIGIN_SZJWSZ07 -2.8801618  0.0360772   -79.833  &lt; 2e-16 ***\nORIGIN_SZJWSZ08  1.4428820  0.0059638   241.938  &lt; 2e-16 ***\nORIGIN_SZJWSZ09  1.8968475  0.0055649   340.860  &lt; 2e-16 ***\nORIGIN_SZKLSZ01  0.1116580  0.0059844    18.658  &lt; 2e-16 ***\nORIGIN_SZKLSZ02 -0.9618787  0.0077344  -124.364  &lt; 2e-16 ***\nORIGIN_SZKLSZ03 -0.7070626  0.0070275  -100.613  &lt; 2e-16 ***\nORIGIN_SZKLSZ04 -2.2742765  0.0139991  -162.459  &lt; 2e-16 ***\nORIGIN_SZKLSZ05 -1.1907262  0.0123719   -96.244  &lt; 2e-16 ***\nORIGIN_SZKLSZ06 -5.9774897  0.1857994   -32.172  &lt; 2e-16 ***\nORIGIN_SZKLSZ07 -1.4258369  0.0103083  -138.320  &lt; 2e-16 ***\nORIGIN_SZKLSZ08 -1.7625888  0.0116107  -151.808  &lt; 2e-16 ***\nORIGIN_SZLKSZ01 -2.0541388  0.0448216   -45.829  &lt; 2e-16 ***\nORIGIN_SZMDSZ01 -0.8571117  0.0321054   -26.697  &lt; 2e-16 ***\nORIGIN_SZMDSZ02 -0.6034597  0.0120724   -49.987  &lt; 2e-16 ***\nORIGIN_SZMDSZ03 -2.1681163  0.0201078  -107.825  &lt; 2e-16 ***\nORIGIN_SZMPSZ01 -0.9331562  0.0096218   -96.984  &lt; 2e-16 ***\nORIGIN_SZMPSZ02 -1.0268229  0.0081379  -126.178  &lt; 2e-16 ***\nORIGIN_SZMPSZ03  0.0054001  0.0066875     0.807 0.419385    \nORIGIN_SZMUSZ02 -3.6269863  0.1105492   -32.809  &lt; 2e-16 ***\nORIGIN_SZNTSZ01 -3.0593717  0.0399843   -76.514  &lt; 2e-16 ***\nORIGIN_SZNTSZ02 -3.3331415  0.0251754  -132.397  &lt; 2e-16 ***\nORIGIN_SZNTSZ03 -0.8351522  0.0090372   -92.413  &lt; 2e-16 ***\nORIGIN_SZNTSZ05 -4.2082472  0.0583343   -72.140  &lt; 2e-16 ***\nORIGIN_SZNTSZ06 -3.8549296  0.0593793   -64.920  &lt; 2e-16 ***\nORIGIN_SZNVSZ01  0.2789069  0.0056024    49.784  &lt; 2e-16 ***\nORIGIN_SZNVSZ02 -0.6036857  0.0077126   -78.273  &lt; 2e-16 ***\nORIGIN_SZNVSZ03 -1.0072683  0.0092678  -108.685  &lt; 2e-16 ***\nORIGIN_SZNVSZ04 -0.8723996  0.0101399   -86.037  &lt; 2e-16 ***\nORIGIN_SZNVSZ05 -2.1552928  0.0183064  -117.734  &lt; 2e-16 ***\nORIGIN_SZPGSZ01  0.0520607  0.0157846     3.298 0.000973 ***\nORIGIN_SZPGSZ02 -0.3481687  0.0089328   -38.976  &lt; 2e-16 ***\nORIGIN_SZPGSZ03  0.9095292  0.0058835   154.590  &lt; 2e-16 ***\nORIGIN_SZPGSZ04  1.3653717  0.0054727   249.489  &lt; 2e-16 ***\nORIGIN_SZPGSZ05  0.3762720  0.0073841    50.957  &lt; 2e-16 ***\nORIGIN_SZPLSZ01 -0.9142754  0.0136552   -66.954  &lt; 2e-16 ***\nORIGIN_SZPLSZ02 -1.0987582  0.0175891   -62.468  &lt; 2e-16 ***\nORIGIN_SZPLSZ03 -2.3427113  0.0474176   -49.406  &lt; 2e-16 ***\nORIGIN_SZPLSZ04 -2.9140779  0.0374458   -77.821  &lt; 2e-16 ***\nORIGIN_SZPLSZ05 -2.2381965  0.0261572   -85.567  &lt; 2e-16 ***\nORIGIN_SZPNSZ01  0.9659006  0.0075177   128.484  &lt; 2e-16 ***\nORIGIN_SZPNSZ02 -0.0158348  0.0143869    -1.101 0.271053    \nORIGIN_SZPNSZ03 -2.1837321  0.0224396   -97.316  &lt; 2e-16 ***\nORIGIN_SZPNSZ04 -3.2481509  0.0370762   -87.608  &lt; 2e-16 ***\nORIGIN_SZPNSZ05 -2.0450679  0.0328165   -62.318  &lt; 2e-16 ***\nORIGIN_SZPRSZ01 -0.6701245  0.0141567   -47.336  &lt; 2e-16 ***\nORIGIN_SZPRSZ02  0.7931907  0.0058079   136.570  &lt; 2e-16 ***\nORIGIN_SZPRSZ03  0.4249094  0.0058610    72.498  &lt; 2e-16 ***\nORIGIN_SZPRSZ04 -0.8529967  0.0090997   -93.739  &lt; 2e-16 ***\nORIGIN_SZPRSZ05  0.7865479  0.0055282   142.278  &lt; 2e-16 ***\nORIGIN_SZPRSZ06 -1.3303664  0.0134512   -98.903  &lt; 2e-16 ***\nORIGIN_SZPRSZ07 -3.0458370  0.0181514  -167.802  &lt; 2e-16 ***\nORIGIN_SZPRSZ08 -0.5342399  0.0075966   -70.327  &lt; 2e-16 ***\nORIGIN_SZQTSZ01 -0.2548930  0.0086485   -29.473  &lt; 2e-16 ***\nORIGIN_SZQTSZ02 -0.8662439  0.0076549  -113.162  &lt; 2e-16 ***\nORIGIN_SZQTSZ03 -0.0890168  0.0072455   -12.286  &lt; 2e-16 ***\nORIGIN_SZQTSZ04 -1.4634370  0.0089384  -163.724  &lt; 2e-16 ***\nORIGIN_SZQTSZ05 -0.6535669  0.0077612   -84.210  &lt; 2e-16 ***\nORIGIN_SZQTSZ06 -0.8275765  0.0081835  -101.128  &lt; 2e-16 ***\nORIGIN_SZQTSZ07 -1.5369800  0.0112808  -136.248  &lt; 2e-16 ***\nORIGIN_SZQTSZ08 -0.4437979  0.0075302   -58.936  &lt; 2e-16 ***\nORIGIN_SZQTSZ09 -0.8184934  0.0083589   -97.918  &lt; 2e-16 ***\nORIGIN_SZQTSZ10 -0.6906597  0.0080980   -85.288  &lt; 2e-16 ***\nORIGIN_SZQTSZ11 -2.3251162  0.0154191  -150.795  &lt; 2e-16 ***\nORIGIN_SZQTSZ12 -3.0442790  0.0208985  -145.670  &lt; 2e-16 ***\nORIGIN_SZQTSZ13 -0.7241013  0.0093441   -77.493  &lt; 2e-16 ***\nORIGIN_SZQTSZ14 -1.8225351  0.0138207  -131.870  &lt; 2e-16 ***\nORIGIN_SZQTSZ15 -0.8720806  0.0138589   -62.926  &lt; 2e-16 ***\nORIGIN_SZRCSZ01 -1.8063415  0.0144295  -125.184  &lt; 2e-16 ***\nORIGIN_SZRCSZ06 -0.5370905  0.0101573   -52.877  &lt; 2e-16 ***\nORIGIN_SZRVSZ01 -2.7426167  0.0341386   -80.338  &lt; 2e-16 ***\nORIGIN_SZRVSZ02 -3.0827269  0.0302299  -101.976  &lt; 2e-16 ***\nORIGIN_SZRVSZ03 -2.9133853  0.0262543  -110.968  &lt; 2e-16 ***\nORIGIN_SZRVSZ04 -3.4220022  0.0582209   -58.776  &lt; 2e-16 ***\nORIGIN_SZRVSZ05 -2.6206257  0.0197470  -132.710  &lt; 2e-16 ***\nORIGIN_SZSBSZ01  0.1010337  0.0085117    11.870  &lt; 2e-16 ***\nORIGIN_SZSBSZ02 -0.8810456  0.0098244   -89.680  &lt; 2e-16 ***\nORIGIN_SZSBSZ03  0.8303668  0.0063009   131.785  &lt; 2e-16 ***\nORIGIN_SZSBSZ04  0.3489128  0.0071456    48.829  &lt; 2e-16 ***\nORIGIN_SZSBSZ05 -0.3182914  0.0085560   -37.201  &lt; 2e-16 ***\nORIGIN_SZSBSZ06 -0.9074308  0.0200035   -45.364  &lt; 2e-16 ***\nORIGIN_SZSBSZ07 -0.2217124  0.0167188   -13.261  &lt; 2e-16 ***\nORIGIN_SZSBSZ08 -1.3007367  0.0178771   -72.760  &lt; 2e-16 ***\nORIGIN_SZSBSZ09 -0.9813703  0.0107885   -90.965  &lt; 2e-16 ***\nORIGIN_SZSESZ02  1.1283424  0.0054209   208.146  &lt; 2e-16 ***\nORIGIN_SZSESZ03  1.2389996  0.0051926   238.610  &lt; 2e-16 ***\nORIGIN_SZSESZ04  0.7535119  0.0060371   124.814  &lt; 2e-16 ***\nORIGIN_SZSESZ05 -0.2347978  0.0071482   -32.847  &lt; 2e-16 ***\nORIGIN_SZSESZ06  0.9520620  0.0057572   165.368  &lt; 2e-16 ***\nORIGIN_SZSESZ07 -2.4296685  0.0231677  -104.873  &lt; 2e-16 ***\nORIGIN_SZSGSZ01 -0.6995899  0.0099969   -69.980  &lt; 2e-16 ***\nORIGIN_SZSGSZ02 -1.2602157  0.0111471  -113.053  &lt; 2e-16 ***\nORIGIN_SZSGSZ03  0.0725860  0.0061970    11.713  &lt; 2e-16 ***\nORIGIN_SZSGSZ04  0.2738315  0.0057524    47.603  &lt; 2e-16 ***\nORIGIN_SZSGSZ05 -2.0207710  0.0119838  -168.625  &lt; 2e-16 ***\nORIGIN_SZSGSZ06  0.4885608  0.0054646    89.404  &lt; 2e-16 ***\nORIGIN_SZSGSZ07 -0.8892155  0.0075074  -118.445  &lt; 2e-16 ***\nORIGIN_SZSKSZ01 -0.3682754  0.0108025   -34.092  &lt; 2e-16 ***\nORIGIN_SZSKSZ02  1.1826086  0.0071388   165.659  &lt; 2e-16 ***\nORIGIN_SZSKSZ03 -0.3230177  0.0101683   -31.767  &lt; 2e-16 ***\nORIGIN_SZSKSZ04 -1.8504236  0.0362400   -51.060  &lt; 2e-16 ***\nORIGIN_SZSKSZ05 -0.2759035  0.0185157   -14.901  &lt; 2e-16 ***\nORIGIN_SZSLSZ01 -2.2757902  0.0348766   -65.253  &lt; 2e-16 ***\nORIGIN_SZSLSZ04 -0.0899820  0.0090356    -9.959  &lt; 2e-16 ***\nORIGIN_SZSRSZ01 -2.1460151  0.0187871  -114.228  &lt; 2e-16 ***\nORIGIN_SZTHSZ01 -2.6851549  0.0571841   -46.956  &lt; 2e-16 ***\nORIGIN_SZTHSZ03 -1.0121495  0.0275551   -36.732  &lt; 2e-16 ***\nORIGIN_SZTHSZ04 -2.6129645  0.0345167   -75.701  &lt; 2e-16 ***\nORIGIN_SZTHSZ06 -1.7229100  0.0208134   -82.779  &lt; 2e-16 ***\nORIGIN_SZTMSZ01 -0.2254986  0.0070312   -32.071  &lt; 2e-16 ***\nORIGIN_SZTMSZ02  1.7271575  0.0049219   350.914  &lt; 2e-16 ***\nORIGIN_SZTMSZ03  0.9891319  0.0052266   189.250  &lt; 2e-16 ***\nORIGIN_SZTMSZ04  0.2018090  0.0062114    32.490  &lt; 2e-16 ***\nORIGIN_SZTMSZ05 -1.1882870  0.0125842   -94.427  &lt; 2e-16 ***\nORIGIN_SZTNSZ01 -1.6122620  0.0141911  -113.611  &lt; 2e-16 ***\nORIGIN_SZTNSZ02 -1.5630967  0.0112227  -139.280  &lt; 2e-16 ***\nORIGIN_SZTNSZ03 -2.0739538  0.0149298  -138.914  &lt; 2e-16 ***\nORIGIN_SZTNSZ04 -0.2816960  0.0085295   -33.026  &lt; 2e-16 ***\nORIGIN_SZTPSZ01 -0.7822239  0.0077901  -100.412  &lt; 2e-16 ***\nORIGIN_SZTPSZ02  0.5735478  0.0053042   108.131  &lt; 2e-16 ***\nORIGIN_SZTPSZ03 -0.8748650  0.0074202  -117.903  &lt; 2e-16 ***\nORIGIN_SZTPSZ04 -0.8537831  0.0069792  -122.332  &lt; 2e-16 ***\nORIGIN_SZTPSZ05 -0.5581114  0.0077012   -72.471  &lt; 2e-16 ***\nORIGIN_SZTPSZ06  0.0262001  0.0075241     3.482 0.000497 ***\nORIGIN_SZTPSZ07 -0.5969952  0.0074272   -80.380  &lt; 2e-16 ***\nORIGIN_SZTPSZ08 -1.0537959  0.0111297   -94.683  &lt; 2e-16 ***\nORIGIN_SZTPSZ09 -0.9588508  0.0081314  -117.920  &lt; 2e-16 ***\nORIGIN_SZTPSZ10 -1.1177249  0.0089403  -125.021  &lt; 2e-16 ***\nORIGIN_SZTPSZ11 -0.2799677  0.0067135   -41.702  &lt; 2e-16 ***\nORIGIN_SZTPSZ12 -0.8898871  0.0080215  -110.938  &lt; 2e-16 ***\nORIGIN_SZTSSZ01 -2.6146463  0.0521606   -50.127  &lt; 2e-16 ***\nORIGIN_SZTSSZ02  0.1682588  0.0119965    14.026  &lt; 2e-16 ***\nORIGIN_SZTSSZ03  0.2587653  0.0123809    20.900  &lt; 2e-16 ***\nORIGIN_SZTSSZ04 -0.5473825  0.0135215   -40.482  &lt; 2e-16 ***\nORIGIN_SZTSSZ05 -0.9967379  0.0206068   -48.369  &lt; 2e-16 ***\nORIGIN_SZTSSZ06  0.4933147  0.0229597    21.486  &lt; 2e-16 ***\nORIGIN_SZWCSZ01  1.2524706  0.0111133   112.700  &lt; 2e-16 ***\nORIGIN_SZWCSZ02 -2.8544820  0.0347805   -82.071  &lt; 2e-16 ***\nORIGIN_SZWCSZ03 -5.1277334  0.1475585   -34.751  &lt; 2e-16 ***\nORIGIN_SZWDSZ01  1.4725308  0.0056496   260.645  &lt; 2e-16 ***\nORIGIN_SZWDSZ02  0.1571680  0.0064909    24.214  &lt; 2e-16 ***\nORIGIN_SZWDSZ03  1.2584097  0.0061471   204.717  &lt; 2e-16 ***\nORIGIN_SZWDSZ04  0.8578765  0.0069277   123.833  &lt; 2e-16 ***\nORIGIN_SZWDSZ05  0.1702728  0.0069687    24.434  &lt; 2e-16 ***\nORIGIN_SZWDSZ06  0.1736910  0.0069507    24.989  &lt; 2e-16 ***\nORIGIN_SZWDSZ07 -1.5610176  0.0100803  -154.859  &lt; 2e-16 ***\nORIGIN_SZWDSZ08 -0.9490906  0.0102047   -93.005  &lt; 2e-16 ***\nORIGIN_SZWDSZ09  1.2107011  0.0062294   194.354  &lt; 2e-16 ***\nORIGIN_SZYSSZ01 -0.3324158  0.0074537   -44.598  &lt; 2e-16 ***\nORIGIN_SZYSSZ02  0.8177113  0.0066108   123.693  &lt; 2e-16 ***\nORIGIN_SZYSSZ03  1.6751777  0.0058470   286.503  &lt; 2e-16 ***\nORIGIN_SZYSSZ04  0.8130044  0.0059025   137.738  &lt; 2e-16 ***\nORIGIN_SZYSSZ05  0.3678420  0.0072431    50.785  &lt; 2e-16 ***\nORIGIN_SZYSSZ06 -0.6024384  0.0126722   -47.540  &lt; 2e-16 ***\nORIGIN_SZYSSZ07 -0.7631918  0.0158478   -48.157  &lt; 2e-16 ***\nORIGIN_SZYSSZ08  0.2141930  0.0076154    28.126  &lt; 2e-16 ***\nORIGIN_SZYSSZ09  1.0809368  0.0057973   186.457  &lt; 2e-16 ***\nDESTIN_SZAMSZ02  0.0761304  0.0051207    14.867  &lt; 2e-16 ***\nDESTIN_SZAMSZ03  0.0143394  0.0050755     2.825 0.004724 ** \nDESTIN_SZAMSZ04 -1.2516780  0.0074947  -167.008  &lt; 2e-16 ***\nDESTIN_SZAMSZ05 -1.2312375  0.0076598  -160.741  &lt; 2e-16 ***\nDESTIN_SZAMSZ06 -1.0333412  0.0075283  -137.261  &lt; 2e-16 ***\nDESTIN_SZAMSZ07 -1.5338249  0.0110036  -139.392  &lt; 2e-16 ***\nDESTIN_SZAMSZ08 -0.3751665  0.0075358   -49.784  &lt; 2e-16 ***\nDESTIN_SZAMSZ09 -1.1633493  0.0077556  -150.001  &lt; 2e-16 ***\nDESTIN_SZAMSZ10  0.1017717  0.0053151    19.148  &lt; 2e-16 ***\nDESTIN_SZAMSZ11 -0.8840362  0.0097007   -91.131  &lt; 2e-16 ***\nDESTIN_SZAMSZ12  0.1628123  0.0055220    29.484  &lt; 2e-16 ***\nDESTIN_SZBDSZ01  1.0040794  0.0047922   209.523  &lt; 2e-16 ***\nDESTIN_SZBDSZ02 -0.2478149  0.0063085   -39.283  &lt; 2e-16 ***\nDESTIN_SZBDSZ03  0.1016088  0.0057420    17.696  &lt; 2e-16 ***\nDESTIN_SZBDSZ04  1.1082928  0.0047747   232.116  &lt; 2e-16 ***\nDESTIN_SZBDSZ05  0.8737933  0.0050593   172.712  &lt; 2e-16 ***\nDESTIN_SZBDSZ06  0.2897032  0.0058244    49.740  &lt; 2e-16 ***\nDESTIN_SZBDSZ07 -0.9026193  0.0113656   -79.416  &lt; 2e-16 ***\nDESTIN_SZBDSZ08 -1.7063577  0.0131234  -130.024  &lt; 2e-16 ***\nDESTIN_SZBKSZ01 -1.3892839  0.0083307  -166.767  &lt; 2e-16 ***\nDESTIN_SZBKSZ02 -0.6661120  0.0073464   -90.672  &lt; 2e-16 ***\nDESTIN_SZBKSZ03 -0.9536826  0.0073196  -130.292  &lt; 2e-16 ***\nDESTIN_SZBKSZ04 -0.6655610  0.0065868  -101.044  &lt; 2e-16 ***\nDESTIN_SZBKSZ05 -0.9053119  0.0079264  -114.215  &lt; 2e-16 ***\nDESTIN_SZBKSZ06 -1.2622159  0.0075079  -168.119  &lt; 2e-16 ***\nDESTIN_SZBKSZ07 -0.0423370  0.0056686    -7.469 8.10e-14 ***\nDESTIN_SZBKSZ08 -1.3811240  0.0084985  -162.515  &lt; 2e-16 ***\nDESTIN_SZBKSZ09 -0.0797012  0.0061428   -12.975  &lt; 2e-16 ***\nDESTIN_SZBLSZ01 -0.8859670  0.0088108  -100.555  &lt; 2e-16 ***\nDESTIN_SZBLSZ02  0.1362723  0.0082167    16.585  &lt; 2e-16 ***\nDESTIN_SZBLSZ03  1.2037396  0.0093508   128.732  &lt; 2e-16 ***\nDESTIN_SZBLSZ04 -0.9316219  0.0178080   -52.315  &lt; 2e-16 ***\nDESTIN_SZBMSZ01  0.7188470  0.0061160   117.536  &lt; 2e-16 ***\nDESTIN_SZBMSZ02 -0.0597895  0.0061206    -9.769  &lt; 2e-16 ***\nDESTIN_SZBMSZ03 -0.2427075  0.0069937   -34.704  &lt; 2e-16 ***\nDESTIN_SZBMSZ04 -0.0622494  0.0065569    -9.494  &lt; 2e-16 ***\nDESTIN_SZBMSZ05 -0.2857019  0.0086450   -33.048  &lt; 2e-16 ***\nDESTIN_SZBMSZ06 -1.3486558  0.0158904   -84.872  &lt; 2e-16 ***\nDESTIN_SZBMSZ07  0.4549687  0.0058315    78.020  &lt; 2e-16 ***\nDESTIN_SZBMSZ08 -0.8730268  0.0077814  -112.195  &lt; 2e-16 ***\nDESTIN_SZBMSZ09 -2.0319890  0.0163038  -124.633  &lt; 2e-16 ***\nDESTIN_SZBMSZ10 -1.4319101  0.0102616  -139.541  &lt; 2e-16 ***\nDESTIN_SZBMSZ11 -1.2429176  0.0092250  -134.733  &lt; 2e-16 ***\nDESTIN_SZBMSZ12 -0.8526549  0.0096009   -88.810  &lt; 2e-16 ***\nDESTIN_SZBMSZ13  0.1399907  0.0066885    20.930  &lt; 2e-16 ***\nDESTIN_SZBMSZ14 -1.0103155  0.0091377  -110.566  &lt; 2e-16 ***\nDESTIN_SZBMSZ15 -0.6819769  0.0086179   -79.135  &lt; 2e-16 ***\nDESTIN_SZBMSZ16 -1.4468308  0.0134051  -107.931  &lt; 2e-16 ***\nDESTIN_SZBMSZ17 -1.5312175  0.0186843   -81.952  &lt; 2e-16 ***\nDESTIN_SZBPSZ01 -1.1726725  0.0073257  -160.077  &lt; 2e-16 ***\nDESTIN_SZBPSZ02 -2.1072012  0.0103320  -203.949  &lt; 2e-16 ***\nDESTIN_SZBPSZ03 -1.6944911  0.0098520  -171.995  &lt; 2e-16 ***\nDESTIN_SZBPSZ04 -0.7664610  0.0074458  -102.939  &lt; 2e-16 ***\nDESTIN_SZBPSZ05  0.1358370  0.0056258    24.145  &lt; 2e-16 ***\nDESTIN_SZBPSZ06 -1.2425471  0.0096942  -128.175  &lt; 2e-16 ***\nDESTIN_SZBPSZ07 -0.1666192  0.0094969   -17.545  &lt; 2e-16 ***\nDESTIN_SZBSSZ01  0.3857894  0.0057261    67.374  &lt; 2e-16 ***\nDESTIN_SZBSSZ02 -0.5293265  0.0064886   -81.578  &lt; 2e-16 ***\nDESTIN_SZBSSZ03  0.3909966  0.0048540    80.551  &lt; 2e-16 ***\nDESTIN_SZBTSZ01  0.7114965  0.0054528   130.482  &lt; 2e-16 ***\nDESTIN_SZBTSZ02 -0.0487084  0.0082474    -5.906 3.51e-09 ***\nDESTIN_SZBTSZ03  0.5539032  0.0064423    85.979  &lt; 2e-16 ***\nDESTIN_SZBTSZ04 -0.7120734  0.0128676   -55.339  &lt; 2e-16 ***\nDESTIN_SZBTSZ05  0.2176097  0.0086791    25.073  &lt; 2e-16 ***\nDESTIN_SZBTSZ06 -0.2167084  0.0084925   -25.518  &lt; 2e-16 ***\nDESTIN_SZBTSZ07 -1.4045618  0.0124363  -112.940  &lt; 2e-16 ***\nDESTIN_SZBTSZ08 -0.8213918  0.0120793   -68.000  &lt; 2e-16 ***\nDESTIN_SZCBSZ01 -5.7340877  0.3333916   -17.199  &lt; 2e-16 ***\nDESTIN_SZCCSZ01 -0.0304192  0.0095920    -3.171 0.001518 ** \nDESTIN_SZCHSZ01 -0.2598507  0.0115311   -22.535  &lt; 2e-16 ***\nDESTIN_SZCHSZ02  0.3497750  0.0068334    51.186  &lt; 2e-16 ***\nDESTIN_SZCHSZ03  2.4550172  0.0050883   482.481  &lt; 2e-16 ***\nDESTIN_SZCKSZ01 -0.4691744  0.0063130   -74.319  &lt; 2e-16 ***\nDESTIN_SZCKSZ02 -0.9557084  0.0069331  -137.847  &lt; 2e-16 ***\nDESTIN_SZCKSZ03  0.0442112  0.0057117     7.740 9.91e-15 ***\nDESTIN_SZCKSZ04 -0.8592063  0.0081238  -105.764  &lt; 2e-16 ***\nDESTIN_SZCKSZ05 -1.1745333  0.0087305  -134.532  &lt; 2e-16 ***\nDESTIN_SZCKSZ06 -0.4982877  0.0085514   -58.269  &lt; 2e-16 ***\nDESTIN_SZCLSZ01  0.2665065  0.0059712    44.632  &lt; 2e-16 ***\nDESTIN_SZCLSZ02 -1.9758876  0.0150823  -131.007  &lt; 2e-16 ***\nDESTIN_SZCLSZ03 -0.9051310  0.0091479   -98.944  &lt; 2e-16 ***\nDESTIN_SZCLSZ04 -0.0828732  0.0061559   -13.462  &lt; 2e-16 ***\nDESTIN_SZCLSZ05 -1.1414780  0.0100760  -113.287  &lt; 2e-16 ***\nDESTIN_SZCLSZ06  0.3229402  0.0056269    57.392  &lt; 2e-16 ***\nDESTIN_SZCLSZ07 -0.4833612  0.0069777   -69.272  &lt; 2e-16 ***\nDESTIN_SZCLSZ08 -0.3219670  0.0075615   -42.580  &lt; 2e-16 ***\nDESTIN_SZCLSZ09  0.0564166  0.0080703     6.991 2.74e-12 ***\nDESTIN_SZDTSZ02 -1.6384236  0.0374725   -43.723  &lt; 2e-16 ***\nDESTIN_SZDTSZ03 -0.4021571  0.0152716   -26.334  &lt; 2e-16 ***\nDESTIN_SZDTSZ13 -1.2799441  0.0177095   -72.274  &lt; 2e-16 ***\nDESTIN_SZGLSZ01 -0.0190303  0.0060665    -3.137 0.001707 ** \nDESTIN_SZGLSZ02 -0.0308469  0.0058724    -5.253 1.50e-07 ***\nDESTIN_SZGLSZ03  0.6927638  0.0048456   142.969  &lt; 2e-16 ***\nDESTIN_SZGLSZ04  0.9325848  0.0049183   189.616  &lt; 2e-16 ***\nDESTIN_SZGLSZ05  0.8480056  0.0048801   173.768  &lt; 2e-16 ***\nDESTIN_SZHGSZ01  0.0652969  0.0047795    13.662  &lt; 2e-16 ***\nDESTIN_SZHGSZ02 -0.9498251  0.0066577  -142.667  &lt; 2e-16 ***\nDESTIN_SZHGSZ03 -1.4372499  0.0076387  -188.154  &lt; 2e-16 ***\nDESTIN_SZHGSZ04 -0.5236292  0.0055353   -94.599  &lt; 2e-16 ***\nDESTIN_SZHGSZ05 -0.5420295  0.0058099   -93.295  &lt; 2e-16 ***\nDESTIN_SZHGSZ06 -0.9054730  0.0067581  -133.983  &lt; 2e-16 ***\nDESTIN_SZHGSZ07  0.0215109  0.0054019     3.982 6.83e-05 ***\nDESTIN_SZHGSZ08 -0.0490979  0.0059206    -8.293  &lt; 2e-16 ***\nDESTIN_SZHGSZ09 -0.0711560  0.0062875   -11.317  &lt; 2e-16 ***\nDESTIN_SZHGSZ10 -3.5807154  0.0290642  -123.200  &lt; 2e-16 ***\nDESTIN_SZJESZ01 -0.4023638  0.0065057   -61.848  &lt; 2e-16 ***\nDESTIN_SZJESZ02 -0.7654353  0.0067096  -114.081  &lt; 2e-16 ***\nDESTIN_SZJESZ03 -0.8778812  0.0071238  -123.232  &lt; 2e-16 ***\nDESTIN_SZJESZ04 -1.1998075  0.0088733  -135.215  &lt; 2e-16 ***\nDESTIN_SZJESZ05 -1.5623652  0.0116898  -133.652  &lt; 2e-16 ***\nDESTIN_SZJESZ06  0.2311474  0.0055595    41.577  &lt; 2e-16 ***\nDESTIN_SZJESZ07 -1.2753348  0.0094838  -134.475  &lt; 2e-16 ***\nDESTIN_SZJESZ08 -0.7654533  0.0099306   -77.081  &lt; 2e-16 ***\nDESTIN_SZJESZ09  0.1637628  0.0074164    22.081  &lt; 2e-16 ***\nDESTIN_SZJESZ10  0.7394958  0.0091249    81.041  &lt; 2e-16 ***\nDESTIN_SZJESZ11  0.5157364  0.0086546    59.591  &lt; 2e-16 ***\nDESTIN_SZJWSZ01 -1.0165204  0.0083025  -122.435  &lt; 2e-16 ***\nDESTIN_SZJWSZ02 -0.8530646  0.0067851  -125.727  &lt; 2e-16 ***\nDESTIN_SZJWSZ03  0.5176135  0.0056449    91.695  &lt; 2e-16 ***\nDESTIN_SZJWSZ04  0.3427105  0.0058499    58.584  &lt; 2e-16 ***\nDESTIN_SZJWSZ05 -1.1695940  0.0080069  -146.073  &lt; 2e-16 ***\nDESTIN_SZJWSZ06 -0.7466462  0.0070240  -106.299  &lt; 2e-16 ***\nDESTIN_SZJWSZ07 -3.0124535  0.0333481   -90.334  &lt; 2e-16 ***\nDESTIN_SZJWSZ08 -0.4253502  0.0066584   -63.881  &lt; 2e-16 ***\nDESTIN_SZJWSZ09  0.9428005  0.0053190   177.251  &lt; 2e-16 ***\nDESTIN_SZKLSZ01 -0.2965013  0.0066422   -44.639  &lt; 2e-16 ***\nDESTIN_SZKLSZ02 -0.4921137  0.0067689   -72.702  &lt; 2e-16 ***\nDESTIN_SZKLSZ03 -0.8489213  0.0078294  -108.427  &lt; 2e-16 ***\nDESTIN_SZKLSZ04 -1.2656342  0.0099918  -126.667  &lt; 2e-16 ***\nDESTIN_SZKLSZ05 -0.3570126  0.0096300   -37.073  &lt; 2e-16 ***\nDESTIN_SZKLSZ06 -2.4764906  0.0390868   -63.359  &lt; 2e-16 ***\nDESTIN_SZKLSZ07 -0.7316189  0.0080994   -90.330  &lt; 2e-16 ***\nDESTIN_SZKLSZ08 -0.1115398  0.0061168   -18.235  &lt; 2e-16 ***\nDESTIN_SZLKSZ01 -1.4940710  0.0271518   -55.027  &lt; 2e-16 ***\nDESTIN_SZMDSZ01 -1.6101440  0.0231238   -69.631  &lt; 2e-16 ***\nDESTIN_SZMDSZ02 -0.9339318  0.0126277   -73.959  &lt; 2e-16 ***\nDESTIN_SZMDSZ03 -3.4868547  0.0303657  -114.829  &lt; 2e-16 ***\nDESTIN_SZMPSZ01 -0.4518483  0.0089869   -50.279  &lt; 2e-16 ***\nDESTIN_SZMPSZ02 -0.5868264  0.0073193   -80.176  &lt; 2e-16 ***\nDESTIN_SZMPSZ03  0.4805365  0.0059041    81.391  &lt; 2e-16 ***\nDESTIN_SZMUSZ02 -1.3837581  0.0218713   -63.268  &lt; 2e-16 ***\nDESTIN_SZNTSZ01 -3.0694691  0.0533346   -57.551  &lt; 2e-16 ***\nDESTIN_SZNTSZ02 -1.4992973  0.0130358  -115.014  &lt; 2e-16 ***\nDESTIN_SZNTSZ03 -0.5221236  0.0089923   -58.064  &lt; 2e-16 ***\nDESTIN_SZNTSZ05 -1.9751162  0.0282369   -69.948  &lt; 2e-16 ***\nDESTIN_SZNTSZ06 -3.9959411  0.0511214   -78.166  &lt; 2e-16 ***\nDESTIN_SZNVSZ01 -0.1126966  0.0057077   -19.745  &lt; 2e-16 ***\nDESTIN_SZNVSZ02 -0.0259250  0.0064427    -4.024 5.72e-05 ***\nDESTIN_SZNVSZ03 -0.0123214  0.0067692    -1.820 0.068725 .  \nDESTIN_SZNVSZ04 -1.3371298  0.0130261  -102.650  &lt; 2e-16 ***\nDESTIN_SZNVSZ05 -0.9686333  0.0101539   -95.395  &lt; 2e-16 ***\nDESTIN_SZPGSZ01 -1.1798309  0.0180543   -65.349  &lt; 2e-16 ***\nDESTIN_SZPGSZ02 -1.3289737  0.0085335  -155.736  &lt; 2e-16 ***\nDESTIN_SZPGSZ03 -0.1661373  0.0055166   -30.116  &lt; 2e-16 ***\nDESTIN_SZPGSZ04 -0.3046408  0.0058469   -52.103  &lt; 2e-16 ***\nDESTIN_SZPGSZ05 -1.5412612  0.0093261  -165.264  &lt; 2e-16 ***\nDESTIN_SZPLSZ01 -0.3439667  0.0083504   -41.192  &lt; 2e-16 ***\nDESTIN_SZPLSZ02 -1.7574919  0.0154244  -113.942  &lt; 2e-16 ***\nDESTIN_SZPLSZ03 -0.3455776  0.0112089   -30.831  &lt; 2e-16 ***\nDESTIN_SZPLSZ04 -2.0749385  0.0141153  -146.999  &lt; 2e-16 ***\nDESTIN_SZPLSZ05 -0.4855216  0.0134069   -36.214  &lt; 2e-16 ***\nDESTIN_SZPNSZ01  0.0117816  0.0083558     1.410 0.158543    \nDESTIN_SZPNSZ02  0.7389858  0.0089823    82.272  &lt; 2e-16 ***\nDESTIN_SZPNSZ03 -0.4708719  0.0098588   -47.761  &lt; 2e-16 ***\nDESTIN_SZPNSZ04  1.3156771  0.0111200   118.316  &lt; 2e-16 ***\nDESTIN_SZPNSZ05  0.9881886  0.0153169    64.516  &lt; 2e-16 ***\nDESTIN_SZPRSZ01 -1.0678999  0.0098295  -108.642  &lt; 2e-16 ***\nDESTIN_SZPRSZ02  0.0650279  0.0063927    10.172  &lt; 2e-16 ***\nDESTIN_SZPRSZ03  0.6348138  0.0050147   126.592  &lt; 2e-16 ***\nDESTIN_SZPRSZ04 -0.3640286  0.0097572   -37.309  &lt; 2e-16 ***\nDESTIN_SZPRSZ05  0.0380410  0.0062577     6.079 1.21e-09 ***\nDESTIN_SZPRSZ06  0.3153712  0.0068742    45.877  &lt; 2e-16 ***\nDESTIN_SZPRSZ07 -1.6669973  0.0145573  -114.513  &lt; 2e-16 ***\nDESTIN_SZPRSZ08 -0.6170648  0.0078424   -78.683  &lt; 2e-16 ***\nDESTIN_SZQTSZ01 -0.5496582  0.0098285   -55.925  &lt; 2e-16 ***\nDESTIN_SZQTSZ02 -0.7318114  0.0086807   -84.303  &lt; 2e-16 ***\nDESTIN_SZQTSZ03 -0.5893064  0.0084789   -69.503  &lt; 2e-16 ***\nDESTIN_SZQTSZ04 -0.7103906  0.0085341   -83.242  &lt; 2e-16 ***\nDESTIN_SZQTSZ05 -0.4721472  0.0078164   -60.405  &lt; 2e-16 ***\nDESTIN_SZQTSZ06 -0.6591466  0.0080069   -82.322  &lt; 2e-16 ***\nDESTIN_SZQTSZ07 -0.9540454  0.0126807   -75.236  &lt; 2e-16 ***\nDESTIN_SZQTSZ08  0.4508867  0.0064870    69.507  &lt; 2e-16 ***\nDESTIN_SZQTSZ09 -0.4061810  0.0075485   -53.810  &lt; 2e-16 ***\nDESTIN_SZQTSZ10  0.1351889  0.0068202    19.822  &lt; 2e-16 ***\nDESTIN_SZQTSZ11  0.3181553  0.0067958    46.816  &lt; 2e-16 ***\nDESTIN_SZQTSZ12 -0.1055766  0.0095576   -11.046  &lt; 2e-16 ***\nDESTIN_SZQTSZ13  0.5199663  0.0071928    72.290  &lt; 2e-16 ***\nDESTIN_SZQTSZ14  0.6086332  0.0078537    77.496  &lt; 2e-16 ***\nDESTIN_SZQTSZ15  1.3906866  0.0092250   150.753  &lt; 2e-16 ***\nDESTIN_SZRCSZ01 -0.0862091  0.0085363   -10.099  &lt; 2e-16 ***\nDESTIN_SZRCSZ06 -1.0186282  0.0211113   -48.250  &lt; 2e-16 ***\nDESTIN_SZRVSZ01 -1.5294454  0.0179337   -85.283  &lt; 2e-16 ***\nDESTIN_SZRVSZ02 -2.3607754  0.0355628   -66.383  &lt; 2e-16 ***\nDESTIN_SZRVSZ03 -1.5266254  0.0156276   -97.688  &lt; 2e-16 ***\nDESTIN_SZRVSZ04 -1.0986565  0.0168695   -65.127  &lt; 2e-16 ***\nDESTIN_SZRVSZ05 -2.4004418  0.0320917   -74.799  &lt; 2e-16 ***\nDESTIN_SZSBSZ01 -1.4023966  0.0109496  -128.078  &lt; 2e-16 ***\nDESTIN_SZSBSZ02 -1.3899893  0.0090891  -152.929  &lt; 2e-16 ***\nDESTIN_SZSBSZ03  0.4509008  0.0059864    75.321  &lt; 2e-16 ***\nDESTIN_SZSBSZ04  0.1796309  0.0070142    25.610  &lt; 2e-16 ***\nDESTIN_SZSBSZ05 -1.3159699  0.0096485  -136.391  &lt; 2e-16 ***\nDESTIN_SZSBSZ06 -1.7705263  0.0253064   -69.964  &lt; 2e-16 ***\nDESTIN_SZSBSZ07 -0.7471529  0.0238628   -31.310  &lt; 2e-16 ***\nDESTIN_SZSBSZ08  0.7884520  0.0069638   113.221  &lt; 2e-16 ***\nDESTIN_SZSBSZ09  0.0131702  0.0066350     1.985 0.047150 *  \nDESTIN_SZSESZ02 -0.7247347  0.0060626  -119.541  &lt; 2e-16 ***\nDESTIN_SZSESZ03  0.1032728  0.0048330    21.368  &lt; 2e-16 ***\nDESTIN_SZSESZ04 -1.0992420  0.0068328  -160.878  &lt; 2e-16 ***\nDESTIN_SZSESZ05 -0.8374712  0.0058155  -144.006  &lt; 2e-16 ***\nDESTIN_SZSESZ06 -0.5531619  0.0074766   -73.985  &lt; 2e-16 ***\nDESTIN_SZSESZ07 -3.0328672  0.0246371  -123.101  &lt; 2e-16 ***\nDESTIN_SZSGSZ01 -0.1933777  0.0068235   -28.340  &lt; 2e-16 ***\nDESTIN_SZSGSZ02 -0.3000845  0.0060284   -49.779  &lt; 2e-16 ***\nDESTIN_SZSGSZ03 -0.4322879  0.0057308   -75.433  &lt; 2e-16 ***\nDESTIN_SZSGSZ04 -0.1214792  0.0056548   -21.482  &lt; 2e-16 ***\nDESTIN_SZSGSZ05 -2.0309074  0.0114993  -176.611  &lt; 2e-16 ***\nDESTIN_SZSGSZ06  0.6592095  0.0046364   142.182  &lt; 2e-16 ***\nDESTIN_SZSGSZ07 -0.4618538  0.0062027   -74.460  &lt; 2e-16 ***\nDESTIN_SZSISZ01 -0.5227257  0.0293399   -17.816  &lt; 2e-16 ***\nDESTIN_SZSKSZ01 -0.4797341  0.0091087   -52.668  &lt; 2e-16 ***\nDESTIN_SZSKSZ02  0.8477357  0.0067821   124.996  &lt; 2e-16 ***\nDESTIN_SZSKSZ03 -0.2477566  0.0074817   -33.115  &lt; 2e-16 ***\nDESTIN_SZSKSZ04 -1.3315992  0.0167055   -79.710  &lt; 2e-16 ***\nDESTIN_SZSKSZ05 -0.3519096  0.0131326   -26.797  &lt; 2e-16 ***\nDESTIN_SZSLSZ01 -0.8570431  0.0102100   -83.941  &lt; 2e-16 ***\nDESTIN_SZSLSZ04 -0.9949105  0.0088280  -112.699  &lt; 2e-16 ***\nDESTIN_SZSRSZ01 -1.0260696  0.0154393   -66.458  &lt; 2e-16 ***\nDESTIN_SZTHSZ01 -4.2040410  0.0404795  -103.856  &lt; 2e-16 ***\nDESTIN_SZTHSZ03 -2.4907000  0.0264056   -94.325  &lt; 2e-16 ***\nDESTIN_SZTHSZ04 -3.0701470  0.0244975  -125.325  &lt; 2e-16 ***\nDESTIN_SZTHSZ06 -2.5308161  0.0169699  -149.135  &lt; 2e-16 ***\nDESTIN_SZTMSZ01 -0.2354889  0.0067201   -35.042  &lt; 2e-16 ***\nDESTIN_SZTMSZ02  1.7379292  0.0044573   389.906  &lt; 2e-16 ***\nDESTIN_SZTMSZ03  0.9112458  0.0048718   187.043  &lt; 2e-16 ***\nDESTIN_SZTMSZ04  1.0731075  0.0048626   220.685  &lt; 2e-16 ***\nDESTIN_SZTMSZ05  0.6398583  0.0067321    95.046  &lt; 2e-16 ***\nDESTIN_SZTNSZ01 -0.3500456  0.0083835   -41.754  &lt; 2e-16 ***\nDESTIN_SZTNSZ02 -1.0573515  0.0112412   -94.060  &lt; 2e-16 ***\nDESTIN_SZTNSZ03 -1.4069979  0.0132733  -106.002  &lt; 2e-16 ***\nDESTIN_SZTNSZ04 -0.3616604  0.0085207   -42.445  &lt; 2e-16 ***\nDESTIN_SZTPSZ01 -0.5919243  0.0071153   -83.190  &lt; 2e-16 ***\nDESTIN_SZTPSZ02  0.7083350  0.0046540   152.198  &lt; 2e-16 ***\nDESTIN_SZTPSZ03 -0.5746433  0.0069625   -82.534  &lt; 2e-16 ***\nDESTIN_SZTPSZ04 -1.5821259  0.0084517  -187.196  &lt; 2e-16 ***\nDESTIN_SZTPSZ05 -1.1796256  0.0073039  -161.505  &lt; 2e-16 ***\nDESTIN_SZTPSZ06 -0.3968272  0.0077295   -51.339  &lt; 2e-16 ***\nDESTIN_SZTPSZ07 -2.1796617  0.0135199  -161.219  &lt; 2e-16 ***\nDESTIN_SZTPSZ08 -1.2568483  0.0107267  -117.170  &lt; 2e-16 ***\nDESTIN_SZTPSZ09 -0.2446623  0.0080840   -30.265  &lt; 2e-16 ***\nDESTIN_SZTPSZ10 -1.2542191  0.0102049  -122.904  &lt; 2e-16 ***\nDESTIN_SZTPSZ11 -0.0886883  0.0062888   -14.102  &lt; 2e-16 ***\nDESTIN_SZTPSZ12 -0.7211823  0.0075086   -96.048  &lt; 2e-16 ***\nDESTIN_SZTSSZ01 -1.6271921  0.0238498   -68.227  &lt; 2e-16 ***\nDESTIN_SZTSSZ02 -0.3340439  0.0169137   -19.750  &lt; 2e-16 ***\nDESTIN_SZTSSZ03  0.3924580  0.0111060    35.338  &lt; 2e-16 ***\nDESTIN_SZTSSZ04  0.4169932  0.0114926    36.283  &lt; 2e-16 ***\nDESTIN_SZTSSZ05  1.3206287  0.0120381   109.704  &lt; 2e-16 ***\nDESTIN_SZTSSZ06  2.4023725  0.0192840   124.579  &lt; 2e-16 ***\nDESTIN_SZWCSZ01  2.0697378  0.0061379   337.206  &lt; 2e-16 ***\nDESTIN_SZWCSZ02 -2.0934025  0.0134782  -155.318  &lt; 2e-16 ***\nDESTIN_SZWCSZ03 -3.0670149  0.0349748   -87.692  &lt; 2e-16 ***\nDESTIN_SZWDSZ01  1.0113215  0.0051461   196.522  &lt; 2e-16 ***\nDESTIN_SZWDSZ02 -1.3383793  0.0076482  -174.993  &lt; 2e-16 ***\nDESTIN_SZWDSZ03  0.3394361  0.0060396    56.202  &lt; 2e-16 ***\nDESTIN_SZWDSZ04 -0.8324928  0.0086019   -96.780  &lt; 2e-16 ***\nDESTIN_SZWDSZ05 -0.8279090  0.0083251   -99.447  &lt; 2e-16 ***\nDESTIN_SZWDSZ06 -0.2252899  0.0061074   -36.888  &lt; 2e-16 ***\nDESTIN_SZWDSZ07 -1.3638599  0.0077990  -174.877  &lt; 2e-16 ***\nDESTIN_SZWDSZ08 -0.4350176  0.0077566   -56.083  &lt; 2e-16 ***\nDESTIN_SZWDSZ09  0.5461048  0.0060745    89.901  &lt; 2e-16 ***\nDESTIN_SZYSSZ01  0.0243093  0.0053476     4.546 5.47e-06 ***\nDESTIN_SZYSSZ02 -0.3398962  0.0065947   -51.540  &lt; 2e-16 ***\nDESTIN_SZYSSZ03 -0.3694187  0.0074032   -49.900  &lt; 2e-16 ***\nDESTIN_SZYSSZ04 -0.5222848  0.0067396   -77.495  &lt; 2e-16 ***\nDESTIN_SZYSSZ05 -1.5460539  0.0124899  -123.784  &lt; 2e-16 ***\nDESTIN_SZYSSZ06 -1.5556892  0.0127640  -121.881  &lt; 2e-16 ***\nDESTIN_SZYSSZ07 -0.8673403  0.0167723   -51.713  &lt; 2e-16 ***\nDESTIN_SZYSSZ08  0.5389364  0.0052540   102.577  &lt; 2e-16 ***\nDESTIN_SZYSSZ09  0.1199483  0.0055235    21.716  &lt; 2e-16 ***\nlog(dist)       -1.8906989  0.0005319 -3554.786  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 36117615  on 14273  degrees of freedom\nResidual deviance:  8091747  on 13715  degrees of freedom\nAIC: 8177420\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)\n\n[1] 0.6883675\n\n\nNotice that there is a relatively greater improvement in the R^2 value.\n\nr2_mcfadden(dbcSIM)\n\n# R2 for Generalized Linear Regression\n       R2: 0.774\n  adj. R2: 0.774\n\n\n\n\nModel comparison\nAnother useful model performance measure for continuous dependent variable is Root Mean Squared Error. In this sub-section, you will learn how to use compare_performance() of performance package\nFirst of all, let us create a list called model_list by using the code chun below.\n\nmodel_list &lt;- list(unconstrained=uncSIM,\n                   originConstrained=orcSIM,\n                   destinationConstrained=decSIM,\n                   doublyConstrained=dbcSIM)\n\nNext, we will compute the RMSE of all the models in model_list file by using the code chunk below.\n\ncompare_performance(model_list,\n                    metrics = \"RMSE\")\n\n# Comparison of Model Performance Indices\n\nName                   | Model |     RMSE\n-----------------------------------------\nunconstrained          |   glm | 2429.978\noriginConstrained      |   glm | 2057.579\ndestinationConstrained |   glm | 1891.724\ndoublyConstrained      |   glm | 1487.111\n\n\nThe print above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 1487.111.\n\n\nVisualising fitted values\nIn this section, you will learn how to visualise the observed values and the fitted values.\nFirstly we will extract the fitted values from each model by using the code chunk below.\n\ndf &lt;- as.data.frame(uncSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nNext, we will join the values to SIM_data data frame.\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(uncTRIPS = \"uncSIM$fitted.values\")\n\nRepeat the same step by for Origin Constrained SIM (i.e. orcSIM)\n\ndf &lt;- as.data.frame(orcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(orcTRIPS = \"orcSIM$fitted.values\")\n\nRepeat the same step by for Destination Constrained SIM (i.e. decSIM)\n\ndf &lt;- as.data.frame(decSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(decTRIPS = \"decSIM$fitted.values\")\n\nRepeat the same step by for Doubly Constrained SIM (i.e. dbcSIM)\n\ndf &lt;- as.data.frame(dbcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(dbcTRIPS = \"dbcSIM$fitted.values\")\n\n\nunc_p &lt;- ggplot(data = SIM_data,\n                aes(x = uncTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\norc_p &lt;- ggplot(data = SIM_data,\n                aes(x = orcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndec_p &lt;- ggplot(data = SIM_data,\n                aes(x = decTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndbc_p &lt;- ggplot(data = SIM_data,\n                aes(x = dbcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\nNow, we will put all the graphs into a single visual for better comparison by using the code chunk below.\n\nggarrange(unc_p, orc_p, dec_p, dbc_p,\n          ncol = 2,\n          nrow = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#getting-started",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#getting-started",
    "title": "In-class Exercise 8: Building Geographically Weighted Predictive Models",
    "section": "Getting Started",
    "text": "Getting Started"
=======
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#getting-started",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#getting-started",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "Getting Started",
    "text": "Getting Started\nInstalling and Loading R packages\n\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse,\n               knitr, kableExtra)"
>>>>>>> 10fc6122f44f9543e3ef2aa7b8609dbd58a3e1d3
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#installing-and-loading-r-packages",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#installing-and-loading-r-packages",
    "title": "In-class Exercise 8: Building Geographically Weighted Predictive Models",
    "section": "Installing and Loading R packages",
    "text": "Installing and Loading R packages\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse,\n               knitr, kableExtra)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#preparing-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#preparing-data",
<<<<<<< HEAD
    "title": "In-class Exercise 8: Building Geographically Weighted Predictive Models",
    "section": "Preparing Data",
    "text": "Preparing Data\nData import\n\nmdata &lt;- read_rds(\"data/rds/mdata.rds\")\n\nData Sampling\nFor quick prototyping, a 10% sample will be selected at random from the data.\n\nset.seed(1234)\nHDB_sample &lt;- mdata %&gt;%\n  sample_n(1500)\n\nChecking of overlapping points\n\noverlapping_points &lt;- HDB_sample %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\nJittering overlapping points\nIn the code chunk below, st_jitter() is used to jitter the overlapping point by a distance of 1 meter.\n\nHDB_sample &lt;- HDB_sample %&gt;%\n  st_jitter(amount = 1)\n\nData Sampling\nThe entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package. rsample is one of the package of tigymodels.\n\nset.seed(1234)\nresale_split &lt;- initial_split(HDB_sample, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)"
=======
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "Preparing Data",
    "text": "Preparing Data\n\nData importData SamplingChecking of overlapping pointSpatial jitter\n\n\n\n\nmdata &lt;- read_rds(\"data/rds/mdata.rds\")\n\n\n\n\nCalibrating predictive models are computational intensive, especially random forest method is used. For quick prototyping, a 10% sample will be selected at random from the data by using the code chunk below.\n\n\nset.seed(1234)\nHDB_sample &lt;- mdata %&gt;%\n  sample_n(1500)\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nWhen using GWmodel to calibrate explanatory or predictive models, it is very important to ensure that there are no overlapping point features\n\n\n\nThe code chunk below is used to check if there are overlapping point features.\n\n\noverlapping_points &lt;- HDB_sample %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\n\n\n\nIn the code code chunk below, st_jitter() of sf package is used to move the point features by 5m to avoid overlapping point features.\n\n\nHDB_sample &lt;- HDB_sample %&gt;%\n  st_jitter(amount = 5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-sampling-1",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-sampling-1",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "Data Sampling",
    "text": "Data Sampling\nThe entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package. rsample is one of the package of tigymodels.\n\n\nset.seed(1234)\nresale_split &lt;- initial_split(HDB_sample, \n                              prop = 6.67/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)"
>>>>>>> 10fc6122f44f9543e3ef2aa7b8609dbd58a3e1d3
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#building-a-non-spatial-multiple-linear-regression",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#building-a-non-spatial-multiple-linear-regression",
<<<<<<< HEAD
    "title": "In-class Exercise 8: Building Geographically Weighted Predictive Models",
    "section": "Building a non-spatial multiple linear regression",
    "text": "Building a non-spatial multiple linear regression\n\nThe reportThe code chunk\n\n\n\n\n                              Model Summary                                \n--------------------------------------------------------------------------\nR                           0.860       RMSE                    61034.447 \nR-Squared                   0.739       MSE                3783410059.812 \nAdj. R-Squared              0.735       Coef. Var                  14.315 \nPred R-Squared              0.730       AIC                     24286.358 \nMAE                     46102.421       SBC                     24364.477 \n--------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                    ANOVA                                     \n-----------------------------------------------------------------------------\n                    Sum of                                                   \n                   Squares         DF       Mean Square       F         Sig. \n-----------------------------------------------------------------------------\nRegression    1.027895e+13         14       7.34211e+11    194.061    0.0000 \nResidual      3.632074e+12        960    3783410059.812                      \nTotal         1.391103e+13        974                                        \n-----------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                 \n------------------------------------------------------------------------------------------------------------------\n                   model          Beta    Std. Error    Std. Beta       t        Sig          lower         upper \n------------------------------------------------------------------------------------------------------------------\n             (Intercept)    114172.894     34962.309                   3.266    0.001     45561.525    182784.264 \n          floor_area_sqm      2777.543       296.467        0.166      9.369    0.000      2195.745      3359.341 \n            storey_order     12752.368      1088.198        0.213     11.719    0.000     10616.846     14887.890 \n    remaining_lease_mths       349.527        14.910        0.449     23.442    0.000       320.267       378.788 \n                PROX_CBD    -16227.901       641.722       -0.572    -25.288    0.000    -17487.240    -14968.562 \n        PROX_ELDERLYCARE    -10941.600      3272.302       -0.059     -3.344    0.001    -17363.291     -4519.910 \n             PROX_HAWKER    -19593.066      4079.929       -0.086     -4.802    0.000    -27599.675    -11586.457 \n                PROX_MRT    -39890.178      5465.548       -0.132     -7.298    0.000    -50615.979    -29164.377 \n               PROX_PARK    -15142.071      4697.197       -0.058     -3.224    0.001    -24360.030     -5924.112 \n               PROX_MALL    -14453.472      6518.983       -0.044     -2.217    0.027    -27246.573     -1660.371 \n        PROX_SUPERMARKET    -17056.095     13703.685       -0.023     -1.245    0.214    -43948.730      9836.540 \nWITHIN_350M_KINDERGARTEN      8899.141      2066.838        0.076      4.306    0.000      4843.100     12955.183 \n   WITHIN_350M_CHILDCARE     -1558.562      1195.890       -0.025     -1.303    0.193     -3905.422       788.297 \n         WITHIN_350M_BUS      -540.341       747.336       -0.013     -0.723    0.470     -2006.942       926.261 \n       WITHIN_1KM_PRISCH    -10529.555      1579.195       -0.135     -6.668    0.000    -13628.627     -7430.483 \n------------------------------------------------------------------------------------------------------------------\n\n\n\n\n\nprice_mlr &lt;- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\nolsrr::ols_regress(price_mlr)"
=======
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "Building a non-spatial multiple linear regression",
    "text": "Building a non-spatial multiple linear regression\n\nThe reportThe code chunk\n\n\n\n\n                              Model Summary                                \n--------------------------------------------------------------------------\nR                           0.862       RMSE                    60813.316 \nR-Squared                   0.742       MSE                3754578098.252 \nAdj. R-Squared              0.739       Coef. Var                  14.255 \nPred R-Squared              0.734       AIC                     24901.005 \nMAE                     45987.256       SBC                     24979.529 \n--------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                      \n-------------------------------------------------------------------------------\n                    Sum of                                                     \n                   Squares         DF         Mean Square       F         Sig. \n-------------------------------------------------------------------------------\nRegression    1.065708e+13         14    761220078101.236    202.745    0.0000 \nResidual      3.698259e+12        985      3754578098.252                      \nTotal         1.435534e+13        999                                          \n-------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                 \n------------------------------------------------------------------------------------------------------------------\n                   model          Beta    Std. Error    Std. Beta       t        Sig          lower         upper \n------------------------------------------------------------------------------------------------------------------\n             (Intercept)    115703.696     34303.409                   3.373    0.001     48387.533    183019.860 \n          floor_area_sqm      2778.618       292.262        0.165      9.507    0.000      2205.089      3352.146 \n            storey_order     12698.165      1070.950        0.211     11.857    0.000     10596.559     14799.771 \n    remaining_lease_mths       350.252        14.596        0.450     23.997    0.000       321.610       378.894 \n                PROX_CBD    -16225.588       630.092       -0.572    -25.751    0.000    -17462.065    -14989.110 \n        PROX_ELDERLYCARE    -11330.930      3220.845       -0.061     -3.518    0.000    -17651.436     -5010.423 \n             PROX_HAWKER    -19964.070      4021.046       -0.087     -4.965    0.000    -27854.872    -12073.268 \n                PROX_MRT    -39652.516      5412.288       -0.130     -7.326    0.000    -50273.456    -29031.577 \n               PROX_PARK    -15878.322      4609.199       -0.061     -3.445    0.001    -24923.300     -6833.344 \n               PROX_MALL    -15910.922      6438.111       -0.048     -2.471    0.014    -28544.911     -3276.933 \n        PROX_SUPERMARKET    -18928.514     13304.965       -0.025     -1.423    0.155    -45037.848      7180.821 \nWITHIN_350M_KINDERGARTEN      9309.735      2024.293        0.079      4.599    0.000      5337.313     13282.157 \n   WITHIN_350M_CHILDCARE     -1619.514      1180.948       -0.026     -1.371    0.171     -3936.977       697.948 \n         WITHIN_350M_BUS      -447.695       738.715       -0.011     -0.606    0.545     -1897.331      1001.940 \n       WITHIN_1KM_PRISCH    -10698.012      1543.511       -0.138     -6.931    0.000    -13726.960     -7669.065 \n------------------------------------------------------------------------------------------------------------------\n\n\n\n\n\n\nprice_mlr &lt;- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\nolsrr::ols_regress(price_mlr)"
>>>>>>> 10fc6122f44f9543e3ef2aa7b8609dbd58a3e1d3
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-mlr",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-mlr",
<<<<<<< HEAD
    "title": "In-class Exercise 8: Building Geographically Weighted Predictive Models",
    "section": "Predictive Modelling with MLR",
    "text": "Predictive Modelling with MLR\n\nComputing adaptive bandwidthModel calibrationModelling results\n\n\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nAdaptive bandwidth: 610 CV score: 3.396956e+12 \nAdaptive bandwidth: 385 CV score: 3.174284e+12 \nAdaptive bandwidth: 245 CV score: 2.869084e+12 \nAdaptive bandwidth: 159 CV score: 2.565914e+12 \nAdaptive bandwidth: 105 CV score: 2.214749e+12 \nAdaptive bandwidth: 72 CV score: 1.950079e+12 \nAdaptive bandwidth: 51 CV score: 1.779031e+12 \nAdaptive bandwidth: 39 CV score: 1.661196e+12 \nAdaptive bandwidth: 30 CV score: 1.568537e+12 \nAdaptive bandwidth: 26 CV score: 1.548441e+12 \nAdaptive bandwidth: 22 CV score: 1.538973e+12 \nAdaptive bandwidth: 21 CV score: 1.523773e+12 \nAdaptive bandwidth: 19 CV score: 1.512814e+12 \nAdaptive bandwidth: 19 CV score: 1.512814e+12 \n\n\n\n\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\n\nwrite_rds(gwr_adaptive, \"data/model/gwr_adaptive.rds\")\n\n\n\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-11-07 09:45:45.353736 \n   Call:\n   gwr.basic(formula = resale_price ~ floor_area_sqm + storey_order + \n    remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n    PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 975\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-167207  -37824    -238   34255  225584 \n\n   Coefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              114172.89   34962.31   3.266 0.001131 ** \n   floor_area_sqm             2777.54     296.47   9.369  &lt; 2e-16 ***\n   storey_order              12752.37    1088.20  11.719  &lt; 2e-16 ***\n   remaining_lease_mths        349.53      14.91  23.442  &lt; 2e-16 ***\n   PROX_CBD                 -16227.90     641.72 -25.288  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -10941.60    3272.30  -3.344 0.000859 ***\n   PROX_HAWKER              -19593.07    4079.93  -4.802 1.82e-06 ***\n   PROX_MRT                 -39890.18    5465.55  -7.298 6.10e-13 ***\n   PROX_PARK                -15142.07    4697.20  -3.224 0.001308 ** \n   PROX_MALL                -14453.47    6518.98  -2.217 0.026847 *  \n   PROX_SUPERMARKET         -17056.10   13703.69  -1.245 0.213569    \n   WITHIN_350M_KINDERGARTEN   8899.14    2066.84   4.306 1.84e-05 ***\n   WITHIN_350M_CHILDCARE     -1558.56    1195.89  -1.303 0.192796    \n   WITHIN_350M_BUS            -540.34     747.34  -0.723 0.469842    \n   WITHIN_1KM_PRISCH        -10529.56    1579.19  -6.668 4.38e-11 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61510 on 960 degrees of freedom\n   Multiple R-squared: 0.7389\n   Adjusted R-squared: 0.7351 \n   F-statistic: 194.1 on 14 and 960 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.632074e+12\n   Sigma(hat): 61097.14\n   AIC:  24286.36\n   AICc:  24286.93\n   BIC:  23499.6\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 19 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -1804831.30  -212653.19     5291.59   245364.33\n   floor_area_sqm              -3179.59     1181.00     2050.13     3349.25\n   storey_order                 3150.87     8077.61    10560.26    13828.72\n   remaining_lease_mths         -532.05      345.60      426.19      503.67\n   PROX_CBD                   -81614.07   -23470.06   -10790.75    -1241.11\n   PROX_ELDERLYCARE          -261721.26   -23297.48    -5504.91    17517.51\n   PROX_HAWKER               -224701.39   -36379.62   -10415.31    20028.64\n   PROX_MRT                  -302038.66   -90711.36   -55586.34   -20477.94\n   PROX_PARK                 -259040.21   -32716.22   -15105.90     8502.33\n   PROX_MALL                 -274797.54   -36470.15     3837.09    49657.49\n   PROX_SUPERMARKET          -176198.56   -45294.60    -5513.55    30554.68\n   WITHIN_350M_KINDERGARTEN   -43497.97    -9552.68    -2527.61     5472.50\n   WITHIN_350M_CHILDCARE      -15837.43    -2492.17     1273.67     3226.31\n   WITHIN_350M_BUS             -9134.60    -1824.97      312.47     2172.53\n   WITHIN_1KM_PRISCH          -54187.08    -3572.90      574.57     4648.81\n                                  Max.\n   Intercept                1520325.69\n   floor_area_sqm              7815.07\n   storey_order               26320.98\n   remaining_lease_mths         720.63\n   PROX_CBD                  126485.54\n   PROX_ELDERLYCARE          179274.62\n   PROX_HAWKER               145934.10\n   PROX_MRT                  128454.43\n   PROX_PARK                  96676.24\n   PROX_MALL                 339627.30\n   PROX_SUPERMARKET          174674.44\n   WITHIN_350M_KINDERGARTEN   40335.52\n   WITHIN_350M_CHILDCARE      15497.94\n   WITHIN_350M_BUS            11132.40\n   WITHIN_1KM_PRISCH          32872.56\n   ************************Diagnostic information*************************\n   Number of data points: 975 \n   Effective number of parameters (2trace(S) - trace(S'S)): 409.1561 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 565.8439 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 23520.23 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 22826.72 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 23824.82 \n   Residual sum of squares: 595433551395 \n   R-square value:  0.957197 \n   Adjusted R-square value:  0.9261918 \n\n   ***********************************************************************\n   Program stops at: 2024-11-07 09:45:45.84839"
=======
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "Predictive Modelling with MLR",
    "text": "Predictive Modelling with MLR\nPredicting with test data\n\nTest data bwPredicting\n\n\n\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\n\n\n\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data, \n                        predictdata = test_data, \n                        bw=bw_adaptive, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
>>>>>>> 10fc6122f44f9543e3ef2aa7b8609dbd58a3e1d3
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-mlr-1",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-mlr-1",
    "title": "In-class Exercise 8: Building Geographically Weighted Predictive Models",
    "section": "Predictive Modelling with MLR",
<<<<<<< HEAD
    "text": "Predictive Modelling with MLR\nPredicting with test data\n\nTest data bwPredicting\n\n\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\n\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data, \n                        predictdata = test_data, \n                        bw=20, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
=======
    "text": "Predictive Modelling with MLR\nPredicting with test data\n\nTest data bwPredicting\n\n\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\ngwr_bw_test_adaptive &lt;- read_rds(\n  \"data/model/gwr_bw_test.rds\")\n\n\n\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data, \n                        predictdata = test_data, \n                        bw=20, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
>>>>>>> 10fc6122f44f9543e3ef2aa7b8609dbd58a3e1d3
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-spatialml-methods",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-spatialml-methods",
    "title": "In-class Exercise 8: Building Geographically Weighted Predictive Models",
    "section": "Predictive Modelling: SpatialML methods",
<<<<<<< HEAD
    "text": "Predictive Modelling: SpatialML methods\n\nPreparing coordinate dataDropping geometry fieldCalibrating RF modelCalibrating with grf()The model\n\n\n\ncoords &lt;- st_coordinates(HDB_sample)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\n\n\n\ntrain_data_nogeom &lt;- train_data %&gt;%\n  st_drop_geometry()\n\n\n\n\nset.seed(1234)\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data_nogeom)\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      975 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       2313484641 \nR squared (OOB):                  0.8380181 \n\n\n\n\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + \n                       storey_order + remaining_lease_mths + \n                       PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + \n                       PROX_MALL + PROX_SUPERMARKET + \n                       WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + \n                       WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data_nogeom, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom, num.trees = 500, mtry = 4, importance = \"impurity\",      num.threads = NULL) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      975 \nNumber of independent variables:  14 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       2112956167 \nR squared (OOB):                  0.8520584 \n\n\n          floor_area_sqm             storey_order     remaining_lease_mths \n            7.014621e+11             1.472727e+12             2.368021e+12 \n                PROX_CBD         PROX_ELDERLYCARE              PROX_HAWKER \n            4.516177e+12             5.035574e+11             6.351735e+11 \n                PROX_MRT                PROX_PARK                PROX_MALL \n            7.926518e+11             5.292538e+11             4.432979e+11 \n        PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN    WITHIN_350M_CHILDCARE \n            3.705109e+11             1.128608e+11             2.219549e+11 \n         WITHIN_350M_BUS        WITHIN_1KM_PRISCH \n            2.189088e+11             7.361648e+11 \n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-270000.0  -22623.5   -1053.8    -135.7   19551.9  281525.0 \n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-39147.7  -3512.7   -193.2   -140.5   3008.0  49294.8 \n\n\n                                Min          Max         Mean          StD\nfloor_area_sqm            677294908 171646042545  24533036541  30954361352\nstorey_order              549135977 331772223227  29133385869  54088578198\nremaining_lease_mths     5114375449 661823599594 102786695234 142171896348\nPROX_CBD                  912967268 332503928021  32392264333  51514033830\nPROX_ELDERLYCARE         1838564832 133952884488  22970415870  24721461470\nPROX_HAWKER               972449835 195788780973  21197339599  25558938240\nPROX_MRT                 1208193337 274719461193  28926658514  46628829835\nPROX_PARK                 975577990 180695540972  19666009819  20888518690\nPROX_MALL                1500241683 253733605522  27134708711  39751850863\nPROX_SUPERMARKET          998330364 179719290742  19465242569  27572499805\nWITHIN_350M_KINDERGARTEN  177738510  47536388608   5495873079   6638613868\nWITHIN_350M_CHILDCARE     372499585 184863358318  19039939760  34603193038\nWITHIN_350M_BUS           613737951 132566126064   8867590594  10958720806\nWITHIN_1KM_PRISCH         242833447  63838623527   6845279399   8864930840\n\n\n\n\n\ngwRF_adaptive &lt;- read_rds(\"data/model/gwRF_adaptive.rds\")"
=======
    "text": "Predictive Modelling: SpatialML methods\n\nPreparing coordinate dataDropping geometry fieldCalibrating RF modelCalibrating with grf()The model\n\n\n\ncoords &lt;- st_coordinates(HDB_sample)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\n\n\n\ntrain_data_nogeom &lt;- train_data %&gt;%\n  st_drop_geometry()\n\n\n\n\nset.seed(1234)\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data_nogeom)\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      975 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       2313484641 \nR squared (OOB):                  0.8380181 \n\n\n\n\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + \n                       storey_order + remaining_lease_mths + \n                       PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + \n                       PROX_MALL + PROX_SUPERMARKET + \n                       WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + \n                       WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data_nogeom, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom, num.trees = 500, mtry = 4, importance = \"impurity\",      num.threads = NULL) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      975 \nNumber of independent variables:  14 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       2112956167 \nR squared (OOB):                  0.8520584 \n\n\n          floor_area_sqm             storey_order     remaining_lease_mths \n            7.014621e+11             1.472727e+12             2.368021e+12 \n                PROX_CBD         PROX_ELDERLYCARE              PROX_HAWKER \n            4.516177e+12             5.035574e+11             6.351735e+11 \n                PROX_MRT                PROX_PARK                PROX_MALL \n            7.926518e+11             5.292538e+11             4.432979e+11 \n        PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN    WITHIN_350M_CHILDCARE \n            3.705109e+11             1.128608e+11             2.219549e+11 \n         WITHIN_350M_BUS        WITHIN_1KM_PRISCH \n            2.189088e+11             7.361648e+11 \n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-244730.6  -21894.3   -1486.0    -147.8   20203.9  272305.6 \n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-39989.0  -3523.0   -235.4   -115.9   2820.4  49785.4 \n\n\n                                Min          Max         Mean          StD\nfloor_area_sqm            696919686 171359696724  24585231938  31054898436\nstorey_order              556286378 336284813866  29111637645  53940346777\nremaining_lease_mths     5015621769 662431581470 102796953916 142322738014\nPROX_CBD                  969645111 333574144319  32398603460  51529843423\nPROX_ELDERLYCARE         1885669191 133808777431  23022318538  24756166362\nPROX_HAWKER              1054538821 197323237741  21225513496  25502913522\nPROX_MRT                 1230399011 268171063212  28859762449  46296774533\nPROX_PARK                1001025148 178811098249  19686271129  20914300056\nPROX_MALL                1463394653 260061426721  27018175100  39644748521\nPROX_SUPERMARKET          919432669 168565348890  19481442490  27618922136\nWITHIN_350M_KINDERGARTEN  190947575  43671284878   5500713976   6598985175\nWITHIN_350M_CHILDCARE     386573451 178795505651  19080750625  34710094711\nWITHIN_350M_BUS           641999519 139202195056   8908180301  11083301899\nWITHIN_1KM_PRISCH         232944521  62733693084   6845346956   8828863011\n\n\n\n\n\ngwRF_adaptive &lt;- read_rds(\"data/model/gwRF_adaptive.rds\")"
>>>>>>> 10fc6122f44f9543e3ef2aa7b8609dbd58a3e1d3
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predicting-by-using-the-test-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predicting-by-using-the-test-data",
<<<<<<< HEAD
    "title": "In-class Exercise 8: Building Geographically Weighted Predictive Models",
    "section": "Predicting by using the test data",
    "text": "Predicting by using the test data\n\nPreparing the test dataPredicting with the test dataCreating DF\n\n\n\ntest_data_nogeom &lt;- cbind(\n  test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data_nogeom, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\n\n\n\nGRF_pred_df &lt;- as.data.frame(gwRF_pred)\n\n\ntest_data_pred &lt;- cbind(test_data, \n                        GRF_pred_df)"
=======
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "Predicting by using the test data",
    "text": "Predicting by using the test data\n\nPreparing the test dataPredicting with the test dataCreating DF\n\n\n\n\ntest_data_nogeom &lt;- cbind(\n  test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n\n\nIn the code chunk below, predict.grf() of spatialML for predicting re-sale prices in the test data set (i.e. test_data_nogeom)\n\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data_nogeom, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\n\n\n\nNext, the code chunk below is used to convert the output from predict.grf() into a data.frame.\n\n\nGRF_pred_df &lt;- as.data.frame(gwRF_pred)\n\n\nThen, cbind() is used to append fields in GRF_pred_df data.frame onto test_data.\n\n\ntest_data_pred &lt;- cbind(test_data, \n                        GRF_pred_df)"
>>>>>>> 10fc6122f44f9543e3ef2aa7b8609dbd58a3e1d3
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#visualising-the-predicted-values",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#visualising-the-predicted-values",
<<<<<<< HEAD
    "title": "In-class Exercise 8: Building Geographically Weighted Predictive Models",
    "section": "Visualising the predicted values",
    "text": "Visualising the predicted values\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = test_data_pred,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()"
=======
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "Visualising the predicted values",
    "text": "Visualising the predicted values\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = test_data_pred,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-gwr",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-with-gwr",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "Predictive Modelling with gwr",
    "text": "Predictive Modelling with gwr\nComputing adaptive bandwidth\n\nThe codeThe output\n\n\n\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\n\n\n\n\nbw_adaptive\n\n[1] 19"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-rf-method",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-rf-method",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "Predictive Modelling: RF method",
    "text": "Predictive Modelling: RF method\n\nData preparationCalibrating RF modelModel output\n\n\nFirstly, code chunk below is used to extract the coordinates of training and test data sets\n\n\ncoords &lt;- st_coordinates(HDB_sample)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\n\nNext, code chunk below is used to drop the geometry column of both training and test data sets.\n\n\ntrain_data_nogeom &lt;- train_data %&gt;%\n  st_drop_geometry()\n\n\n\n\n\n\nset.seed(1234)\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data_nogeom)\n\n\n\n\n\n\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      1000 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       2289284270 \nR squared (OOB):                  0.8406868"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-spatialml-method",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predictive-modelling-spatialml-method",
    "title": "In-class Exercise 8: Supplement to Hands-on Exercise 8",
    "section": "Predictive Modelling: SpatialML method",
    "text": "Predictive Modelling: SpatialML method\n\nCalibrating with grf\n\n\n\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + \n                       storey_order + remaining_lease_mths + \n                       PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n                       PROX_MRT + PROX_PARK + PROX_MALL + \n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data_nogeom, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)"
>>>>>>> 10fc6122f44f9543e3ef2aa7b8609dbd58a3e1d3
  }
]