{
  "hash": "ace7fedb4a4fb754b5002c263bcd4d65",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation: sfdep methods\"\nauthor: \"Dr. Kam Tin Seong<br/>Assoc. Professor of Information Systems(Practice)\"\ninstitute: \"School of Computing and Information Systems,<br/>Singapore Management University\"\ndate: \"last-modified\"\nformat: \n  revealjs:\n    pdf: default\n    width: 1600\n    height: 900\n    show-notes: false\n    slide-number: true\n    show-slide-number: all\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  freeze: true\neditor: visual\n---\n\n\n## Content\n\n-   Introducing [**sfdep**](https://sfdep.josiahparry.com/index.html). \n    -   sfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep. \n    -   sfdep utilizes list columns extensively to make this interface possible.\"\n\n\n## Getting started\n\n### Installing and Loading the R Packages\n\nFour R packages will be used for this in-class exercise, they are: sf, sfdep, tmap and tidyverse.\n\n::: {.panel-tabset}\n### Do It Yourself!\n\nUsing the steps you learned in previous lesson, install and load **sf**, **tmap**, **sfdep** and **tidyverse** packages into R environment.\n\n### The code\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, sfdep, tmap, tidyverse)\n```\n:::\n\n:::\n:::\n\n## The Data\n\nFor the purpose of this in-class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:\n\n-   Hunan, a geospatial data set in ESRI shapefile format, and\n-   Hunan_2012, an attribute data set in csv format.\n\n::: {.panel-tabset}\n### Do It Yourself!\n\nUsing the steps you learned in previous lesson, import *Hunan* shapefile into R environment as an sf data frame.\n\n### The code\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Hunan' from data source \n  `D:\\tskam\\ISSS626-AY2024-25Aug\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n:::\n:::\n\n## Importing Attribute Table\n\n::: {.panel-tabset}\n### Do It Yourself!\n\nUsing the steps you learned in previous lesson, import *Hunan_2012.csv* into R environment as an tibble data frame.\n\n### The ccode\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n```\n:::\n\n:::\n:::\n\n## Combining both data frame by using left join\n\n::: {.panel-tabset}\n### Do It Yourself!\n\nUsing the steps you learned in previous lesson, combine the Hunan sf data frame and Hunan_2012 data frame. Ensure that the output is an sf data frame.\n\n::: callout-important\nIn order to retain the geospatial properties, the left data frame must the sf data.frame (i.e. hunan)\n:::\n\n### The code\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_GDPPC <- left_join(hunan, hunan2012) %>%\n  select(1:4, 7, 15)\n```\n:::\n\n:::\n:::\n\n## Plotting a choropleth map\n\n::: {.panel-tabset}\n### Do It Yourself!\n\nUsing the steps you learned in previous lesson, plot a choropleth map showing the distribution of GDPPC of Hunan Province.\n\n### The plot\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](In-class_Ex05_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='left' width=864}\n:::\n:::\n\n\n### The code\n\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n```\n:::\n\n:::\n:::\n\n## Global Measures of Spatial Association\n### Step 1: Deriving Queen's contiguity weights: sfdep methods\n\n::: columns\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1) \n```\n:::\n\n:::\n:::\n\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 0.85em\"}\nNotice that `st_weights()` provides tree arguments, they are:\n\n-   *nb*: A neighbor list object as created by st_neighbors().\n-   *style*: Default \"W\" for row standardized weights. This value can also be \"B\", \"C\", \"U\", \"minmax\", and \"S\". B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n-   *allow_zero*: If TRUE, assigns zero as lagged value to zone without neighbors.\n:::\n:::\n:::\n\n---\n\n### The wm_q \n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n```\n\n\n:::\n:::\n\n:::\n\n---\n\n### Computing Global Moran' I\n\n::: columns\n::: {.column width=\"65%\"}\nIn the code chunk below, global_moran() function is used to compute the Moran's I value. Different from spdep package, the output is a tibble data.frame.\n\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranI <- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n```\n\n\n:::\n:::\n\n:::\n:::\n:::\n\n---\n\n### Performing Global Moran'sI test\n\nIn general, Moran's I test will be performed instead of just computing the Moran's I statistics. With sfdep package, Moran's I test can be performed by using [`global_moran_test()`](https://sfdep.josiahparry.com/reference/global_moran_test.html) as shown in the code chunk below.\n\n::: {.panel-tabset}\n### The code\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_test(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n```\n\n\n:::\n:::\n\n:::\n\n### Tips\n::: callout-tip\n-   The default for `alternative` argument is \"two.sided\". Other supported arguments are \"greater\" or \"less\". randomization, and\n-   By default the `randomization` argument is **TRUE**. If FALSE, under the assumption of normality.\n:::\n:::\n\n---\n\n### Performing Global Moran'I permutation test\n\nIn practice, Monte carlo simulation should be used to perform the statistical test. For **sfdep**, it is supported by [`globel_moran_perm()`](https://sfdep.josiahparry.com/reference/global_moran_perm.html)\n\n::: {.panel-tabset}\n### Step 1\nIt is always a good practice to use `set.seed()` before performing simulation. This is to ensure that the computation is reproducible.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n```\n:::\n\n\n### Step 2\nNext, `global_moran_perm()` is used to perform Monte Carlo simulation.\n\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n:::\n\n### The report\nThe statistical report on previous tab shows that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of GPD per capita are resemble random distribution (i.e. independent from spatial). Because the Moran's I statistics is greater than 0. We can infer that the spatial distribution shows sign of clustering.\n\n::: callout-tip\n# Reminder\n\nThe numbers of simulation is alway equal to nsim + 1. This mean in nsim = 99. This mean 100 simulation will be performed.\n:::\n:::\n\n## Computing local Moran's I\n\nIn this section, you will learn how to compute Local Moran's I of GDPPC at county level by using [`local_moran()`](https://sfdep.josiahparry.com/reference/local_moran.html) of sfdep package.\n\n::: {.panel-tabset}\n### The code\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa <- wm_q %>% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_moran)\n```\n:::\n\n:::\n\n### The output\n::: {style=\"font-size: 0.7em\"}\nThe output of `local_moran()` is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.\n\n-   ii: local moran statistic\n-   eii: expectation of local moran statistic; for localmoran_permthe permutation sample means\n-   var_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations\n-   z_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations p_ii_sim: For `localmoran_perm()`, `rank()` and `punif()` of observed statistic rank for \\[0, 1\\] p-values using `alternative=` -p_folded_sim: the simulation folded \\[0, 0.5\\] range ranked p-value (based on https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b cadcbecc5e061/esda/crand.py#L211-L213)\n-   skewness: For `localmoran_perm`, the output of e1071::skewness() for the permutation samples underlying the standard deviates\n-   kurtosis: For `localmoran_perm`, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.\n:::\n:::\n\n---\n\n### Visualising local Moran's I\n\n::: columns\n::: {.column width=\"50%\"}\nIn this code chunk below, tmap functions are used prepare a choropleth map by using value in the *ii* field.\n\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 2)\n```\n:::\n\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](In-class_Ex05_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n---\n\n### Visualising p-value of local Moran's I\n\n::: columns\n::: {.column width=\"50%\"}\nIn the code chunk below, tmap functions are used prepare a choropleth map by using value in the *p_ii_sim* field.\n\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 2)\n```\n:::\n\n:::\n\n\n::: callout-warning\nFor p-values, the appropriate classification should be 0.001, 0.01, 0.05 and not significant instead of using default classification scheme.\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](In-class_Ex05_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n---\n\n### Visualising local Moran's I and p-value\n\nFor effective comparison, it will be better for us to plot both maps next to each other.\n\n::: panel-tabset\n\n### The plot\n\n::: {.cell}\n::: {.cell-output-display}\n![](In-class_Ex05_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n### The code\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\nmap1 <- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n```\n:::\n\n:::\n:::\n\n---\n\n### LISA map\n\n::: columns\n::: {.column width=\"50%\"}\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low cluaters. In fact, LISA map is an interpreted map by combining local Moran's I of geographical areas and their respective p-values.\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](In-class_Ex05_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n---\n\n### Visualising LISA map\n\nIn lisa sf data.frame, we can find three fields contain the LISA categories. They are *mean*, *median* and *pysal*. In general, classification in *mean* will be used as shown in the code chunk below.\n\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa_sig <- lisa  %>%\n  filter(p_ii < 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n```\n:::\n\n:::\n\n## Hot Spot and Cold Spot Area Analysis (HCSA)\n\nHCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure.\n\n---\n\n### Computing local Gi\\* statistics\n\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi\\* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_idw <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n```\n:::\n\n:::\n\n::: callout-note\nGi\\* and local Gi\\* are distance-based spatial statistics. Hence, distance methods instead of contiguity methods should be used to derive the spatial weight matrix.\n:::\n\n---\n\n### Computing local Gi\\* statistics\n\nNow, we will compute the local Gi\\* by using the code chunk below.\n\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\nHCSA\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     <dbl> <fct>    <dbl>      <dbl>   <dbl>   <dbl> <dbl>        <dbl>    <dbl>\n 1  0.0416 Low     0.0114 0.00000641  0.0493 9.61e-1  0.7          0.35    0.875\n 2 -0.333  Low     0.0106 0.00000384 -0.0941 9.25e-1  1            0.5     0.661\n 3  0.281  High    0.0126 0.00000751 -0.151  8.80e-1  0.9          0.45    0.640\n 4  0.411  High    0.0118 0.00000922  0.264  7.92e-1  0.6          0.3     0.853\n 5  0.387  High    0.0115 0.00000956  0.339  7.34e-1  0.62         0.31    1.07 \n 6 -0.368  High    0.0118 0.00000591 -0.583  5.60e-1  0.72         0.36    0.594\n 7  3.56   High    0.0151 0.00000731  2.61   9.01e-3  0.06         0.03    1.09 \n 8  2.52   High    0.0136 0.00000614  1.49   1.35e-1  0.2          0.1     1.12 \n 9  4.56   High    0.0144 0.00000584  3.53   4.17e-4  0.04         0.02    1.23 \n10  1.16   Low     0.0104 0.00000370  1.82   6.86e-2  0.12         0.06    0.416\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis <dbl>, nb <nb>, wts <list>, NAME_2 <chr>,\n#   ID_3 <int>, NAME_3 <chr>, ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>,\n#   geometry <POLYGON [°]>\n```\n\n\n:::\n:::\n\n:::\n\n---\n\n### Visualising Gi\\*\n\n::: columns\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n```\n:::\n\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](In-class_Ex05_files/figure-revealjs/unnamed-chunk-25-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n---\n\n### Visualising p-value of HCSA\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](In-class_Ex05_files/figure-revealjs/unnamed-chunk-26-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n```\n:::\n\n:::\n:::\n:::\n\n---\n\n### Visuaising local HCSA\n\nFor effective comparison, you can plot both maps next to each other as shown below.\n\n::: {.panel-tabset}\n\n### The plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](In-class_Ex05_files/figure-revealjs/unnamed-chunk-28-1.png){width=960}\n:::\n:::\n\n\n\n### The code\n\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\nmap1 <- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n```\n:::\n\n:::\n:::\n\n---\n\n### Visualising hot spot and cold spot areas\n\n::: columns\n::: {.column width=\"50%\"}\nNow, we are ready to plot the significant (i.e. p-values less than 0.05) hot spot and cold spot areas by using appropriate tmap functions as shown below.\n\n::: {style=\"font-size: 1.5em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA_sig <- HCSA  %>%\n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.4)\n```\n:::\n\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](In-class_Ex05_files/figure-revealjs/unnamed-chunk-31-1.png){width=960}\n:::\n:::\n\n\n::: callout-note\nFigure above reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran's I method in the earlier sub-section.\n:::\n:::\n:::",
    "supporting": [
      "In-class_Ex05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}